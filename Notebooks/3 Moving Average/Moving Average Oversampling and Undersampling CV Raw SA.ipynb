{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, cross_val_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours, TomekLinks\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv(\"./../../Datasets/kieranFeatures_1-31_21-Jan-2025_avgof3_rawSA.csv\").replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Create Low vs High Columns\n",
    "df[\"Lv_1_Lo\"] = (df[\"SA1\"] < 5).astype(np.bool_)\n",
    "df[\"Lv_2_Lo\"] = (df[\"SA2\"] < 5).astype(np.bool_)\n",
    "df[\"Lv_3_Lo\"] = (df[\"SA3\"] < 5).astype(np.bool_)\n",
    "df[\"Tot_Lo\"] = (df[\"SAtotal\"] < 15).astype(np.bool_)\n",
    "\n",
    "# Impute missing values with mean of column\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].fillna(value = df[col].mean())\n",
    "\n",
    "# Split up dataset\n",
    "ids = df[\"ID\"].astype(np.uint8)\n",
    "# trial_nums = df[\"trialNum\"].astype(np.uint8)\n",
    "predictors_df = df.drop(columns = [\"ID\", \"trialNum\", \"SA1\", \"SA2\", \"SA3\", \"SAtotal\", \"Lv_1_Lo\", \"Lv_2_Lo\", \"Lv_3_Lo\", \"Tot_Lo\"]).astype(np.float64)\n",
    "outcomes_df = df[[\"Lv_1_Lo\", \"Lv_2_Lo\", \"Lv_3_Lo\", \"Tot_Lo\"]]\n",
    "outcomes_df_shuffled = outcomes_df.copy()\n",
    "\n",
    "# Shuffle labels for shuffled data\n",
    "outcomes_df_shuffled[\"Lv_1_Lo\"] = np.random.permutation(outcomes_df_shuffled[\"Lv_1_Lo\"])\n",
    "outcomes_df_shuffled[\"Lv_2_Lo\"] = np.random.permutation(outcomes_df_shuffled[\"Lv_2_Lo\"])\n",
    "outcomes_df_shuffled[\"Lv_3_Lo\"] = np.random.permutation(outcomes_df_shuffled[\"Lv_3_Lo\"])\n",
    "outcomes_df_shuffled[\"Tot_Lo\"] = np.random.permutation(outcomes_df_shuffled[\"Tot_Lo\"])\n",
    "\n",
    "# Free up memory\n",
    "del col, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 42)\n",
    "\n",
    "no_penalty_model = LogisticRegression(\n",
    "    fit_intercept = False,\n",
    "    solver = \"saga\",\n",
    "    n_jobs = -1,\n",
    "    max_iter = 20000,\n",
    "    class_weight = \"balanced\",\n",
    "    penalty = None,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "Ridge_model = LogisticRegression(\n",
    "    C = 0.001,\n",
    "    fit_intercept = False,\n",
    "    solver = \"saga\",\n",
    "    n_jobs = -1,\n",
    "    max_iter = 20000,\n",
    "    class_weight = \"balanced\",\n",
    "    penalty = \"l2\",\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "LASSO_model = LogisticRegression(\n",
    "    C = 1,\n",
    "    fit_intercept = False,\n",
    "    solver = \"saga\",\n",
    "    n_jobs = -1,\n",
    "    max_iter = 20000,\n",
    "    class_weight = \"balanced\",\n",
    "    penalty = \"l1\",\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "modified_Ridge_model_l2 = LogisticRegression(\n",
    "    fit_intercept = False,\n",
    "    solver = \"saga\",\n",
    "    n_jobs = -1,\n",
    "    max_iter = 20000,\n",
    "    class_weight = \"balanced\",\n",
    "    penalty = \"l2\",\n",
    "    C = 0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Mean F1: 0.587\n",
      "*** Median F1: 0.596\n"
     ]
    }
   ],
   "source": [
    "# No Penalty Control\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 42)\n",
    "pipeline = Pipeline([(\"transformer\", StandardScaler()), (\"estimator\", no_penalty_model)])\n",
    "scores = cross_val_score(pipeline, predictors_df.values, outcomes_df[\"Lv_1_Lo\"].values, scoring = \"f1\", cv = cv.split(predictors_df, ids), n_jobs = -1)\n",
    "print(\"*** Mean F1: %.3f\" % np.mean(scores))\n",
    "print(\"*** Median F1: %.3f\" % np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE(random_state=42)\n",
      "*** Mean F1: 0.596\n",
      "*** Median F1: 0.596\n",
      "\n",
      "BorderlineSMOTE(random_state=42)\n",
      "*** Mean F1: 0.587\n",
      "*** Median F1: 0.596\n",
      "\n",
      "SVMSMOTE(random_state=42)\n",
      "*** Mean F1: 0.590\n",
      "*** Median F1: 0.609\n",
      "\n",
      "ADASYN(random_state=42)\n",
      "*** Mean F1: 0.588\n",
      "*** Median F1: 0.588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# No Penalty (Just Over)\n",
    "for oversampling_method in [SMOTE(random_state = 42), BorderlineSMOTE(random_state = 42), SVMSMOTE(random_state = 42), ADASYN(random_state = 42)]:\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 42)\n",
    "    pipeline = Pipeline([(\"transformer\", StandardScaler()), (\"over\", oversampling_method), (\"estimator\", no_penalty_model)])\n",
    "    scores = cross_val_score(pipeline, predictors_df.values, outcomes_df[\"Lv_1_Lo\"].values, scoring = \"f1\", cv = cv.split(predictors_df, ids), n_jobs = -1)\n",
    "    print(oversampling_method)\n",
    "    print(\"*** Mean F1: %.3f\" % np.mean(scores))\n",
    "    print(\"*** Median F1: %.3f\" % np.median(scores))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE(random_state=42) RandomUnderSampler(random_state=42)\n",
      "*** Mean F1: 0.596\n",
      "*** Median F1: 0.596\n",
      "\n",
      "SMOTE(random_state=42) EditedNearestNeighbours()\n",
      "*** Mean F1: 0.596\n",
      "*** Median F1: 0.596\n",
      "\n",
      "SMOTE(random_state=42) TomekLinks()\n",
      "*** Mean F1: 0.596\n",
      "*** Median F1: 0.596\n",
      "\n",
      "BorderlineSMOTE(random_state=42) RandomUnderSampler(random_state=42)\n",
      "*** Mean F1: 0.587\n",
      "*** Median F1: 0.596\n",
      "\n",
      "BorderlineSMOTE(random_state=42) EditedNearestNeighbours()\n",
      "*** Mean F1: 0.587\n",
      "*** Median F1: 0.596\n",
      "\n",
      "BorderlineSMOTE(random_state=42) TomekLinks()\n",
      "*** Mean F1: 0.587\n",
      "*** Median F1: 0.596\n",
      "\n",
      "SVMSMOTE(random_state=42) RandomUnderSampler(random_state=42)\n",
      "*** Mean F1: 0.592\n",
      "*** Median F1: 0.609\n",
      "\n",
      "SVMSMOTE(random_state=42) EditedNearestNeighbours()\n",
      "*** Mean F1: 0.592\n",
      "*** Median F1: 0.609\n",
      "\n",
      "SVMSMOTE(random_state=42) TomekLinks()\n",
      "*** Mean F1: 0.592\n",
      "*** Median F1: 0.609\n",
      "\n",
      "ADASYN(random_state=42) RandomUnderSampler(random_state=42)\n",
      "*** Mean F1: 0.579\n",
      "*** Median F1: 0.586\n",
      "\n",
      "ADASYN(random_state=42) EditedNearestNeighbours()\n",
      "*** Mean F1: 0.579\n",
      "*** Median F1: 0.586\n",
      "\n",
      "ADASYN(random_state=42) TomekLinks()\n",
      "*** Mean F1: 0.579\n",
      "*** Median F1: 0.586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# No Penalty (Over and Under)\n",
    "for oversampling_method in [SMOTE(random_state = 42), BorderlineSMOTE(random_state = 42), SVMSMOTE(random_state = 42), ADASYN(random_state = 42)]:\n",
    "    for undersampling_method in [RandomUnderSampler(random_state = 42), EditedNearestNeighbours(), TomekLinks()]:\n",
    "        cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 42)\n",
    "        pipeline = Pipeline([(\"transformer\", StandardScaler()), (\"over\", oversampling_method), (\"under\", RandomUnderSampler(random_state = 42)), (\"estimator\", no_penalty_model)])\n",
    "        scores = cross_val_score(pipeline, predictors_df.values, outcomes_df[\"Lv_1_Lo\"].values, scoring = \"f1\", cv = cv.split(predictors_df, ids), n_jobs = -1)\n",
    "        print(oversampling_method, undersampling_method)\n",
    "        print(\"*** Mean F1: %.3f\" % np.mean(scores))\n",
    "        print(\"*** Median F1: %.3f\" % np.median(scores))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN(random_state=42)\n",
      "*** Mean F1: 0.584\n",
      "*** Median F1: 0.593\n",
      "\n",
      "ADASYN(random_state=42)\n",
      "*** Mean F1: 0.597\n",
      "*** Median F1: 0.604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# No Penalty (Over and Under from library)\n",
    "for combination_method in [SMOTEENN(random_state = 42), SMOTETomek(random_state = 42)]:\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 42)\n",
    "    pipeline = Pipeline([(\"transformer\", StandardScaler()), (\"combine\", combination_method), (\"estimator\", no_penalty_model)])\n",
    "    scores = cross_val_score(pipeline, predictors_df.values, outcomes_df[\"Lv_1_Lo\"].values, scoring = \"f1\", cv = cv.split(predictors_df, ids), n_jobs = -1)\n",
    "    print(combination_method)\n",
    "    print(\"*** Mean F1: %.3f\" % np.mean(scores))\n",
    "    print(\"*** Median F1: %.3f\" % np.median(scores))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Mean F1: 0.640\n",
      "*** Median F1: 0.638\n"
     ]
    }
   ],
   "source": [
    "# Ridge Control\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 42)\n",
    "pipeline = Pipeline([(\"transformer\", StandardScaler()), (\"estimator\", Ridge_model)])\n",
    "scores = cross_val_score(pipeline, predictors_df, outcomes_df[\"Lv_1_Lo\"], scoring = \"f1\", cv = cv.split(predictors_df, ids), n_jobs = -1)\n",
    "print(\"*** Mean F1: %.3f\" % np.mean(scores))\n",
    "print(\"*** Median F1: %.3f\" % np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE(random_state=42)\n",
      "*** Mean F1: 0.639\n",
      "*** Median F1: 0.609\n",
      "\n",
      "BorderlineSMOTE(random_state=42)\n",
      "*** Mean F1: 0.642\n",
      "*** Median F1: 0.626\n",
      "\n",
      "SVMSMOTE(random_state=42)\n",
      "*** Mean F1: 0.629\n",
      "*** Median F1: 0.604\n",
      "\n",
      "ADASYN(random_state=42)\n",
      "*** Mean F1: 0.638\n",
      "*** Median F1: 0.640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge (Just Over)\n",
    "for oversampling_method in [SMOTE(random_state = 42), BorderlineSMOTE(random_state = 42), SVMSMOTE(random_state = 42), ADASYN(random_state = 42)]:\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 42)\n",
    "    pipeline = Pipeline([(\"transformer\", StandardScaler()), (\"over\", oversampling_method), (\"estimator\", Ridge_model)])\n",
    "    scores = cross_val_score(pipeline, predictors_df.values, outcomes_df[\"Lv_1_Lo\"].values, scoring = \"f1\", cv = cv.split(predictors_df, ids), n_jobs = -1)\n",
    "    print(oversampling_method)\n",
    "    print(\"*** Mean F1: %.3f\" % np.mean(scores))\n",
    "    print(\"*** Median F1: %.3f\" % np.median(scores))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE(random_state=42) RandomUnderSampler(random_state=42)\n",
      "*** Mean F1: 0.639\n",
      "*** Median F1: 0.609\n",
      "\n",
      "SMOTE(random_state=42) EditedNearestNeighbours()\n",
      "*** Mean F1: 0.639\n",
      "*** Median F1: 0.609\n",
      "\n",
      "SMOTE(random_state=42) TomekLinks()\n",
      "*** Mean F1: 0.639\n",
      "*** Median F1: 0.609\n",
      "\n",
      "BorderlineSMOTE(random_state=42) RandomUnderSampler(random_state=42)\n",
      "*** Mean F1: 0.642\n",
      "*** Median F1: 0.626\n",
      "\n",
      "BorderlineSMOTE(random_state=42) EditedNearestNeighbours()\n",
      "*** Mean F1: 0.642\n",
      "*** Median F1: 0.626\n",
      "\n",
      "BorderlineSMOTE(random_state=42) TomekLinks()\n",
      "*** Mean F1: 0.642\n",
      "*** Median F1: 0.626\n",
      "\n",
      "SVMSMOTE(random_state=42) RandomUnderSampler(random_state=42)\n",
      "*** Mean F1: 0.629\n",
      "*** Median F1: 0.604\n",
      "\n",
      "SVMSMOTE(random_state=42) EditedNearestNeighbours()\n",
      "*** Mean F1: 0.629\n",
      "*** Median F1: 0.604\n",
      "\n",
      "SVMSMOTE(random_state=42) TomekLinks()\n",
      "*** Mean F1: 0.629\n",
      "*** Median F1: 0.604\n",
      "\n",
      "ADASYN(random_state=42) RandomUnderSampler(random_state=42)\n",
      "*** Mean F1: 0.638\n",
      "*** Median F1: 0.636\n",
      "\n",
      "ADASYN(random_state=42) EditedNearestNeighbours()\n",
      "*** Mean F1: 0.638\n",
      "*** Median F1: 0.636\n",
      "\n",
      "ADASYN(random_state=42) TomekLinks()\n",
      "*** Mean F1: 0.638\n",
      "*** Median F1: 0.636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge (Over and Under)\n",
    "for oversampling_method in [SMOTE(random_state = 42), BorderlineSMOTE(random_state = 42), SVMSMOTE(random_state = 42), ADASYN(random_state = 42)]:\n",
    "    for undersampling_method in [RandomUnderSampler(random_state = 42), EditedNearestNeighbours(), TomekLinks()]:\n",
    "        cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 42)\n",
    "        pipeline = Pipeline([(\"transformer\", StandardScaler()), (\"over\", oversampling_method), (\"under\", RandomUnderSampler(random_state = 42)), (\"estimator\", Ridge_model)])\n",
    "        scores = cross_val_score(pipeline, predictors_df.values, outcomes_df[\"Lv_1_Lo\"].values, scoring = \"f1\", cv = cv.split(predictors_df, ids), n_jobs = -1)\n",
    "        print(oversampling_method, undersampling_method)\n",
    "        print(\"*** Mean F1: %.3f\" % np.mean(scores))\n",
    "        print(\"*** Median F1: %.3f\" % np.median(scores))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTEENN(random_state=42)\n",
      "*** Mean F1: 0.575\n",
      "*** Median F1: 0.556\n",
      "\n",
      "SMOTETomek(random_state=42)\n",
      "*** Mean F1: 0.633\n",
      "*** Median F1: 0.609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge (Over and Under from library)\n",
    "for combination_method in [SMOTEENN(random_state = 42), SMOTETomek(random_state = 42)]:\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 42)\n",
    "    pipeline = Pipeline([(\"transformer\", StandardScaler()), (\"combine\", combination_method), (\"estimator\", Ridge_model)])\n",
    "    scores = cross_val_score(pipeline, predictors_df.values, outcomes_df[\"Lv_1_Lo\"].values, scoring = \"f1\", cv = cv.split(predictors_df, ids), n_jobs = -1)\n",
    "    print(combination_method)\n",
    "    print(\"*** Mean F1: %.3f\" % np.mean(scores))\n",
    "    print(\"*** Median F1: %.3f\" % np.median(scores))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO Control\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 42)\n",
    "pipeline = Pipeline([(\"transformer\", StandardScaler()), (\"estimator\", LASSO_model)])\n",
    "scores = cross_val_score(pipeline, predictors_df, outcomes_df[\"Lv_1_Lo\"], scoring = \"f1\", cv = cv.split(predictors_df, ids), n_jobs = -1)\n",
    "print(\"*** Mean F1: %.3f\" % np.mean(scores))\n",
    "print(\"*** Median F1: %.3f\" % np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO (Just Over)\n",
    "for oversampling_method in [SMOTE(random_state = 42), BorderlineSMOTE(random_state = 42), SVMSMOTE(random_state = 42), ADASYN(random_state = 42)]:\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 42)\n",
    "    pipeline = Pipeline([(\"transformer\", StandardScaler()), (\"over\", oversampling_method), (\"estimator\", LASSO_model)])\n",
    "    scores = cross_val_score(pipeline, predictors_df, outcomes_df[\"Lv_1_Lo\"], scoring = \"f1\", cv = cv.split(predictors_df, ids), n_jobs = -1)\n",
    "    print(\"*** Mean F1: %.3f\" % np.mean(scores))\n",
    "    print(\"*** Median F1: %.3f\" % np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO (Over and Under)\n",
    "for oversampling_method in [SMOTE(random_state = 42), BorderlineSMOTE(random_state = 42), SVMSMOTE(random_state = 42), ADASYN(random_state = 42)]:\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 42)\n",
    "    pipeline = Pipeline([(\"transformer\", StandardScaler()), (\"over\", oversampling_method), (\"under\", RandomUnderSampler(random_state = 42)), (\"estimator\", LASSO_model)])\n",
    "    scores = cross_val_score(pipeline, predictors_df, outcomes_df[\"Lv_1_Lo\"], scoring = \"f1\", cv = cv.split(predictors_df, ids), n_jobs = -1)\n",
    "    print(\"*** Mean F1: %.3f\" % np.mean(scores))\n",
    "    print(\"*** Median F1: %.3f\" % np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO (Over and Under from library)\n",
    "for combination_method in [SMOTEENN(random_state = 42), SMOTETomek(random_state = 42)]:\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 42)\n",
    "    pipeline = Pipeline([(\"transformer\", StandardScaler()), (\"combine\", combination_method), (\"estimator\", LASSO_model)])\n",
    "    scores = cross_val_score(pipeline, predictors_df, outcomes_df[\"Lv_1_Lo\"], scoring = \"f1\", cv = cv.split(predictors_df, ids), n_jobs = -1)\n",
    "    print(\"*** Mean F1: %.3f\" % np.mean(scores))\n",
    "    print(\"*** Median F1: %.3f\" % np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO (Varying Under)\n",
    "for undersampling_method in [RandomUnderSampler(random_state = 42), EditedNearestNeighbours(), TomekLinks()]:\n",
    "    cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 42)\n",
    "    pipeline = Pipeline([(\"transformer\", StandardScaler()), (\"over\", SVMSMOTE(random_state = 42)), (\"under\", undersampling_method), (\"estimator\", LASSO_model)])\n",
    "    scores = cross_val_score(pipeline, predictors_df, outcomes_df[\"Lv_1_Lo\"], scoring = \"f1\", cv = cv.split(predictors_df, ids), n_jobs = -1)\n",
    "    print(\"*** Mean F1: %.3f\" % np.mean(scores))\n",
    "    print(\"*** Median F1: %.3f\" % np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(pred_df, out_df, ids):\n",
    "    # Obtain 10 test folds stratifying by participant ID\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "    for i, (CV_idx, test_idx) in enumerate(skf.split(pred_df, ids)):\n",
    "        # Train-Test Split for the Fold\n",
    "        ids_CV = ids.iloc[CV_idx].values\n",
    "        # ids_test = ids.iloc[test_idx].values\n",
    "        # trial_nums_CV = ids.iloc[CV_idx].values\n",
    "        # trial_nums_test = ids.iloc[test_idx].values\n",
    "        pred_CV = pred_df.iloc[CV_idx, :].values\n",
    "        pred_test = pred_df.iloc[test_idx, :].values\n",
    "        out_CV = out_df.iloc[CV_idx].values\n",
    "        # out_test = out_df.iloc[test_idx].values\n",
    "\n",
    "        # Standardize data for each test fold\n",
    "        scaler = StandardScaler()\n",
    "        pred_CV = scaler.fit_transform(pred_CV)\n",
    "        pred_test = scaler.transform(pred_test)\n",
    "\n",
    "        # Setup Cross Validation Object\n",
    "        rskf = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 2, random_state = 42)\n",
    "        \n",
    "        # Initialize Models to Train\n",
    "        LASSO_model = LogisticRegressionCV(\n",
    "            Cs = [0.001, 0.01, 0.1, 1], \n",
    "            cv = rskf.split(pred_CV, ids_CV), \n",
    "            fit_intercept = False,\n",
    "            class_weight = \"balanced\",\n",
    "            penalty = \"l1\", \n",
    "            solver = \"saga\", \n",
    "            n_jobs = -1, \n",
    "            max_iter = 20000, \n",
    "            scoring = \"f1\", \n",
    "            refit = True,\n",
    "            random_state = 42\n",
    "        )\n",
    "\n",
    "        # Fit Models\n",
    "        LASSO_model.fit(pred_CV, out_CV)\n",
    "\n",
    "        # Display C value\n",
    "        print(LASSO_model.C_)\n",
    "\n",
    "        # Completion Message\n",
    "        print(f\"Test Fold {i + 1} Completed\")\n",
    "\n",
    "evaluate_models(predictors_df, outcomes_df[\"Lv_1_Lo\"], ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
