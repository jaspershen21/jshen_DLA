{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>EDA_TonicMean_version02</th>\n",
       "      <th>EDA_TonicMean_version03</th>\n",
       "      <th>EDA_TonicMean_version04</th>\n",
       "      <th>EDA_TonicMean_version05</th>\n",
       "      <th>EDA_TonicMean_version09</th>\n",
       "      <th>EDA_TonicMean_version10</th>\n",
       "      <th>EDA_TonicMean_version11</th>\n",
       "      <th>EDA_TonicMean_version12</th>\n",
       "      <th>EDA_TonicMean_version16</th>\n",
       "      <th>...</th>\n",
       "      <th>EEG_avgRelTheta_version16</th>\n",
       "      <th>EEG_avgRelTheta_version17</th>\n",
       "      <th>EEG_avgRelTheta_version19</th>\n",
       "      <th>EEG_avgRelTheta_version20</th>\n",
       "      <th>EEG_avgRelTheta_version22</th>\n",
       "      <th>EEG_avgRelTheta_version23</th>\n",
       "      <th>adjSA1</th>\n",
       "      <th>adjSA2</th>\n",
       "      <th>adjSA3</th>\n",
       "      <th>adjSAtotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.123031</td>\n",
       "      <td>-0.226077</td>\n",
       "      <td>-1.220480</td>\n",
       "      <td>-1.697738</td>\n",
       "      <td>-0.273200</td>\n",
       "      <td>-0.601171</td>\n",
       "      <td>-0.809518</td>\n",
       "      <td>-1.012558</td>\n",
       "      <td>-0.299118</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.877017</td>\n",
       "      <td>-1.442056</td>\n",
       "      <td>1.070298</td>\n",
       "      <td>1.277417</td>\n",
       "      <td>0.249605</td>\n",
       "      <td>0.400156</td>\n",
       "      <td>0.119790</td>\n",
       "      <td>1.593122</td>\n",
       "      <td>-0.800726</td>\n",
       "      <td>0.350233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.152896</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>1.527067</td>\n",
       "      <td>1.883468</td>\n",
       "      <td>-0.378060</td>\n",
       "      <td>-0.018812</td>\n",
       "      <td>1.023216</td>\n",
       "      <td>1.189124</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.632698</td>\n",
       "      <td>-1.531970</td>\n",
       "      <td>1.779032</td>\n",
       "      <td>1.074498</td>\n",
       "      <td>0.409991</td>\n",
       "      <td>0.333842</td>\n",
       "      <td>0.075246</td>\n",
       "      <td>-1.663383</td>\n",
       "      <td>0.859309</td>\n",
       "      <td>-0.262893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.166035</td>\n",
       "      <td>-0.181478</td>\n",
       "      <td>1.634437</td>\n",
       "      <td>0.904620</td>\n",
       "      <td>-0.424192</td>\n",
       "      <td>-0.452936</td>\n",
       "      <td>1.123414</td>\n",
       "      <td>0.534554</td>\n",
       "      <td>-0.380039</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.489450</td>\n",
       "      <td>-1.448590</td>\n",
       "      <td>2.194570</td>\n",
       "      <td>1.262672</td>\n",
       "      <td>0.504028</td>\n",
       "      <td>0.395338</td>\n",
       "      <td>-1.072729</td>\n",
       "      <td>0.879836</td>\n",
       "      <td>-1.542415</td>\n",
       "      <td>-0.938513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.231095</td>\n",
       "      <td>-0.209571</td>\n",
       "      <td>1.654951</td>\n",
       "      <td>1.247081</td>\n",
       "      <td>-0.652624</td>\n",
       "      <td>-0.546311</td>\n",
       "      <td>1.214370</td>\n",
       "      <td>0.821624</td>\n",
       "      <td>-0.502463</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.353433</td>\n",
       "      <td>-1.059878</td>\n",
       "      <td>2.589134</td>\n",
       "      <td>2.139926</td>\n",
       "      <td>0.593317</td>\n",
       "      <td>0.682023</td>\n",
       "      <td>-0.643181</td>\n",
       "      <td>-0.217332</td>\n",
       "      <td>0.945816</td>\n",
       "      <td>0.145041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.236090</td>\n",
       "      <td>-0.323013</td>\n",
       "      <td>-0.478244</td>\n",
       "      <td>-1.080788</td>\n",
       "      <td>-0.670161</td>\n",
       "      <td>-0.923364</td>\n",
       "      <td>-0.421866</td>\n",
       "      <td>-0.775114</td>\n",
       "      <td>-0.511862</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.443846</td>\n",
       "      <td>-0.627980</td>\n",
       "      <td>2.326862</td>\n",
       "      <td>3.114644</td>\n",
       "      <td>0.533965</td>\n",
       "      <td>1.000560</td>\n",
       "      <td>-0.323098</td>\n",
       "      <td>0.712401</td>\n",
       "      <td>-1.473404</td>\n",
       "      <td>-0.642872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5820 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  EDA_TonicMean_version02  EDA_TonicMean_version03  \\\n",
       "0   5                -0.123031                -0.226077   \n",
       "1   5                -0.152896                -0.050866   \n",
       "2   5                -0.166035                -0.181478   \n",
       "3   5                -0.231095                -0.209571   \n",
       "4   5                -0.236090                -0.323013   \n",
       "\n",
       "   EDA_TonicMean_version04  EDA_TonicMean_version05  EDA_TonicMean_version09  \\\n",
       "0                -1.220480                -1.697738                -0.273200   \n",
       "1                 1.527067                 1.883468                -0.378060   \n",
       "2                 1.634437                 0.904620                -0.424192   \n",
       "3                 1.654951                 1.247081                -0.652624   \n",
       "4                -0.478244                -1.080788                -0.670161   \n",
       "\n",
       "   EDA_TonicMean_version10  EDA_TonicMean_version11  EDA_TonicMean_version12  \\\n",
       "0                -0.601171                -0.809518                -1.012558   \n",
       "1                -0.018812                 1.023216                 1.189124   \n",
       "2                -0.452936                 1.123414                 0.534554   \n",
       "3                -0.546311                 1.214370                 0.821624   \n",
       "4                -0.923364                -0.421866                -0.775114   \n",
       "\n",
       "   EDA_TonicMean_version16  ...  EEG_avgRelTheta_version16  \\\n",
       "0                -0.299118  ...                  -1.877017   \n",
       "1                -0.355315  ...                  -1.632698   \n",
       "2                -0.380039  ...                  -1.489450   \n",
       "3                -0.502463  ...                  -1.353433   \n",
       "4                -0.511862  ...                  -1.443846   \n",
       "\n",
       "   EEG_avgRelTheta_version17  EEG_avgRelTheta_version19  \\\n",
       "0                  -1.442056                   1.070298   \n",
       "1                  -1.531970                   1.779032   \n",
       "2                  -1.448590                   2.194570   \n",
       "3                  -1.059878                   2.589134   \n",
       "4                  -0.627980                   2.326862   \n",
       "\n",
       "   EEG_avgRelTheta_version20  EEG_avgRelTheta_version22  \\\n",
       "0                   1.277417                   0.249605   \n",
       "1                   1.074498                   0.409991   \n",
       "2                   1.262672                   0.504028   \n",
       "3                   2.139926                   0.593317   \n",
       "4                   3.114644                   0.533965   \n",
       "\n",
       "   EEG_avgRelTheta_version23    adjSA1    adjSA2    adjSA3  adjSAtotal  \n",
       "0                   0.400156  0.119790  1.593122 -0.800726    0.350233  \n",
       "1                   0.333842  0.075246 -1.663383  0.859309   -0.262893  \n",
       "2                   0.395338 -1.072729  0.879836 -1.542415   -0.938513  \n",
       "3                   0.682023 -0.643181 -0.217332  0.945816    0.145041  \n",
       "4                   1.000560 -0.323098  0.712401 -1.473404   -0.642872  \n",
       "\n",
       "[5 rows x 5820 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"./kieranFeatures_1-30_26-Sep-2024.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling Values of All Non-Selected Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide up dataframe into predictors and outcomes. Train-test-split the following data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column for the calculated synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Function to calculate synthetic outcome values\n",
    "def func_val_bin(predictors):\n",
    "    \"\"\"\n",
    "        Creates a function out of five variables in the predictors dataframe\n",
    "        and outputs a boolean Pandas series where True means the function value\n",
    "        was greater than or equal to the median and False otherwise.\n",
    "\n",
    "        Parameters:\n",
    "            predictors (Dataframe): pandas Dataframe containing all predictor features\n",
    "\n",
    "        Output:\n",
    "            (Series): pandas Series containing True and False values where True means that\n",
    "                      the calculated value was above the median and False otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize array to store continuous values of function\n",
    "    func_calcs = np.array([])\n",
    "\n",
    "    # Get random coefficients and features\n",
    "    random.seed(42)\n",
    "    coefficients = np.array([round(random.uniform(-5, 5), 1) for _ in range(5)])\n",
    "    selected_features = np.array(random.sample(list(predictors.columns), 5))\n",
    "\n",
    "    print(\"Function = 1/(1+e^{-(\" + \n",
    "            f\"{coefficients[0]} * {selected_features[0]} + \" +\n",
    "            f\"{coefficients[1]} * {selected_features[1]} + \" +\n",
    "            f\"{coefficients[2]} * {selected_features[2]} + \" +\n",
    "            f\"{coefficients[3]} * {selected_features[3]} + \" +\n",
    "            f\"{coefficients[4]} * {selected_features[4]}\" + \n",
    "            \")})\")\n",
    "    \n",
    "    for index, row in predictors.iterrows():\n",
    "        # Add new calculation to func_calcs\n",
    "        func_calcs = np.append(func_calcs, 1/(1+np.e**(-(coefficients[0] * row[selected_features[0]] +\n",
    "                                              coefficients[1] * row[selected_features[1]] +\n",
    "                                              coefficients[2] * row[selected_features[2]] +\n",
    "                                              coefficients[3] * row[selected_features[3]] +\n",
    "                                              coefficients[4] * row[selected_features[4]]))))\n",
    "\n",
    "    return pd.Series(data = (func_calcs >= 0.5).astype(int)), selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function = 1/(1+e^{-(1.4 * fNIRS_S8D6_hbr_timeToMax_version12 + -4.7 * fNIRS_S6D6_hbr_kurtosis_version17 + -2.2 * EEG_p100_poz_version11 + -2.8 * fNIRS_S7D5_hbo_kurtosis_version03 + 2.4 * fNIRS_S5D3_hbr_kurtosis_version11)})\n"
     ]
    }
   ],
   "source": [
    "# Create the outcome feature\n",
    "synthetic_vals, selected_features = func_val_bin(df)\n",
    "df[\"synthetic_outcome\"] = synthetic_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDA_TonicMean_version02</th>\n",
       "      <th>EDA_TonicMean_version03</th>\n",
       "      <th>EDA_TonicMean_version04</th>\n",
       "      <th>EDA_TonicMean_version05</th>\n",
       "      <th>EDA_TonicMean_version09</th>\n",
       "      <th>EDA_TonicMean_version10</th>\n",
       "      <th>EDA_TonicMean_version11</th>\n",
       "      <th>EDA_TonicMean_version12</th>\n",
       "      <th>EDA_TonicMean_version16</th>\n",
       "      <th>EDA_TonicMean_version17</th>\n",
       "      <th>...</th>\n",
       "      <th>EEG_avgRelTheta_version09</th>\n",
       "      <th>EEG_avgRelTheta_version10</th>\n",
       "      <th>EEG_avgRelTheta_version11</th>\n",
       "      <th>EEG_avgRelTheta_version12</th>\n",
       "      <th>EEG_avgRelTheta_version16</th>\n",
       "      <th>EEG_avgRelTheta_version17</th>\n",
       "      <th>EEG_avgRelTheta_version19</th>\n",
       "      <th>EEG_avgRelTheta_version20</th>\n",
       "      <th>EEG_avgRelTheta_version22</th>\n",
       "      <th>EEG_avgRelTheta_version23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012822</td>\n",
       "      <td>-0.416788</td>\n",
       "      <td>-0.704162</td>\n",
       "      <td>0.016441</td>\n",
       "      <td>-0.365210</td>\n",
       "      <td>0.453263</td>\n",
       "      <td>0.126973</td>\n",
       "      <td>-0.237457</td>\n",
       "      <td>-0.103915</td>\n",
       "      <td>-0.533249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140859</td>\n",
       "      <td>0.552955</td>\n",
       "      <td>0.278096</td>\n",
       "      <td>0.676488</td>\n",
       "      <td>-0.320605</td>\n",
       "      <td>1.189590</td>\n",
       "      <td>-0.312717</td>\n",
       "      <td>-0.505705</td>\n",
       "      <td>1.864835</td>\n",
       "      <td>-0.628527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.007689</td>\n",
       "      <td>3.483298</td>\n",
       "      <td>-0.216242</td>\n",
       "      <td>1.693930</td>\n",
       "      <td>-0.004899</td>\n",
       "      <td>-0.328826</td>\n",
       "      <td>-0.612785</td>\n",
       "      <td>-0.473730</td>\n",
       "      <td>-0.166883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.355901</td>\n",
       "      <td>1.254154</td>\n",
       "      <td>-0.015860</td>\n",
       "      <td>-0.582439</td>\n",
       "      <td>-0.590692</td>\n",
       "      <td>-1.629689</td>\n",
       "      <td>0.271118</td>\n",
       "      <td>2.585835</td>\n",
       "      <td>-1.346976</td>\n",
       "      <td>0.381893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.739434</td>\n",
       "      <td>-0.501785</td>\n",
       "      <td>1.011080</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>-0.449432</td>\n",
       "      <td>0.984819</td>\n",
       "      <td>0.284838</td>\n",
       "      <td>-0.149024</td>\n",
       "      <td>-0.558297</td>\n",
       "      <td>-0.097964</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.236782</td>\n",
       "      <td>0.167538</td>\n",
       "      <td>-0.927555</td>\n",
       "      <td>0.346639</td>\n",
       "      <td>-0.002149</td>\n",
       "      <td>-0.173218</td>\n",
       "      <td>0.105745</td>\n",
       "      <td>0.094431</td>\n",
       "      <td>-0.599893</td>\n",
       "      <td>-0.212018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.354384</td>\n",
       "      <td>3.658397</td>\n",
       "      <td>-0.328634</td>\n",
       "      <td>-0.866528</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>1.331609</td>\n",
       "      <td>0.593198</td>\n",
       "      <td>-0.990292</td>\n",
       "      <td>-0.161187</td>\n",
       "      <td>-0.315683</td>\n",
       "      <td>...</td>\n",
       "      <td>1.063605</td>\n",
       "      <td>-3.053046</td>\n",
       "      <td>1.224810</td>\n",
       "      <td>-0.744128</td>\n",
       "      <td>-0.307295</td>\n",
       "      <td>0.234313</td>\n",
       "      <td>-3.332147</td>\n",
       "      <td>-2.522525</td>\n",
       "      <td>-0.854538</td>\n",
       "      <td>0.200101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.733113</td>\n",
       "      <td>0.586161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.437125</td>\n",
       "      <td>-1.407872</td>\n",
       "      <td>0.054983</td>\n",
       "      <td>-0.048732</td>\n",
       "      <td>-0.811792</td>\n",
       "      <td>0.418093</td>\n",
       "      <td>-0.530534</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.231899</td>\n",
       "      <td>0.410830</td>\n",
       "      <td>-0.529614</td>\n",
       "      <td>-0.145746</td>\n",
       "      <td>0.249210</td>\n",
       "      <td>-0.487681</td>\n",
       "      <td>0.345635</td>\n",
       "      <td>0.798785</td>\n",
       "      <td>0.532665</td>\n",
       "      <td>0.967764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>-0.598078</td>\n",
       "      <td>-0.390531</td>\n",
       "      <td>-0.450103</td>\n",
       "      <td>-1.017841</td>\n",
       "      <td>1.233320</td>\n",
       "      <td>3.522785</td>\n",
       "      <td>-0.560103</td>\n",
       "      <td>-0.126197</td>\n",
       "      <td>-0.289149</td>\n",
       "      <td>-0.152899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288472</td>\n",
       "      <td>1.827563</td>\n",
       "      <td>1.572345</td>\n",
       "      <td>0.435968</td>\n",
       "      <td>0.872790</td>\n",
       "      <td>0.674919</td>\n",
       "      <td>-0.649638</td>\n",
       "      <td>-0.374913</td>\n",
       "      <td>0.269036</td>\n",
       "      <td>0.551399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.224112</td>\n",
       "      <td>0.543684</td>\n",
       "      <td>0.884390</td>\n",
       "      <td>0.198192</td>\n",
       "      <td>-0.500100</td>\n",
       "      <td>-0.300991</td>\n",
       "      <td>-0.027186</td>\n",
       "      <td>0.129104</td>\n",
       "      <td>-0.254102</td>\n",
       "      <td>-0.382328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983117</td>\n",
       "      <td>0.160554</td>\n",
       "      <td>-1.047351</td>\n",
       "      <td>1.053314</td>\n",
       "      <td>-0.539889</td>\n",
       "      <td>-1.405018</td>\n",
       "      <td>0.061110</td>\n",
       "      <td>0.552190</td>\n",
       "      <td>-0.334424</td>\n",
       "      <td>1.902183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-0.054260</td>\n",
       "      <td>-0.197166</td>\n",
       "      <td>-0.621228</td>\n",
       "      <td>-0.515195</td>\n",
       "      <td>0.045195</td>\n",
       "      <td>-1.211518</td>\n",
       "      <td>-0.306500</td>\n",
       "      <td>0.018082</td>\n",
       "      <td>0.209721</td>\n",
       "      <td>-0.199617</td>\n",
       "      <td>...</td>\n",
       "      <td>1.039271</td>\n",
       "      <td>-0.133419</td>\n",
       "      <td>0.030269</td>\n",
       "      <td>-0.555496</td>\n",
       "      <td>0.169580</td>\n",
       "      <td>0.816828</td>\n",
       "      <td>-1.230679</td>\n",
       "      <td>-0.463581</td>\n",
       "      <td>-0.045654</td>\n",
       "      <td>-1.598365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-0.040642</td>\n",
       "      <td>-0.282184</td>\n",
       "      <td>-0.100554</td>\n",
       "      <td>-0.466908</td>\n",
       "      <td>2.704038</td>\n",
       "      <td>0.215096</td>\n",
       "      <td>0.490540</td>\n",
       "      <td>0.180223</td>\n",
       "      <td>1.201976</td>\n",
       "      <td>0.194834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975978</td>\n",
       "      <td>0.237272</td>\n",
       "      <td>0.673080</td>\n",
       "      <td>-0.495113</td>\n",
       "      <td>0.997935</td>\n",
       "      <td>0.018829</td>\n",
       "      <td>0.080233</td>\n",
       "      <td>-1.281584</td>\n",
       "      <td>0.701455</td>\n",
       "      <td>-0.375448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.478040</td>\n",
       "      <td>-0.419721</td>\n",
       "      <td>-0.068644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.093066</td>\n",
       "      <td>0.085939</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>-0.266370</td>\n",
       "      <td>-0.297686</td>\n",
       "      <td>-0.038083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.386655</td>\n",
       "      <td>0.075227</td>\n",
       "      <td>-0.792842</td>\n",
       "      <td>-1.070733</td>\n",
       "      <td>-1.034137</td>\n",
       "      <td>1.397330</td>\n",
       "      <td>1.623671</td>\n",
       "      <td>0.977044</td>\n",
       "      <td>0.249605</td>\n",
       "      <td>-0.683299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows Ã— 5815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EDA_TonicMean_version02  EDA_TonicMean_version03  \\\n",
       "0                   0.012822                -0.416788   \n",
       "1                  -0.007689                 3.483298   \n",
       "2                  -0.739434                -0.501785   \n",
       "3                  -0.354384                 3.658397   \n",
       "4                  -0.733113                 0.586161   \n",
       "..                       ...                      ...   \n",
       "299                -0.598078                -0.390531   \n",
       "300                 0.224112                 0.543684   \n",
       "301                -0.054260                -0.197166   \n",
       "302                -0.040642                -0.282184   \n",
       "303                 0.478040                -0.419721   \n",
       "\n",
       "     EDA_TonicMean_version04  EDA_TonicMean_version05  \\\n",
       "0                  -0.704162                 0.016441   \n",
       "1                  -0.216242                 1.693930   \n",
       "2                   1.011080                 0.009381   \n",
       "3                  -0.328634                -0.866528   \n",
       "4                   0.000000                -0.437125   \n",
       "..                       ...                      ...   \n",
       "299                -0.450103                -1.017841   \n",
       "300                 0.884390                 0.198192   \n",
       "301                -0.621228                -0.515195   \n",
       "302                -0.100554                -0.466908   \n",
       "303                -0.068644                 0.000000   \n",
       "\n",
       "     EDA_TonicMean_version09  EDA_TonicMean_version10  \\\n",
       "0                  -0.365210                 0.453263   \n",
       "1                  -0.004899                -0.328826   \n",
       "2                  -0.449432                 0.984819   \n",
       "3                  -0.004807                 1.331609   \n",
       "4                  -1.407872                 0.054983   \n",
       "..                       ...                      ...   \n",
       "299                 1.233320                 3.522785   \n",
       "300                -0.500100                -0.300991   \n",
       "301                 0.045195                -1.211518   \n",
       "302                 2.704038                 0.215096   \n",
       "303                -0.093066                 0.085939   \n",
       "\n",
       "     EDA_TonicMean_version11  EDA_TonicMean_version12  \\\n",
       "0                   0.126973                -0.237457   \n",
       "1                  -0.612785                -0.473730   \n",
       "2                   0.284838                -0.149024   \n",
       "3                   0.593198                -0.990292   \n",
       "4                  -0.048732                -0.811792   \n",
       "..                       ...                      ...   \n",
       "299                -0.560103                -0.126197   \n",
       "300                -0.027186                 0.129104   \n",
       "301                -0.306500                 0.018082   \n",
       "302                 0.490540                 0.180223   \n",
       "303                 0.069300                -0.266370   \n",
       "\n",
       "     EDA_TonicMean_version16  EDA_TonicMean_version17  ...  \\\n",
       "0                  -0.103915                -0.533249  ...   \n",
       "1                  -0.166883                 0.000000  ...   \n",
       "2                  -0.558297                -0.097964  ...   \n",
       "3                  -0.161187                -0.315683  ...   \n",
       "4                   0.418093                -0.530534  ...   \n",
       "..                       ...                      ...  ...   \n",
       "299                -0.289149                -0.152899  ...   \n",
       "300                -0.254102                -0.382328  ...   \n",
       "301                 0.209721                -0.199617  ...   \n",
       "302                 1.201976                 0.194834  ...   \n",
       "303                -0.297686                -0.038083  ...   \n",
       "\n",
       "     EEG_avgRelTheta_version09  EEG_avgRelTheta_version10  \\\n",
       "0                    -0.140859                   0.552955   \n",
       "1                    -0.355901                   1.254154   \n",
       "2                    -2.236782                   0.167538   \n",
       "3                     1.063605                  -3.053046   \n",
       "4                    -1.231899                   0.410830   \n",
       "..                         ...                        ...   \n",
       "299                  -0.288472                   1.827563   \n",
       "300                   0.983117                   0.160554   \n",
       "301                   1.039271                  -0.133419   \n",
       "302                   0.975978                   0.237272   \n",
       "303                  -0.386655                   0.075227   \n",
       "\n",
       "     EEG_avgRelTheta_version11  EEG_avgRelTheta_version12  \\\n",
       "0                     0.278096                   0.676488   \n",
       "1                    -0.015860                  -0.582439   \n",
       "2                    -0.927555                   0.346639   \n",
       "3                     1.224810                  -0.744128   \n",
       "4                    -0.529614                  -0.145746   \n",
       "..                         ...                        ...   \n",
       "299                   1.572345                   0.435968   \n",
       "300                  -1.047351                   1.053314   \n",
       "301                   0.030269                  -0.555496   \n",
       "302                   0.673080                  -0.495113   \n",
       "303                  -0.792842                  -1.070733   \n",
       "\n",
       "     EEG_avgRelTheta_version16  EEG_avgRelTheta_version17  \\\n",
       "0                    -0.320605                   1.189590   \n",
       "1                    -0.590692                  -1.629689   \n",
       "2                    -0.002149                  -0.173218   \n",
       "3                    -0.307295                   0.234313   \n",
       "4                     0.249210                  -0.487681   \n",
       "..                         ...                        ...   \n",
       "299                   0.872790                   0.674919   \n",
       "300                  -0.539889                  -1.405018   \n",
       "301                   0.169580                   0.816828   \n",
       "302                   0.997935                   0.018829   \n",
       "303                  -1.034137                   1.397330   \n",
       "\n",
       "     EEG_avgRelTheta_version19  EEG_avgRelTheta_version20  \\\n",
       "0                    -0.312717                  -0.505705   \n",
       "1                     0.271118                   2.585835   \n",
       "2                     0.105745                   0.094431   \n",
       "3                    -3.332147                  -2.522525   \n",
       "4                     0.345635                   0.798785   \n",
       "..                         ...                        ...   \n",
       "299                  -0.649638                  -0.374913   \n",
       "300                   0.061110                   0.552190   \n",
       "301                  -1.230679                  -0.463581   \n",
       "302                   0.080233                  -1.281584   \n",
       "303                   1.623671                   0.977044   \n",
       "\n",
       "     EEG_avgRelTheta_version22  EEG_avgRelTheta_version23  \n",
       "0                     1.864835                  -0.628527  \n",
       "1                    -1.346976                   0.381893  \n",
       "2                    -0.599893                  -0.212018  \n",
       "3                    -0.854538                   0.200101  \n",
       "4                     0.532665                   0.967764  \n",
       "..                         ...                        ...  \n",
       "299                   0.269036                   0.551399  \n",
       "300                  -0.334424                   1.902183  \n",
       "301                  -0.045654                  -1.598365  \n",
       "302                   0.701455                  -0.375448  \n",
       "303                   0.249605                  -0.683299  \n",
       "\n",
       "[304 rows x 5815 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjSA1</th>\n",
       "      <th>adjSA2</th>\n",
       "      <th>adjSA3</th>\n",
       "      <th>adjSAtotal</th>\n",
       "      <th>synthetic_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.119790</td>\n",
       "      <td>1.593122</td>\n",
       "      <td>-0.800726</td>\n",
       "      <td>0.350233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.075246</td>\n",
       "      <td>-1.663383</td>\n",
       "      <td>0.859309</td>\n",
       "      <td>-0.262893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.072729</td>\n",
       "      <td>0.879836</td>\n",
       "      <td>-1.542415</td>\n",
       "      <td>-0.938513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.643181</td>\n",
       "      <td>-0.217332</td>\n",
       "      <td>0.945816</td>\n",
       "      <td>0.145041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.323098</td>\n",
       "      <td>0.712401</td>\n",
       "      <td>-1.473404</td>\n",
       "      <td>-0.642872</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.076099</td>\n",
       "      <td>1.105227</td>\n",
       "      <td>-0.609431</td>\n",
       "      <td>0.209332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-0.258249</td>\n",
       "      <td>-0.360422</td>\n",
       "      <td>0.778641</td>\n",
       "      <td>0.155357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.110240</td>\n",
       "      <td>0.092504</td>\n",
       "      <td>0.945232</td>\n",
       "      <td>0.627581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-1.105639</td>\n",
       "      <td>0.426616</td>\n",
       "      <td>0.328063</td>\n",
       "      <td>-0.108335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1.141504</td>\n",
       "      <td>1.452440</td>\n",
       "      <td>0.883889</td>\n",
       "      <td>1.694167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adjSA1    adjSA2    adjSA3  adjSAtotal  synthetic_outcome\n",
       "0    0.119790  1.593122 -0.800726    0.350233                  1\n",
       "1    0.075246 -1.663383  0.859309   -0.262893                  1\n",
       "2   -1.072729  0.879836 -1.542415   -0.938513                  1\n",
       "3   -0.643181 -0.217332  0.945816    0.145041                  1\n",
       "4   -0.323098  0.712401 -1.473404   -0.642872                  1\n",
       "..        ...       ...       ...         ...                ...\n",
       "299  0.076099  1.105227 -0.609431    0.209332                  0\n",
       "300 -0.258249 -0.360422  0.778641    0.155357                  1\n",
       "301  0.110240  0.092504  0.945232    0.627581                  1\n",
       "302 -1.105639  0.426616  0.328063   -0.108335                  1\n",
       "303  1.141504  1.452440  0.883889    1.694167                  0\n",
       "\n",
       "[304 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDA_TonicMean_version02</th>\n",
       "      <th>EDA_TonicMean_version03</th>\n",
       "      <th>EDA_TonicMean_version04</th>\n",
       "      <th>EDA_TonicMean_version05</th>\n",
       "      <th>EDA_TonicMean_version09</th>\n",
       "      <th>EDA_TonicMean_version10</th>\n",
       "      <th>EDA_TonicMean_version11</th>\n",
       "      <th>EDA_TonicMean_version12</th>\n",
       "      <th>EDA_TonicMean_version16</th>\n",
       "      <th>EDA_TonicMean_version17</th>\n",
       "      <th>...</th>\n",
       "      <th>EEG_avgRelTheta_version09</th>\n",
       "      <th>EEG_avgRelTheta_version10</th>\n",
       "      <th>EEG_avgRelTheta_version11</th>\n",
       "      <th>EEG_avgRelTheta_version12</th>\n",
       "      <th>EEG_avgRelTheta_version16</th>\n",
       "      <th>EEG_avgRelTheta_version17</th>\n",
       "      <th>EEG_avgRelTheta_version19</th>\n",
       "      <th>EEG_avgRelTheta_version20</th>\n",
       "      <th>EEG_avgRelTheta_version22</th>\n",
       "      <th>EEG_avgRelTheta_version23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>-0.004478</td>\n",
       "      <td>-0.296439</td>\n",
       "      <td>0.291263</td>\n",
       "      <td>-0.027784</td>\n",
       "      <td>-0.424192</td>\n",
       "      <td>0.044597</td>\n",
       "      <td>0.383287</td>\n",
       "      <td>-0.272376</td>\n",
       "      <td>-0.158862</td>\n",
       "      <td>-1.029447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410908</td>\n",
       "      <td>-0.306810</td>\n",
       "      <td>2.125386</td>\n",
       "      <td>1.223240</td>\n",
       "      <td>-0.461088</td>\n",
       "      <td>0.008128</td>\n",
       "      <td>-0.167925</td>\n",
       "      <td>0.925339</td>\n",
       "      <td>-1.076381</td>\n",
       "      <td>0.920460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>-0.779110</td>\n",
       "      <td>3.447829</td>\n",
       "      <td>0.333107</td>\n",
       "      <td>-0.320344</td>\n",
       "      <td>-1.396764</td>\n",
       "      <td>0.243619</td>\n",
       "      <td>0.195744</td>\n",
       "      <td>-0.029013</td>\n",
       "      <td>-0.282806</td>\n",
       "      <td>-0.268734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066389</td>\n",
       "      <td>0.271901</td>\n",
       "      <td>-0.187972</td>\n",
       "      <td>-0.061929</td>\n",
       "      <td>0.124738</td>\n",
       "      <td>3.146601</td>\n",
       "      <td>-0.661742</td>\n",
       "      <td>-3.840152</td>\n",
       "      <td>0.518098</td>\n",
       "      <td>0.516509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.063175</td>\n",
       "      <td>-0.351993</td>\n",
       "      <td>-0.366936</td>\n",
       "      <td>-0.914811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.308968</td>\n",
       "      <td>0.282758</td>\n",
       "      <td>-0.045087</td>\n",
       "      <td>-0.189088</td>\n",
       "      <td>-0.136151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260123</td>\n",
       "      <td>-0.333163</td>\n",
       "      <td>0.195292</td>\n",
       "      <td>-0.698929</td>\n",
       "      <td>0.507635</td>\n",
       "      <td>-0.431520</td>\n",
       "      <td>-0.587280</td>\n",
       "      <td>0.427443</td>\n",
       "      <td>0.572984</td>\n",
       "      <td>0.474066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.117180</td>\n",
       "      <td>1.039846</td>\n",
       "      <td>0.509620</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>-0.624705</td>\n",
       "      <td>0.103524</td>\n",
       "      <td>-0.236083</td>\n",
       "      <td>0.049359</td>\n",
       "      <td>0.389764</td>\n",
       "      <td>-0.361357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763694</td>\n",
       "      <td>-1.420337</td>\n",
       "      <td>1.030135</td>\n",
       "      <td>0.775843</td>\n",
       "      <td>0.007059</td>\n",
       "      <td>0.412261</td>\n",
       "      <td>-0.640743</td>\n",
       "      <td>-1.574889</td>\n",
       "      <td>-1.436534</td>\n",
       "      <td>-0.794811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-0.325386</td>\n",
       "      <td>-0.820564</td>\n",
       "      <td>0.581645</td>\n",
       "      <td>-0.563344</td>\n",
       "      <td>-1.119621</td>\n",
       "      <td>-3.171786</td>\n",
       "      <td>-0.762099</td>\n",
       "      <td>-1.012558</td>\n",
       "      <td>-0.054422</td>\n",
       "      <td>-0.409463</td>\n",
       "      <td>...</td>\n",
       "      <td>1.139064</td>\n",
       "      <td>0.385377</td>\n",
       "      <td>0.813855</td>\n",
       "      <td>-0.379276</td>\n",
       "      <td>0.118412</td>\n",
       "      <td>-0.251355</td>\n",
       "      <td>-1.110239</td>\n",
       "      <td>-0.113208</td>\n",
       "      <td>0.275224</td>\n",
       "      <td>-0.282644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.834268</td>\n",
       "      <td>-0.385206</td>\n",
       "      <td>-0.125706</td>\n",
       "      <td>-0.397122</td>\n",
       "      <td>0.029509</td>\n",
       "      <td>-0.025531</td>\n",
       "      <td>1.096324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012802</td>\n",
       "      <td>-0.545149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962391</td>\n",
       "      <td>-0.306750</td>\n",
       "      <td>-0.418917</td>\n",
       "      <td>-0.047756</td>\n",
       "      <td>0.967351</td>\n",
       "      <td>-0.576016</td>\n",
       "      <td>-0.823747</td>\n",
       "      <td>0.739829</td>\n",
       "      <td>0.674976</td>\n",
       "      <td>0.989332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.171929</td>\n",
       "      <td>0.026153</td>\n",
       "      <td>-1.537252</td>\n",
       "      <td>-0.573580</td>\n",
       "      <td>0.311933</td>\n",
       "      <td>1.419516</td>\n",
       "      <td>-0.930341</td>\n",
       "      <td>0.130450</td>\n",
       "      <td>-1.806372</td>\n",
       "      <td>-0.661295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755186</td>\n",
       "      <td>0.547954</td>\n",
       "      <td>-0.583691</td>\n",
       "      <td>0.208789</td>\n",
       "      <td>-0.042654</td>\n",
       "      <td>0.074185</td>\n",
       "      <td>-1.201410</td>\n",
       "      <td>0.079871</td>\n",
       "      <td>1.774917</td>\n",
       "      <td>0.097127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.312612</td>\n",
       "      <td>-0.730176</td>\n",
       "      <td>1.499590</td>\n",
       "      <td>-0.694283</td>\n",
       "      <td>-0.105819</td>\n",
       "      <td>0.581651</td>\n",
       "      <td>-0.654169</td>\n",
       "      <td>-0.481057</td>\n",
       "      <td>-0.171312</td>\n",
       "      <td>0.587846</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.634937</td>\n",
       "      <td>1.129175</td>\n",
       "      <td>0.958044</td>\n",
       "      <td>0.355521</td>\n",
       "      <td>0.564511</td>\n",
       "      <td>-0.538994</td>\n",
       "      <td>2.023002</td>\n",
       "      <td>-3.085901</td>\n",
       "      <td>-0.796321</td>\n",
       "      <td>-0.420182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.755155</td>\n",
       "      <td>-0.392341</td>\n",
       "      <td>2.375815</td>\n",
       "      <td>0.309768</td>\n",
       "      <td>1.423450</td>\n",
       "      <td>-0.115324</td>\n",
       "      <td>-0.329798</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>-0.551082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639188</td>\n",
       "      <td>-1.264488</td>\n",
       "      <td>2.240786</td>\n",
       "      <td>-0.250041</td>\n",
       "      <td>-0.747182</td>\n",
       "      <td>-0.617142</td>\n",
       "      <td>-0.737785</td>\n",
       "      <td>3.748948</td>\n",
       "      <td>-0.497711</td>\n",
       "      <td>0.385244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.449824</td>\n",
       "      <td>-0.126156</td>\n",
       "      <td>-0.150550</td>\n",
       "      <td>0.158460</td>\n",
       "      <td>0.427894</td>\n",
       "      <td>0.347301</td>\n",
       "      <td>0.100168</td>\n",
       "      <td>-0.159546</td>\n",
       "      <td>-0.064850</td>\n",
       "      <td>0.286859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973121</td>\n",
       "      <td>-0.297233</td>\n",
       "      <td>-1.030958</td>\n",
       "      <td>-0.211552</td>\n",
       "      <td>0.203648</td>\n",
       "      <td>-0.803721</td>\n",
       "      <td>-0.037417</td>\n",
       "      <td>0.932104</td>\n",
       "      <td>-0.298577</td>\n",
       "      <td>0.398556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 5815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EDA_TonicMean_version02  EDA_TonicMean_version03  \\\n",
       "269                -0.004478                -0.296439   \n",
       "211                -0.779110                 3.447829   \n",
       "197                 0.063175                -0.351993   \n",
       "75                  0.117180                 1.039846   \n",
       "177                -0.325386                -0.820564   \n",
       "..                       ...                      ...   \n",
       "188                 0.834268                -0.385206   \n",
       "71                  0.171929                 0.026153   \n",
       "106                 0.312612                -0.730176   \n",
       "270                 0.000000                -0.755155   \n",
       "102                -0.449824                -0.126156   \n",
       "\n",
       "     EDA_TonicMean_version04  EDA_TonicMean_version05  \\\n",
       "269                 0.291263                -0.027784   \n",
       "211                 0.333107                -0.320344   \n",
       "197                -0.366936                -0.914811   \n",
       "75                  0.509620                 0.055600   \n",
       "177                 0.581645                -0.563344   \n",
       "..                       ...                      ...   \n",
       "188                -0.125706                -0.397122   \n",
       "71                 -1.537252                -0.573580   \n",
       "106                 1.499590                -0.694283   \n",
       "270                -0.392341                 2.375815   \n",
       "102                -0.150550                 0.158460   \n",
       "\n",
       "     EDA_TonicMean_version09  EDA_TonicMean_version10  \\\n",
       "269                -0.424192                 0.044597   \n",
       "211                -1.396764                 0.243619   \n",
       "197                 0.000000                 0.308968   \n",
       "75                 -0.624705                 0.103524   \n",
       "177                -1.119621                -3.171786   \n",
       "..                       ...                      ...   \n",
       "188                 0.029509                -0.025531   \n",
       "71                  0.311933                 1.419516   \n",
       "106                -0.105819                 0.581651   \n",
       "270                 0.309768                 1.423450   \n",
       "102                 0.427894                 0.347301   \n",
       "\n",
       "     EDA_TonicMean_version11  EDA_TonicMean_version12  \\\n",
       "269                 0.383287                -0.272376   \n",
       "211                 0.195744                -0.029013   \n",
       "197                 0.282758                -0.045087   \n",
       "75                 -0.236083                 0.049359   \n",
       "177                -0.762099                -1.012558   \n",
       "..                       ...                      ...   \n",
       "188                 1.096324                 0.000000   \n",
       "71                 -0.930341                 0.130450   \n",
       "106                -0.654169                -0.481057   \n",
       "270                -0.115324                -0.329798   \n",
       "102                 0.100168                -0.159546   \n",
       "\n",
       "     EDA_TonicMean_version16  EDA_TonicMean_version17  ...  \\\n",
       "269                -0.158862                -1.029447  ...   \n",
       "211                -0.282806                -0.268734  ...   \n",
       "197                -0.189088                -0.136151  ...   \n",
       "75                  0.389764                -0.361357  ...   \n",
       "177                -0.054422                -0.409463  ...   \n",
       "..                       ...                      ...  ...   \n",
       "188                -0.012802                -0.545149  ...   \n",
       "71                 -1.806372                -0.661295  ...   \n",
       "106                -0.171312                 0.587846  ...   \n",
       "270                 0.282408                -0.551082  ...   \n",
       "102                -0.064850                 0.286859  ...   \n",
       "\n",
       "     EEG_avgRelTheta_version09  EEG_avgRelTheta_version10  \\\n",
       "269                   0.410908                  -0.306810   \n",
       "211                  -0.066389                   0.271901   \n",
       "197                  -0.260123                  -0.333163   \n",
       "75                    0.763694                  -1.420337   \n",
       "177                   1.139064                   0.385377   \n",
       "..                         ...                        ...   \n",
       "188                   0.962391                  -0.306750   \n",
       "71                    0.755186                   0.547954   \n",
       "106                  -1.634937                   1.129175   \n",
       "270                   0.639188                  -1.264488   \n",
       "102                   0.973121                  -0.297233   \n",
       "\n",
       "     EEG_avgRelTheta_version11  EEG_avgRelTheta_version12  \\\n",
       "269                   2.125386                   1.223240   \n",
       "211                  -0.187972                  -0.061929   \n",
       "197                   0.195292                  -0.698929   \n",
       "75                    1.030135                   0.775843   \n",
       "177                   0.813855                  -0.379276   \n",
       "..                         ...                        ...   \n",
       "188                  -0.418917                  -0.047756   \n",
       "71                   -0.583691                   0.208789   \n",
       "106                   0.958044                   0.355521   \n",
       "270                   2.240786                  -0.250041   \n",
       "102                  -1.030958                  -0.211552   \n",
       "\n",
       "     EEG_avgRelTheta_version16  EEG_avgRelTheta_version17  \\\n",
       "269                  -0.461088                   0.008128   \n",
       "211                   0.124738                   3.146601   \n",
       "197                   0.507635                  -0.431520   \n",
       "75                    0.007059                   0.412261   \n",
       "177                   0.118412                  -0.251355   \n",
       "..                         ...                        ...   \n",
       "188                   0.967351                  -0.576016   \n",
       "71                   -0.042654                   0.074185   \n",
       "106                   0.564511                  -0.538994   \n",
       "270                  -0.747182                  -0.617142   \n",
       "102                   0.203648                  -0.803721   \n",
       "\n",
       "     EEG_avgRelTheta_version19  EEG_avgRelTheta_version20  \\\n",
       "269                  -0.167925                   0.925339   \n",
       "211                  -0.661742                  -3.840152   \n",
       "197                  -0.587280                   0.427443   \n",
       "75                   -0.640743                  -1.574889   \n",
       "177                  -1.110239                  -0.113208   \n",
       "..                         ...                        ...   \n",
       "188                  -0.823747                   0.739829   \n",
       "71                   -1.201410                   0.079871   \n",
       "106                   2.023002                  -3.085901   \n",
       "270                  -0.737785                   3.748948   \n",
       "102                  -0.037417                   0.932104   \n",
       "\n",
       "     EEG_avgRelTheta_version22  EEG_avgRelTheta_version23  \n",
       "269                  -1.076381                   0.920460  \n",
       "211                   0.518098                   0.516509  \n",
       "197                   0.572984                   0.474066  \n",
       "75                   -1.436534                  -0.794811  \n",
       "177                   0.275224                  -0.282644  \n",
       "..                         ...                        ...  \n",
       "188                   0.674976                   0.989332  \n",
       "71                    1.774917                   0.097127  \n",
       "106                  -0.796321                  -0.420182  \n",
       "270                  -0.497711                   0.385244  \n",
       "102                  -0.298577                   0.398556  \n",
       "\n",
       "[243 rows x 5815 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjSA1</th>\n",
       "      <th>adjSA2</th>\n",
       "      <th>adjSA3</th>\n",
       "      <th>adjSAtotal</th>\n",
       "      <th>synthetic_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.143670</td>\n",
       "      <td>1.101324</td>\n",
       "      <td>-0.822506</td>\n",
       "      <td>0.117187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>-0.783965</td>\n",
       "      <td>-0.834554</td>\n",
       "      <td>0.116317</td>\n",
       "      <td>-0.677632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.475912</td>\n",
       "      <td>-0.162414</td>\n",
       "      <td>1.180378</td>\n",
       "      <td>0.804260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.088596</td>\n",
       "      <td>0.229732</td>\n",
       "      <td>0.972713</td>\n",
       "      <td>0.618738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-1.146056</td>\n",
       "      <td>0.662741</td>\n",
       "      <td>-3.060939</td>\n",
       "      <td>-1.932524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.116062</td>\n",
       "      <td>0.313836</td>\n",
       "      <td>0.270247</td>\n",
       "      <td>0.799881</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.881938</td>\n",
       "      <td>0.311514</td>\n",
       "      <td>-0.739256</td>\n",
       "      <td>-0.666210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.900207</td>\n",
       "      <td>0.372292</td>\n",
       "      <td>-1.423042</td>\n",
       "      <td>-1.032613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-2.025591</td>\n",
       "      <td>0.753425</td>\n",
       "      <td>0.139548</td>\n",
       "      <td>-0.472791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.002411</td>\n",
       "      <td>-1.686081</td>\n",
       "      <td>0.460911</td>\n",
       "      <td>-0.533697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adjSA1    adjSA2    adjSA3  adjSAtotal  synthetic_outcome\n",
       "269  0.143670  1.101324 -0.822506    0.117187                  1\n",
       "211 -0.783965 -0.834554  0.116317   -0.677632                  0\n",
       "197  0.475912 -0.162414  1.180378    0.804260                  1\n",
       "75  -0.088596  0.229732  0.972713    0.618738                  0\n",
       "177 -1.146056  0.662741 -3.060939   -1.932524                  0\n",
       "..        ...       ...       ...         ...                ...\n",
       "188  1.116062  0.313836  0.270247    0.799881                  0\n",
       "71  -0.881938  0.311514 -0.739256   -0.666210                  1\n",
       "106 -0.900207  0.372292 -1.423042   -1.032613                  0\n",
       "270 -2.025591  0.753425  0.139548   -0.472791                  1\n",
       "102 -0.002411 -1.686081  0.460911   -0.533697                  1\n",
       "\n",
       "[243 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDA_TonicMean_version02</th>\n",
       "      <th>EDA_TonicMean_version03</th>\n",
       "      <th>EDA_TonicMean_version04</th>\n",
       "      <th>EDA_TonicMean_version05</th>\n",
       "      <th>EDA_TonicMean_version09</th>\n",
       "      <th>EDA_TonicMean_version10</th>\n",
       "      <th>EDA_TonicMean_version11</th>\n",
       "      <th>EDA_TonicMean_version12</th>\n",
       "      <th>EDA_TonicMean_version16</th>\n",
       "      <th>EDA_TonicMean_version17</th>\n",
       "      <th>...</th>\n",
       "      <th>EEG_avgRelTheta_version09</th>\n",
       "      <th>EEG_avgRelTheta_version10</th>\n",
       "      <th>EEG_avgRelTheta_version11</th>\n",
       "      <th>EEG_avgRelTheta_version12</th>\n",
       "      <th>EEG_avgRelTheta_version16</th>\n",
       "      <th>EEG_avgRelTheta_version17</th>\n",
       "      <th>EEG_avgRelTheta_version19</th>\n",
       "      <th>EEG_avgRelTheta_version20</th>\n",
       "      <th>EEG_avgRelTheta_version22</th>\n",
       "      <th>EEG_avgRelTheta_version23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007824</td>\n",
       "      <td>-0.312446</td>\n",
       "      <td>0.303162</td>\n",
       "      <td>-0.000712</td>\n",
       "      <td>-0.398739</td>\n",
       "      <td>0.024310</td>\n",
       "      <td>0.341945</td>\n",
       "      <td>-0.300662</td>\n",
       "      <td>-0.117506</td>\n",
       "      <td>-1.052965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414148</td>\n",
       "      <td>-0.334746</td>\n",
       "      <td>2.136799</td>\n",
       "      <td>1.131520</td>\n",
       "      <td>-0.470416</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>-0.181429</td>\n",
       "      <td>0.922585</td>\n",
       "      <td>-1.132090</td>\n",
       "      <td>0.928216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.815700</td>\n",
       "      <td>3.470203</td>\n",
       "      <td>0.343469</td>\n",
       "      <td>-0.300121</td>\n",
       "      <td>-1.335565</td>\n",
       "      <td>0.228192</td>\n",
       "      <td>0.160015</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>-0.251208</td>\n",
       "      <td>-0.231397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067867</td>\n",
       "      <td>0.272943</td>\n",
       "      <td>-0.146814</td>\n",
       "      <td>-0.090276</td>\n",
       "      <td>0.118196</td>\n",
       "      <td>3.058558</td>\n",
       "      <td>-0.664644</td>\n",
       "      <td>-3.733837</td>\n",
       "      <td>0.515541</td>\n",
       "      <td>0.514769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062731</td>\n",
       "      <td>-0.368570</td>\n",
       "      <td>-0.330851</td>\n",
       "      <td>-0.908504</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>0.295137</td>\n",
       "      <td>0.244424</td>\n",
       "      <td>-0.017102</td>\n",
       "      <td>-0.150111</td>\n",
       "      <td>-0.088207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263516</td>\n",
       "      <td>-0.362419</td>\n",
       "      <td>0.231522</td>\n",
       "      <td>-0.695866</td>\n",
       "      <td>0.502914</td>\n",
       "      <td>-0.423821</td>\n",
       "      <td>-0.591780</td>\n",
       "      <td>0.436085</td>\n",
       "      <td>0.572256</td>\n",
       "      <td>0.471328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119054</td>\n",
       "      <td>1.037536</td>\n",
       "      <td>0.513496</td>\n",
       "      <td>0.084624</td>\n",
       "      <td>-0.591882</td>\n",
       "      <td>0.084677</td>\n",
       "      <td>-0.258887</td>\n",
       "      <td>0.100726</td>\n",
       "      <td>0.474316</td>\n",
       "      <td>-0.331430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770423</td>\n",
       "      <td>-1.504030</td>\n",
       "      <td>1.055631</td>\n",
       "      <td>0.706185</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.397383</td>\n",
       "      <td>-0.644095</td>\n",
       "      <td>-1.520420</td>\n",
       "      <td>-1.504248</td>\n",
       "      <td>-0.827376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.342504</td>\n",
       "      <td>-0.841944</td>\n",
       "      <td>0.582874</td>\n",
       "      <td>-0.548810</td>\n",
       "      <td>-1.068608</td>\n",
       "      <td>-3.270620</td>\n",
       "      <td>-0.769161</td>\n",
       "      <td>-1.224092</td>\n",
       "      <td>-0.004843</td>\n",
       "      <td>-0.383384</td>\n",
       "      <td>...</td>\n",
       "      <td>1.149504</td>\n",
       "      <td>0.392101</td>\n",
       "      <td>0.842132</td>\n",
       "      <td>-0.391975</td>\n",
       "      <td>0.111840</td>\n",
       "      <td>-0.248476</td>\n",
       "      <td>-1.103511</td>\n",
       "      <td>-0.092192</td>\n",
       "      <td>0.264570</td>\n",
       "      <td>-0.303169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.866916</td>\n",
       "      <td>-0.402123</td>\n",
       "      <td>-0.098485</td>\n",
       "      <td>-0.378696</td>\n",
       "      <td>0.038287</td>\n",
       "      <td>-0.047530</td>\n",
       "      <td>1.033641</td>\n",
       "      <td>0.039147</td>\n",
       "      <td>0.040054</td>\n",
       "      <td>-0.529925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971084</td>\n",
       "      <td>-0.334683</td>\n",
       "      <td>-0.374789</td>\n",
       "      <td>-0.076802</td>\n",
       "      <td>0.964816</td>\n",
       "      <td>-0.564450</td>\n",
       "      <td>-0.823170</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.677648</td>\n",
       "      <td>0.998708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.176153</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>-1.458164</td>\n",
       "      <td>-0.559285</td>\n",
       "      <td>0.310331</td>\n",
       "      <td>1.432806</td>\n",
       "      <td>-0.932367</td>\n",
       "      <td>0.201893</td>\n",
       "      <td>-1.894731</td>\n",
       "      <td>-0.655362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761830</td>\n",
       "      <td>0.562819</td>\n",
       "      <td>-0.537444</td>\n",
       "      <td>0.167093</td>\n",
       "      <td>-0.049992</td>\n",
       "      <td>0.068353</td>\n",
       "      <td>-1.192724</td>\n",
       "      <td>0.096468</td>\n",
       "      <td>1.814255</td>\n",
       "      <td>0.085529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.322874</td>\n",
       "      <td>-0.750629</td>\n",
       "      <td>1.467089</td>\n",
       "      <td>-0.682814</td>\n",
       "      <td>-0.092067</td>\n",
       "      <td>0.574479</td>\n",
       "      <td>-0.664461</td>\n",
       "      <td>-0.561006</td>\n",
       "      <td>-0.130936</td>\n",
       "      <td>0.693708</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.651923</td>\n",
       "      <td>1.173143</td>\n",
       "      <td>0.984467</td>\n",
       "      <td>0.306589</td>\n",
       "      <td>0.560060</td>\n",
       "      <td>-0.528419</td>\n",
       "      <td>1.962458</td>\n",
       "      <td>-2.996849</td>\n",
       "      <td>-0.842694</td>\n",
       "      <td>-0.443940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-0.003154</td>\n",
       "      <td>-0.775865</td>\n",
       "      <td>-0.355323</td>\n",
       "      <td>2.459155</td>\n",
       "      <td>0.308246</td>\n",
       "      <td>1.436837</td>\n",
       "      <td>-0.141743</td>\n",
       "      <td>-0.372299</td>\n",
       "      <td>0.358507</td>\n",
       "      <td>-0.536333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644686</td>\n",
       "      <td>-1.340379</td>\n",
       "      <td>2.250714</td>\n",
       "      <td>-0.269113</td>\n",
       "      <td>-0.757870</td>\n",
       "      <td>-0.604476</td>\n",
       "      <td>-0.739053</td>\n",
       "      <td>3.681570</td>\n",
       "      <td>-0.534130</td>\n",
       "      <td>0.380419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>-0.472283</td>\n",
       "      <td>-0.140418</td>\n",
       "      <td>-0.122417</td>\n",
       "      <td>0.189892</td>\n",
       "      <td>0.422030</td>\n",
       "      <td>0.334407</td>\n",
       "      <td>0.067299</td>\n",
       "      <td>-0.159898</td>\n",
       "      <td>-0.016092</td>\n",
       "      <td>0.368643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981920</td>\n",
       "      <td>-0.324689</td>\n",
       "      <td>-0.978960</td>\n",
       "      <td>-0.232521</td>\n",
       "      <td>0.197482</td>\n",
       "      <td>-0.786062</td>\n",
       "      <td>-0.053723</td>\n",
       "      <td>0.929196</td>\n",
       "      <td>-0.328359</td>\n",
       "      <td>0.394043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 5815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EDA_TonicMean_version02  EDA_TonicMean_version03  \\\n",
       "0                  -0.007824                -0.312446   \n",
       "1                  -0.815700                 3.470203   \n",
       "2                   0.062731                -0.368570   \n",
       "3                   0.119054                 1.037536   \n",
       "4                  -0.342504                -0.841944   \n",
       "..                       ...                      ...   \n",
       "238                 0.866916                -0.402123   \n",
       "239                 0.176153                 0.013452   \n",
       "240                 0.322874                -0.750629   \n",
       "241                -0.003154                -0.775865   \n",
       "242                -0.472283                -0.140418   \n",
       "\n",
       "     EDA_TonicMean_version04  EDA_TonicMean_version05  \\\n",
       "0                   0.303162                -0.000712   \n",
       "1                   0.343469                -0.300121   \n",
       "2                  -0.330851                -0.908504   \n",
       "3                   0.513496                 0.084624   \n",
       "4                   0.582874                -0.548810   \n",
       "..                       ...                      ...   \n",
       "238                -0.098485                -0.378696   \n",
       "239                -1.458164                -0.559285   \n",
       "240                 1.467089                -0.682814   \n",
       "241                -0.355323                 2.459155   \n",
       "242                -0.122417                 0.189892   \n",
       "\n",
       "     EDA_TonicMean_version09  EDA_TonicMean_version10  \\\n",
       "0                  -0.398739                 0.024310   \n",
       "1                  -1.335565                 0.228192   \n",
       "2                   0.009863                 0.295137   \n",
       "3                  -0.591882                 0.084677   \n",
       "4                  -1.068608                -3.270620   \n",
       "..                       ...                      ...   \n",
       "238                 0.038287                -0.047530   \n",
       "239                 0.310331                 1.432806   \n",
       "240                -0.092067                 0.574479   \n",
       "241                 0.308246                 1.436837   \n",
       "242                 0.422030                 0.334407   \n",
       "\n",
       "     EDA_TonicMean_version11  EDA_TonicMean_version12  \\\n",
       "0                   0.341945                -0.300662   \n",
       "1                   0.160015                 0.002951   \n",
       "2                   0.244424                -0.017102   \n",
       "3                  -0.258887                 0.100726   \n",
       "4                  -0.769161                -1.224092   \n",
       "..                       ...                      ...   \n",
       "238                 1.033641                 0.039147   \n",
       "239                -0.932367                 0.201893   \n",
       "240                -0.664461                -0.561006   \n",
       "241                -0.141743                -0.372299   \n",
       "242                 0.067299                -0.159898   \n",
       "\n",
       "     EDA_TonicMean_version16  EDA_TonicMean_version17  ...  \\\n",
       "0                  -0.117506                -1.052965  ...   \n",
       "1                  -0.251208                -0.231397  ...   \n",
       "2                  -0.150111                -0.088207  ...   \n",
       "3                   0.474316                -0.331430  ...   \n",
       "4                  -0.004843                -0.383384  ...   \n",
       "..                       ...                      ...  ...   \n",
       "238                 0.040054                -0.529925  ...   \n",
       "239                -1.894731                -0.655362  ...   \n",
       "240                -0.130936                 0.693708  ...   \n",
       "241                 0.358507                -0.536333  ...   \n",
       "242                -0.016092                 0.368643  ...   \n",
       "\n",
       "     EEG_avgRelTheta_version09  EEG_avgRelTheta_version10  \\\n",
       "0                     0.414148                  -0.334746   \n",
       "1                    -0.067867                   0.272943   \n",
       "2                    -0.263516                  -0.362419   \n",
       "3                     0.770423                  -1.504030   \n",
       "4                     1.149504                   0.392101   \n",
       "..                         ...                        ...   \n",
       "238                   0.971084                  -0.334683   \n",
       "239                   0.761830                   0.562819   \n",
       "240                  -1.651923                   1.173143   \n",
       "241                   0.644686                  -1.340379   \n",
       "242                   0.981920                  -0.324689   \n",
       "\n",
       "     EEG_avgRelTheta_version11  EEG_avgRelTheta_version12  \\\n",
       "0                     2.136799                   1.131520   \n",
       "1                    -0.146814                  -0.090276   \n",
       "2                     0.231522                  -0.695866   \n",
       "3                     1.055631                   0.706185   \n",
       "4                     0.842132                  -0.391975   \n",
       "..                         ...                        ...   \n",
       "238                  -0.374789                  -0.076802   \n",
       "239                  -0.537444                   0.167093   \n",
       "240                   0.984467                   0.306589   \n",
       "241                   2.250714                  -0.269113   \n",
       "242                  -0.978960                  -0.232521   \n",
       "\n",
       "     EEG_avgRelTheta_version16  EEG_avgRelTheta_version17  \\\n",
       "0                    -0.470416                   0.004063   \n",
       "1                     0.118196                   3.058558   \n",
       "2                     0.502914                  -0.423821   \n",
       "3                    -0.000043                   0.397383   \n",
       "4                     0.111840                  -0.248476   \n",
       "..                         ...                        ...   \n",
       "238                   0.964816                  -0.564450   \n",
       "239                  -0.049992                   0.068353   \n",
       "240                   0.560060                  -0.528419   \n",
       "241                  -0.757870                  -0.604476   \n",
       "242                   0.197482                  -0.786062   \n",
       "\n",
       "     EEG_avgRelTheta_version19  EEG_avgRelTheta_version20  \\\n",
       "0                    -0.181429                   0.922585   \n",
       "1                    -0.664644                  -3.733837   \n",
       "2                    -0.591780                   0.436085   \n",
       "3                    -0.644095                  -1.520420   \n",
       "4                    -1.103511                  -0.092192   \n",
       "..                         ...                        ...   \n",
       "238                  -0.823170                   0.741321   \n",
       "239                  -1.192724                   0.096468   \n",
       "240                   1.962458                  -2.996849   \n",
       "241                  -0.739053                   3.681570   \n",
       "242                  -0.053723                   0.929196   \n",
       "\n",
       "     EEG_avgRelTheta_version22  EEG_avgRelTheta_version23  \n",
       "0                    -1.132090                   0.928216  \n",
       "1                     0.515541                   0.514769  \n",
       "2                     0.572256                   0.471328  \n",
       "3                    -1.504248                  -0.827376  \n",
       "4                     0.264570                  -0.303169  \n",
       "..                         ...                        ...  \n",
       "238                   0.677648                   0.998708  \n",
       "239                   1.814255                   0.085529  \n",
       "240                  -0.842694                  -0.443940  \n",
       "241                  -0.534130                   0.380419  \n",
       "242                  -0.328359                   0.394043  \n",
       "\n",
       "[243 rows x 5815 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjSA1</th>\n",
       "      <th>adjSA2</th>\n",
       "      <th>adjSA3</th>\n",
       "      <th>adjSAtotal</th>\n",
       "      <th>synthetic_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.143670</td>\n",
       "      <td>1.101324</td>\n",
       "      <td>-0.822506</td>\n",
       "      <td>0.117187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>-0.783965</td>\n",
       "      <td>-0.834554</td>\n",
       "      <td>0.116317</td>\n",
       "      <td>-0.677632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.475912</td>\n",
       "      <td>-0.162414</td>\n",
       "      <td>1.180378</td>\n",
       "      <td>0.804260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.088596</td>\n",
       "      <td>0.229732</td>\n",
       "      <td>0.972713</td>\n",
       "      <td>0.618738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-1.146056</td>\n",
       "      <td>0.662741</td>\n",
       "      <td>-3.060939</td>\n",
       "      <td>-1.932524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.116062</td>\n",
       "      <td>0.313836</td>\n",
       "      <td>0.270247</td>\n",
       "      <td>0.799881</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.881938</td>\n",
       "      <td>0.311514</td>\n",
       "      <td>-0.739256</td>\n",
       "      <td>-0.666210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.900207</td>\n",
       "      <td>0.372292</td>\n",
       "      <td>-1.423042</td>\n",
       "      <td>-1.032613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-2.025591</td>\n",
       "      <td>0.753425</td>\n",
       "      <td>0.139548</td>\n",
       "      <td>-0.472791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.002411</td>\n",
       "      <td>-1.686081</td>\n",
       "      <td>0.460911</td>\n",
       "      <td>-0.533697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adjSA1    adjSA2    adjSA3  adjSAtotal  synthetic_outcome\n",
       "269  0.143670  1.101324 -0.822506    0.117187                  1\n",
       "211 -0.783965 -0.834554  0.116317   -0.677632                  0\n",
       "197  0.475912 -0.162414  1.180378    0.804260                  1\n",
       "75  -0.088596  0.229732  0.972713    0.618738                  0\n",
       "177 -1.146056  0.662741 -3.060939   -1.932524                  0\n",
       "..        ...       ...       ...         ...                ...\n",
       "188  1.116062  0.313836  0.270247    0.799881                  0\n",
       "71  -0.881938  0.311514 -0.739256   -0.666210                  1\n",
       "106 -0.900207  0.372292 -1.423042   -1.032613                  0\n",
       "270 -2.025591  0.753425  0.139548   -0.472791                  1\n",
       "102 -0.002411 -1.686081  0.460911   -0.533697                  1\n",
       "\n",
       "[243 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictors_df = df.iloc[:, 1:(df.shape[1] - 5)]\n",
    "outcomes_df = df.iloc[:, (df.shape[1] - 5):]\n",
    "\n",
    "# Randomize data in all non-selected feature columns\n",
    "for col in predictors_df.columns:\n",
    "    # Don't randomize selected features\n",
    "    if col in selected_features:\n",
    "        continue\n",
    "\n",
    "    predictors_df[col] = np.random.permutation(predictors_df[col].values)\n",
    "\n",
    "display(predictors_df)\n",
    "display(outcomes_df)\n",
    "\n",
    "# Split into train and test\n",
    "predictors_train, predictors_test, outcomes_train, outcomes_test = train_test_split(predictors_df, outcomes_df, test_size = 0.2, random_state = 42)\n",
    "\n",
    "display(predictors_train)\n",
    "display(outcomes_train)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "predictors_train = scaler.fit_transform(predictors_train)\n",
    "predictors_train = pd.DataFrame(predictors_train, columns = predictors_df.columns)\n",
    "predictors_test = scaler.transform(predictors_test)\n",
    "predictors_test = pd.DataFrame(predictors_test, columns = predictors_df.columns)\n",
    "\n",
    "display(predictors_train)\n",
    "\n",
    "# Free up memory\n",
    "del df\n",
    "del predictors_df\n",
    "del outcomes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_hyperparameters(model, predictors, outcome, params, eval_metric):\n",
    "    \"\"\"\n",
    "        Conducts GridSearchCV on a Logistic Regression model to identify suitable hyperparameters\n",
    "\n",
    "        Parameters:\n",
    "            model (sklearn Model): sklearn Model to conduct GridSearchCV on\n",
    "            predictors (Dataframe): pandas Dataframe containing all predictor features\n",
    "            outcome (Series): pandas Series containing all values for the outcome variable\n",
    "            params (dictionary): Dictionary of parameters for GridSearchCV for a LogisticRegression model\n",
    "            eval_metric (string): Name of evaluation metric to use for GridSearchCV\n",
    "\n",
    "        Return:\n",
    "            clf (GridSearchCV): GridSearchCV object after running GridSearchCV with provided parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Perform 5-fold cross-validation with different regularization strengths and regularization types\n",
    "    clf = GridSearchCV(model, params, cv = 5, scoring = eval_metric, n_jobs = -1)\n",
    "    clf.fit(predictors, outcome)\n",
    "\n",
    "    # Show the best regularization strength and penaalty type\n",
    "    print(\"Best regularization strength:\", clf.best_params_[\"C\"])\n",
    "    print(\"Best l1_ratio:\", clf.best_params_[\"l1_ratio\"])\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regularization strength: 0.1\n",
      "Best l1_ratio: 1\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"l1_ratio\": [0, 0.1, 0.5, 0.9, 1]\n",
    "}\n",
    "\n",
    "SA_func_Log_Reg = LogisticRegression(solver = \"saga\", penalty = \"elasticnet\", max_iter = 10000, fit_intercept = False)\n",
    "SA_GridSearchCV_func = select_hyperparameters(SA_func_Log_Reg, predictors_train, outcomes_train[\"synthetic_outcome\"], params, \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "0.8354591836734695\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(SA_GridSearchCV_func.best_estimator_.coef_ != 0))\n",
    "print(SA_GridSearchCV_func.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Actual Model with Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, fit_intercept=False, l1_ratio=1, max_iter=15000,\n",
       "                   n_jobs=-1, penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, fit_intercept=False, l1_ratio=1, max_iter=15000,\n",
       "                   n_jobs=-1, penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, fit_intercept=False, l1_ratio=1, max_iter=15000,\n",
       "                   n_jobs=-1, penalty='elasticnet', solver='saga')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_model_func = LogisticRegression(max_iter = 15000, penalty = \"elasticnet\", solver = \"saga\", C = 0.1, l1_ratio = 1, n_jobs = -1, fit_intercept = False)\n",
    "SA_model_func.fit(predictors_train, outcomes_train[\"synthetic_outcome\"])\n",
    "SA_model_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(66)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(SA_model_func.coef_ != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fNIRS_S8D6_hbr_timeToMax_version12</th>\n",
       "      <td>0.104446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S6D6_hbr_kurtosis_version17</th>\n",
       "      <td>-1.404350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_p100_poz_version11</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S7D5_hbo_kurtosis_version03</th>\n",
       "      <td>-0.980910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S5D3_hbr_kurtosis_version11</th>\n",
       "      <td>0.021495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    coefficients\n",
       "fNIRS_S8D6_hbr_timeToMax_version12      0.104446\n",
       "fNIRS_S6D6_hbr_kurtosis_version17      -1.404350\n",
       "EEG_p100_poz_version11                  0.000000\n",
       "fNIRS_S7D5_hbo_kurtosis_version03      -0.980910\n",
       "fNIRS_S5D3_hbr_kurtosis_version11       0.021495"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ECG_SDNN_version04</th>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EYE_BlinkRate_version12</th>\n",
       "      <td>0.034345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_avgRelFroAlpha_version09</th>\n",
       "      <td>0.017653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_avgRelOccDelta_version10</th>\n",
       "      <td>0.077428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_avgRelParDelta_version12</th>\n",
       "      <td>-0.045260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S8D6_hbr_slope_version03</th>\n",
       "      <td>0.014012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S8D6_hbr_MaxAmp_version23</th>\n",
       "      <td>-0.010613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S8D6_hbr_timeToMax_version12</th>\n",
       "      <td>0.104446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S8D7_hbo_area_version19</th>\n",
       "      <td>0.060378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S8D7_hbr_skew_version04</th>\n",
       "      <td>0.085112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    coefficients\n",
       "ECG_SDNN_version04                      0.000153\n",
       "EYE_BlinkRate_version12                 0.034345\n",
       "EEG_avgRelFroAlpha_version09            0.017653\n",
       "EEG_avgRelOccDelta_version10            0.077428\n",
       "EEG_avgRelParDelta_version12           -0.045260\n",
       "...                                          ...\n",
       "fNIRS_S8D6_hbr_slope_version03          0.014012\n",
       "fNIRS_S8D6_hbr_MaxAmp_version23        -0.010613\n",
       "fNIRS_S8D6_hbr_timeToMax_version12      0.104446\n",
       "fNIRS_S8D7_hbo_area_version19           0.060378\n",
       "fNIRS_S8D7_hbr_skew_version04           0.085112\n",
       "\n",
       "[66 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SA_model_func_coef = pd.DataFrame(\n",
    "    data = {\n",
    "        \"coefficients\": SA_model_func.coef_[0]\n",
    "    },\n",
    "    index = np.array(list(predictors_test.columns))\n",
    ")\n",
    "\n",
    "display(SA_model_func_coef.loc[selected_features, :])\n",
    "display(SA_model_func_coef[SA_model_func_coef[\"coefficients\"] != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metrics(model, predictors, outcome):\n",
    "    \"\"\"\n",
    "        Plots confusion matrix and ROC-AUC curve for a fitted sklearn model\n",
    "\n",
    "        Parameters:\n",
    "            model (sklearn Model): sklearn model to predict outcome values\n",
    "            predictors (DataFrame): pandas Dataframe containing all predictor features\n",
    "            outcome (Series): pandas Series containing all values for the outcome variable\n",
    "            display_labels (list(str)): List of 2 strings for labeling the 0 and 1 outputs for confusion matrix\n",
    "\n",
    "        Return:\n",
    "            None\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_outcomes = model.predict(predictors)\n",
    "    print(\"Accuracy: \", accuracy_score(predicted_outcomes, outcome))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = metrics.confusion_matrix(outcome, predicted_outcomes)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm)\n",
    "    cm_display.plot()\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(outcome, predicted_outcomes)\n",
    "    roc_auc  = metrics.auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, label = \"ROC Curve (area = %0.3f)\" % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], \"k--\") # Random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9672131147540983\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_eval_metrics(SA_model_func, predictors_test, outcomes_test[\"synthetic_outcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
