{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>EDA_TonicMean_version02</th>\n",
       "      <th>EDA_TonicMean_version03</th>\n",
       "      <th>EDA_TonicMean_version04</th>\n",
       "      <th>EDA_TonicMean_version05</th>\n",
       "      <th>EDA_TonicMean_version09</th>\n",
       "      <th>EDA_TonicMean_version10</th>\n",
       "      <th>EDA_TonicMean_version11</th>\n",
       "      <th>EDA_TonicMean_version12</th>\n",
       "      <th>EDA_TonicMean_version16</th>\n",
       "      <th>...</th>\n",
       "      <th>EEG_avgRelTheta_version16</th>\n",
       "      <th>EEG_avgRelTheta_version17</th>\n",
       "      <th>EEG_avgRelTheta_version19</th>\n",
       "      <th>EEG_avgRelTheta_version20</th>\n",
       "      <th>EEG_avgRelTheta_version22</th>\n",
       "      <th>EEG_avgRelTheta_version23</th>\n",
       "      <th>adjSA1</th>\n",
       "      <th>adjSA2</th>\n",
       "      <th>adjSA3</th>\n",
       "      <th>adjSAtotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.123031</td>\n",
       "      <td>-0.226077</td>\n",
       "      <td>-1.220480</td>\n",
       "      <td>-1.697738</td>\n",
       "      <td>-0.273200</td>\n",
       "      <td>-0.601171</td>\n",
       "      <td>-0.809518</td>\n",
       "      <td>-1.012558</td>\n",
       "      <td>-0.299118</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.877017</td>\n",
       "      <td>-1.442056</td>\n",
       "      <td>1.070298</td>\n",
       "      <td>1.277417</td>\n",
       "      <td>0.249605</td>\n",
       "      <td>0.400156</td>\n",
       "      <td>0.119790</td>\n",
       "      <td>1.593122</td>\n",
       "      <td>-0.800726</td>\n",
       "      <td>0.350233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.152896</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>1.527067</td>\n",
       "      <td>1.883468</td>\n",
       "      <td>-0.378060</td>\n",
       "      <td>-0.018812</td>\n",
       "      <td>1.023216</td>\n",
       "      <td>1.189124</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.632698</td>\n",
       "      <td>-1.531970</td>\n",
       "      <td>1.779032</td>\n",
       "      <td>1.074498</td>\n",
       "      <td>0.409991</td>\n",
       "      <td>0.333842</td>\n",
       "      <td>0.075246</td>\n",
       "      <td>-1.663383</td>\n",
       "      <td>0.859309</td>\n",
       "      <td>-0.262893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.166035</td>\n",
       "      <td>-0.181478</td>\n",
       "      <td>1.634437</td>\n",
       "      <td>0.904620</td>\n",
       "      <td>-0.424192</td>\n",
       "      <td>-0.452936</td>\n",
       "      <td>1.123414</td>\n",
       "      <td>0.534554</td>\n",
       "      <td>-0.380039</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.489450</td>\n",
       "      <td>-1.448590</td>\n",
       "      <td>2.194570</td>\n",
       "      <td>1.262672</td>\n",
       "      <td>0.504028</td>\n",
       "      <td>0.395338</td>\n",
       "      <td>-1.072729</td>\n",
       "      <td>0.879836</td>\n",
       "      <td>-1.542415</td>\n",
       "      <td>-0.938513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.231095</td>\n",
       "      <td>-0.209571</td>\n",
       "      <td>1.654951</td>\n",
       "      <td>1.247081</td>\n",
       "      <td>-0.652624</td>\n",
       "      <td>-0.546311</td>\n",
       "      <td>1.214370</td>\n",
       "      <td>0.821624</td>\n",
       "      <td>-0.502463</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.353433</td>\n",
       "      <td>-1.059878</td>\n",
       "      <td>2.589134</td>\n",
       "      <td>2.139926</td>\n",
       "      <td>0.593317</td>\n",
       "      <td>0.682023</td>\n",
       "      <td>-0.643181</td>\n",
       "      <td>-0.217332</td>\n",
       "      <td>0.945816</td>\n",
       "      <td>0.145041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.236090</td>\n",
       "      <td>-0.323013</td>\n",
       "      <td>-0.478244</td>\n",
       "      <td>-1.080788</td>\n",
       "      <td>-0.670161</td>\n",
       "      <td>-0.923364</td>\n",
       "      <td>-0.421866</td>\n",
       "      <td>-0.775114</td>\n",
       "      <td>-0.511862</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.443846</td>\n",
       "      <td>-0.627980</td>\n",
       "      <td>2.326862</td>\n",
       "      <td>3.114644</td>\n",
       "      <td>0.533965</td>\n",
       "      <td>1.000560</td>\n",
       "      <td>-0.323098</td>\n",
       "      <td>0.712401</td>\n",
       "      <td>-1.473404</td>\n",
       "      <td>-0.642872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5820 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  EDA_TonicMean_version02  EDA_TonicMean_version03  \\\n",
       "0   5                -0.123031                -0.226077   \n",
       "1   5                -0.152896                -0.050866   \n",
       "2   5                -0.166035                -0.181478   \n",
       "3   5                -0.231095                -0.209571   \n",
       "4   5                -0.236090                -0.323013   \n",
       "\n",
       "   EDA_TonicMean_version04  EDA_TonicMean_version05  EDA_TonicMean_version09  \\\n",
       "0                -1.220480                -1.697738                -0.273200   \n",
       "1                 1.527067                 1.883468                -0.378060   \n",
       "2                 1.634437                 0.904620                -0.424192   \n",
       "3                 1.654951                 1.247081                -0.652624   \n",
       "4                -0.478244                -1.080788                -0.670161   \n",
       "\n",
       "   EDA_TonicMean_version10  EDA_TonicMean_version11  EDA_TonicMean_version12  \\\n",
       "0                -0.601171                -0.809518                -1.012558   \n",
       "1                -0.018812                 1.023216                 1.189124   \n",
       "2                -0.452936                 1.123414                 0.534554   \n",
       "3                -0.546311                 1.214370                 0.821624   \n",
       "4                -0.923364                -0.421866                -0.775114   \n",
       "\n",
       "   EDA_TonicMean_version16  ...  EEG_avgRelTheta_version16  \\\n",
       "0                -0.299118  ...                  -1.877017   \n",
       "1                -0.355315  ...                  -1.632698   \n",
       "2                -0.380039  ...                  -1.489450   \n",
       "3                -0.502463  ...                  -1.353433   \n",
       "4                -0.511862  ...                  -1.443846   \n",
       "\n",
       "   EEG_avgRelTheta_version17  EEG_avgRelTheta_version19  \\\n",
       "0                  -1.442056                   1.070298   \n",
       "1                  -1.531970                   1.779032   \n",
       "2                  -1.448590                   2.194570   \n",
       "3                  -1.059878                   2.589134   \n",
       "4                  -0.627980                   2.326862   \n",
       "\n",
       "   EEG_avgRelTheta_version20  EEG_avgRelTheta_version22  \\\n",
       "0                   1.277417                   0.249605   \n",
       "1                   1.074498                   0.409991   \n",
       "2                   1.262672                   0.504028   \n",
       "3                   2.139926                   0.593317   \n",
       "4                   3.114644                   0.533965   \n",
       "\n",
       "   EEG_avgRelTheta_version23    adjSA1    adjSA2    adjSA3  adjSAtotal  \n",
       "0                   0.400156  0.119790  1.593122 -0.800726    0.350233  \n",
       "1                   0.333842  0.075246 -1.663383  0.859309   -0.262893  \n",
       "2                   0.395338 -1.072729  0.879836 -1.542415   -0.938513  \n",
       "3                   0.682023 -0.643181 -0.217332  0.945816    0.145041  \n",
       "4                   1.000560 -0.323098  0.712401 -1.473404   -0.642872  \n",
       "\n",
       "[5 rows x 5820 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"./kieranFeatures_1-30_26-Sep-2024.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling Values of All Non-Selected Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide up dataframe into predictors and outcomes. Train-test-split the following data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column for the calculated synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Function to calculate synthetic outcome values\n",
    "def func_val_bin(predictors):\n",
    "    \"\"\"\n",
    "        Creates a function out of five variables in the predictors dataframe\n",
    "        and outputs a boolean Pandas series where True means the function value\n",
    "        was greater than or equal to the median and False otherwise.\n",
    "\n",
    "        Parameters:\n",
    "            predictors (Dataframe): pandas Dataframe containing all predictor features\n",
    "\n",
    "        Output:\n",
    "            (Series): pandas Series containing True and False values where True means that\n",
    "                      the calculated value was above the median and False otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize array to store continuous values of function\n",
    "    func_calcs = np.array([])\n",
    "\n",
    "    # Get random coefficients and features\n",
    "    random.seed(42)\n",
    "    coefficients = np.array([round(random.uniform(-5, 5), 1) for _ in range(5)])\n",
    "    selected_features = np.array(random.sample(list(predictors.columns), 5))\n",
    "\n",
    "    print(\"Function = 1/(1+e^{-(\" + \n",
    "            f\"{coefficients[0]} * {selected_features[0]} + \" +\n",
    "            f\"{coefficients[1]} * {selected_features[1]} + \" +\n",
    "            f\"{coefficients[2]} * {selected_features[2]} + \" +\n",
    "            f\"{coefficients[3]} * {selected_features[3]} + \" +\n",
    "            f\"{coefficients[4]} * {selected_features[4]}\" + \n",
    "            \")})\")\n",
    "    \n",
    "    for index, row in predictors.iterrows():\n",
    "        # Add new calculation to func_calcs\n",
    "        func_calcs = np.append(func_calcs, 1/(1+np.e**(-(coefficients[0] * row[selected_features[0]] +\n",
    "                                              coefficients[1] * row[selected_features[1]] +\n",
    "                                              coefficients[2] * row[selected_features[2]] +\n",
    "                                              coefficients[3] * row[selected_features[3]] +\n",
    "                                              coefficients[4] * row[selected_features[4]]))))\n",
    "\n",
    "    return pd.Series(data = (func_calcs >= 0.5).astype(int)), selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function = 1/(1+e^{-(1.4 * fNIRS_S8D6_hbr_timeToMax_version12 + -4.7 * fNIRS_S6D6_hbr_kurtosis_version17 + -2.2 * EEG_p100_poz_version11 + -2.8 * fNIRS_S7D5_hbo_kurtosis_version03 + 2.4 * fNIRS_S5D3_hbr_kurtosis_version11)})\n"
     ]
    }
   ],
   "source": [
    "# Create the outcome feature\n",
    "synthetic_vals, selected_features = func_val_bin(df)\n",
    "df[\"synthetic_outcome\"] = synthetic_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDA_TonicMean_version02</th>\n",
       "      <th>EDA_TonicMean_version03</th>\n",
       "      <th>EDA_TonicMean_version04</th>\n",
       "      <th>EDA_TonicMean_version05</th>\n",
       "      <th>EDA_TonicMean_version09</th>\n",
       "      <th>EDA_TonicMean_version10</th>\n",
       "      <th>EDA_TonicMean_version11</th>\n",
       "      <th>EDA_TonicMean_version12</th>\n",
       "      <th>EDA_TonicMean_version16</th>\n",
       "      <th>EDA_TonicMean_version17</th>\n",
       "      <th>...</th>\n",
       "      <th>EEG_avgRelTheta_version09</th>\n",
       "      <th>EEG_avgRelTheta_version10</th>\n",
       "      <th>EEG_avgRelTheta_version11</th>\n",
       "      <th>EEG_avgRelTheta_version12</th>\n",
       "      <th>EEG_avgRelTheta_version16</th>\n",
       "      <th>EEG_avgRelTheta_version17</th>\n",
       "      <th>EEG_avgRelTheta_version19</th>\n",
       "      <th>EEG_avgRelTheta_version20</th>\n",
       "      <th>EEG_avgRelTheta_version22</th>\n",
       "      <th>EEG_avgRelTheta_version23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.320525</td>\n",
       "      <td>3.447829</td>\n",
       "      <td>-0.704162</td>\n",
       "      <td>-0.052621</td>\n",
       "      <td>0.204803</td>\n",
       "      <td>0.761195</td>\n",
       "      <td>3.447279</td>\n",
       "      <td>0.431375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064239</td>\n",
       "      <td>0.126067</td>\n",
       "      <td>0.246068</td>\n",
       "      <td>0.259256</td>\n",
       "      <td>-1.179334</td>\n",
       "      <td>1.108622</td>\n",
       "      <td>-0.266532</td>\n",
       "      <td>-0.172166</td>\n",
       "      <td>0.637170</td>\n",
       "      <td>-0.406958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.620807</td>\n",
       "      <td>0.108571</td>\n",
       "      <td>0.644553</td>\n",
       "      <td>0.711197</td>\n",
       "      <td>-1.143716</td>\n",
       "      <td>1.105370</td>\n",
       "      <td>5.576809</td>\n",
       "      <td>-0.278585</td>\n",
       "      <td>-0.381270</td>\n",
       "      <td>-0.558388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125644</td>\n",
       "      <td>0.553828</td>\n",
       "      <td>-0.055151</td>\n",
       "      <td>1.682599</td>\n",
       "      <td>2.170514</td>\n",
       "      <td>2.716596</td>\n",
       "      <td>0.196207</td>\n",
       "      <td>-0.336609</td>\n",
       "      <td>0.419895</td>\n",
       "      <td>0.739755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.714415</td>\n",
       "      <td>-0.403908</td>\n",
       "      <td>-0.478244</td>\n",
       "      <td>-0.409288</td>\n",
       "      <td>-0.248912</td>\n",
       "      <td>0.559665</td>\n",
       "      <td>-1.131586</td>\n",
       "      <td>1.027405</td>\n",
       "      <td>0.603905</td>\n",
       "      <td>0.360187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309453</td>\n",
       "      <td>-0.479757</td>\n",
       "      <td>-0.418917</td>\n",
       "      <td>0.769802</td>\n",
       "      <td>-0.495493</td>\n",
       "      <td>0.819586</td>\n",
       "      <td>-0.832655</td>\n",
       "      <td>-1.042634</td>\n",
       "      <td>0.269036</td>\n",
       "      <td>0.698494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.312291</td>\n",
       "      <td>-0.355095</td>\n",
       "      <td>0.197474</td>\n",
       "      <td>-2.219966</td>\n",
       "      <td>0.414908</td>\n",
       "      <td>0.691593</td>\n",
       "      <td>-0.551155</td>\n",
       "      <td>-0.241204</td>\n",
       "      <td>-0.120968</td>\n",
       "      <td>-1.023674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111386</td>\n",
       "      <td>1.018686</td>\n",
       "      <td>-0.768448</td>\n",
       "      <td>0.650895</td>\n",
       "      <td>-0.320605</td>\n",
       "      <td>-0.427370</td>\n",
       "      <td>-2.971263</td>\n",
       "      <td>-1.344882</td>\n",
       "      <td>1.201660</td>\n",
       "      <td>-1.309779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.581154</td>\n",
       "      <td>-0.381095</td>\n",
       "      <td>0.411544</td>\n",
       "      <td>1.154769</td>\n",
       "      <td>-1.240624</td>\n",
       "      <td>-0.041039</td>\n",
       "      <td>1.214370</td>\n",
       "      <td>0.542192</td>\n",
       "      <td>-0.493256</td>\n",
       "      <td>-0.596055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184739</td>\n",
       "      <td>0.947198</td>\n",
       "      <td>-0.749513</td>\n",
       "      <td>0.588270</td>\n",
       "      <td>0.094825</td>\n",
       "      <td>-0.663735</td>\n",
       "      <td>-1.230679</td>\n",
       "      <td>0.360461</td>\n",
       "      <td>0.523294</td>\n",
       "      <td>-0.291697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.103193</td>\n",
       "      <td>-0.076871</td>\n",
       "      <td>-0.385595</td>\n",
       "      <td>2.739124</td>\n",
       "      <td>-1.657081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.671440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.679889</td>\n",
       "      <td>5.020698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832598</td>\n",
       "      <td>-1.421879</td>\n",
       "      <td>0.172395</td>\n",
       "      <td>-1.201797</td>\n",
       "      <td>-1.848760</td>\n",
       "      <td>0.060765</td>\n",
       "      <td>0.450827</td>\n",
       "      <td>2.189873</td>\n",
       "      <td>-2.008172</td>\n",
       "      <td>0.370404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-0.720222</td>\n",
       "      <td>-0.032484</td>\n",
       "      <td>0.708645</td>\n",
       "      <td>0.769935</td>\n",
       "      <td>0.296930</td>\n",
       "      <td>0.137379</td>\n",
       "      <td>-0.037451</td>\n",
       "      <td>-0.142881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.139320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152102</td>\n",
       "      <td>1.255472</td>\n",
       "      <td>-0.555193</td>\n",
       "      <td>0.233826</td>\n",
       "      <td>2.436617</td>\n",
       "      <td>-1.649437</td>\n",
       "      <td>-0.787868</td>\n",
       "      <td>0.318748</td>\n",
       "      <td>-0.796321</td>\n",
       "      <td>-0.477352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-0.752910</td>\n",
       "      <td>-0.362019</td>\n",
       "      <td>0.044329</td>\n",
       "      <td>0.434921</td>\n",
       "      <td>-1.396764</td>\n",
       "      <td>-0.415992</td>\n",
       "      <td>2.018638</td>\n",
       "      <td>-0.547836</td>\n",
       "      <td>0.499421</td>\n",
       "      <td>-1.128980</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.480677</td>\n",
       "      <td>1.791404</td>\n",
       "      <td>2.323490</td>\n",
       "      <td>-1.136134</td>\n",
       "      <td>0.261106</td>\n",
       "      <td>-0.294957</td>\n",
       "      <td>-0.566511</td>\n",
       "      <td>-1.160890</td>\n",
       "      <td>0.163293</td>\n",
       "      <td>-1.440341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-0.465714</td>\n",
       "      <td>-0.735187</td>\n",
       "      <td>-0.982640</td>\n",
       "      <td>0.740229</td>\n",
       "      <td>-0.344376</td>\n",
       "      <td>-2.210110</td>\n",
       "      <td>-0.683907</td>\n",
       "      <td>-0.899814</td>\n",
       "      <td>-0.558297</td>\n",
       "      <td>-0.567322</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.971378</td>\n",
       "      <td>-0.550725</td>\n",
       "      <td>0.067899</td>\n",
       "      <td>-0.249387</td>\n",
       "      <td>-0.849135</td>\n",
       "      <td>-1.245770</td>\n",
       "      <td>0.420022</td>\n",
       "      <td>-0.678148</td>\n",
       "      <td>1.381828</td>\n",
       "      <td>-0.303485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-0.494618</td>\n",
       "      <td>-0.422489</td>\n",
       "      <td>-0.405868</td>\n",
       "      <td>-0.224016</td>\n",
       "      <td>0.091122</td>\n",
       "      <td>0.027097</td>\n",
       "      <td>0.091855</td>\n",
       "      <td>-0.224350</td>\n",
       "      <td>-0.985642</td>\n",
       "      <td>-0.065595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629543</td>\n",
       "      <td>1.639572</td>\n",
       "      <td>-0.450558</td>\n",
       "      <td>-0.529535</td>\n",
       "      <td>0.203648</td>\n",
       "      <td>0.375322</td>\n",
       "      <td>-0.142394</td>\n",
       "      <td>0.839077</td>\n",
       "      <td>0.121210</td>\n",
       "      <td>-0.073620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows Ã— 5815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EDA_TonicMean_version02  EDA_TonicMean_version03  \\\n",
       "0                  -0.320525                 3.447829   \n",
       "1                  -0.620807                 0.108571   \n",
       "2                  -0.714415                -0.403908   \n",
       "3                  -0.312291                -0.355095   \n",
       "4                   0.581154                -0.381095   \n",
       "..                       ...                      ...   \n",
       "299                 0.103193                -0.076871   \n",
       "300                -0.720222                -0.032484   \n",
       "301                -0.752910                -0.362019   \n",
       "302                -0.465714                -0.735187   \n",
       "303                -0.494618                -0.422489   \n",
       "\n",
       "     EDA_TonicMean_version04  EDA_TonicMean_version05  \\\n",
       "0                  -0.704162                -0.052621   \n",
       "1                   0.644553                 0.711197   \n",
       "2                  -0.478244                -0.409288   \n",
       "3                   0.197474                -2.219966   \n",
       "4                   0.411544                 1.154769   \n",
       "..                       ...                      ...   \n",
       "299                -0.385595                 2.739124   \n",
       "300                 0.708645                 0.769935   \n",
       "301                 0.044329                 0.434921   \n",
       "302                -0.982640                 0.740229   \n",
       "303                -0.405868                -0.224016   \n",
       "\n",
       "     EDA_TonicMean_version09  EDA_TonicMean_version10  \\\n",
       "0                   0.204803                 0.761195   \n",
       "1                  -1.143716                 1.105370   \n",
       "2                  -0.248912                 0.559665   \n",
       "3                   0.414908                 0.691593   \n",
       "4                  -1.240624                -0.041039   \n",
       "..                       ...                      ...   \n",
       "299                -1.657081                 0.000000   \n",
       "300                 0.296930                 0.137379   \n",
       "301                -1.396764                -0.415992   \n",
       "302                -0.344376                -2.210110   \n",
       "303                 0.091122                 0.027097   \n",
       "\n",
       "     EDA_TonicMean_version11  EDA_TonicMean_version12  \\\n",
       "0                   3.447279                 0.431375   \n",
       "1                   5.576809                -0.278585   \n",
       "2                  -1.131586                 1.027405   \n",
       "3                  -0.551155                -0.241204   \n",
       "4                   1.214370                 0.542192   \n",
       "..                       ...                      ...   \n",
       "299                 1.671440                 0.000000   \n",
       "300                -0.037451                -0.142881   \n",
       "301                 2.018638                -0.547836   \n",
       "302                -0.683907                -0.899814   \n",
       "303                 0.091855                -0.224350   \n",
       "\n",
       "     EDA_TonicMean_version16  EDA_TonicMean_version17  ...  \\\n",
       "0                   0.000000                 0.055425  ...   \n",
       "1                  -0.381270                -0.558388  ...   \n",
       "2                   0.603905                 0.360187  ...   \n",
       "3                  -0.120968                -1.023674  ...   \n",
       "4                  -0.493256                -0.596055  ...   \n",
       "..                       ...                      ...  ...   \n",
       "299                -0.679889                 5.020698  ...   \n",
       "300                 0.000000                -0.139320  ...   \n",
       "301                 0.499421                -1.128980  ...   \n",
       "302                -0.558297                -0.567322  ...   \n",
       "303                -0.985642                -0.065595  ...   \n",
       "\n",
       "     EEG_avgRelTheta_version09  EEG_avgRelTheta_version10  \\\n",
       "0                    -0.064239                   0.126067   \n",
       "1                     0.125644                   0.553828   \n",
       "2                     0.309453                  -0.479757   \n",
       "3                    -0.111386                   1.018686   \n",
       "4                    -0.184739                   0.947198   \n",
       "..                         ...                        ...   \n",
       "299                   0.832598                  -1.421879   \n",
       "300                   0.152102                   1.255472   \n",
       "301                  -1.480677                   1.791404   \n",
       "302                  -1.971378                  -0.550725   \n",
       "303                   0.629543                   1.639572   \n",
       "\n",
       "     EEG_avgRelTheta_version11  EEG_avgRelTheta_version12  \\\n",
       "0                     0.246068                   0.259256   \n",
       "1                    -0.055151                   1.682599   \n",
       "2                    -0.418917                   0.769802   \n",
       "3                    -0.768448                   0.650895   \n",
       "4                    -0.749513                   0.588270   \n",
       "..                         ...                        ...   \n",
       "299                   0.172395                  -1.201797   \n",
       "300                  -0.555193                   0.233826   \n",
       "301                   2.323490                  -1.136134   \n",
       "302                   0.067899                  -0.249387   \n",
       "303                  -0.450558                  -0.529535   \n",
       "\n",
       "     EEG_avgRelTheta_version16  EEG_avgRelTheta_version17  \\\n",
       "0                    -1.179334                   1.108622   \n",
       "1                     2.170514                   2.716596   \n",
       "2                    -0.495493                   0.819586   \n",
       "3                    -0.320605                  -0.427370   \n",
       "4                     0.094825                  -0.663735   \n",
       "..                         ...                        ...   \n",
       "299                  -1.848760                   0.060765   \n",
       "300                   2.436617                  -1.649437   \n",
       "301                   0.261106                  -0.294957   \n",
       "302                  -0.849135                  -1.245770   \n",
       "303                   0.203648                   0.375322   \n",
       "\n",
       "     EEG_avgRelTheta_version19  EEG_avgRelTheta_version20  \\\n",
       "0                    -0.266532                  -0.172166   \n",
       "1                     0.196207                  -0.336609   \n",
       "2                    -0.832655                  -1.042634   \n",
       "3                    -2.971263                  -1.344882   \n",
       "4                    -1.230679                   0.360461   \n",
       "..                         ...                        ...   \n",
       "299                   0.450827                   2.189873   \n",
       "300                  -0.787868                   0.318748   \n",
       "301                  -0.566511                  -1.160890   \n",
       "302                   0.420022                  -0.678148   \n",
       "303                  -0.142394                   0.839077   \n",
       "\n",
       "     EEG_avgRelTheta_version22  EEG_avgRelTheta_version23  \n",
       "0                     0.637170                  -0.406958  \n",
       "1                     0.419895                   0.739755  \n",
       "2                     0.269036                   0.698494  \n",
       "3                     1.201660                  -1.309779  \n",
       "4                     0.523294                  -0.291697  \n",
       "..                         ...                        ...  \n",
       "299                  -2.008172                   0.370404  \n",
       "300                  -0.796321                  -0.477352  \n",
       "301                   0.163293                  -1.440341  \n",
       "302                   1.381828                  -0.303485  \n",
       "303                   0.121210                  -0.073620  \n",
       "\n",
       "[304 rows x 5815 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjSA1</th>\n",
       "      <th>adjSA2</th>\n",
       "      <th>adjSA3</th>\n",
       "      <th>adjSAtotal</th>\n",
       "      <th>synthetic_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.119790</td>\n",
       "      <td>1.593122</td>\n",
       "      <td>-0.800726</td>\n",
       "      <td>0.350233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.075246</td>\n",
       "      <td>-1.663383</td>\n",
       "      <td>0.859309</td>\n",
       "      <td>-0.262893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.072729</td>\n",
       "      <td>0.879836</td>\n",
       "      <td>-1.542415</td>\n",
       "      <td>-0.938513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.643181</td>\n",
       "      <td>-0.217332</td>\n",
       "      <td>0.945816</td>\n",
       "      <td>0.145041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.323098</td>\n",
       "      <td>0.712401</td>\n",
       "      <td>-1.473404</td>\n",
       "      <td>-0.642872</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.076099</td>\n",
       "      <td>1.105227</td>\n",
       "      <td>-0.609431</td>\n",
       "      <td>0.209332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-0.258249</td>\n",
       "      <td>-0.360422</td>\n",
       "      <td>0.778641</td>\n",
       "      <td>0.155357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.110240</td>\n",
       "      <td>0.092504</td>\n",
       "      <td>0.945232</td>\n",
       "      <td>0.627581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-1.105639</td>\n",
       "      <td>0.426616</td>\n",
       "      <td>0.328063</td>\n",
       "      <td>-0.108335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1.141504</td>\n",
       "      <td>1.452440</td>\n",
       "      <td>0.883889</td>\n",
       "      <td>1.694167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adjSA1    adjSA2    adjSA3  adjSAtotal  synthetic_outcome\n",
       "0    0.119790  1.593122 -0.800726    0.350233                  1\n",
       "1    0.075246 -1.663383  0.859309   -0.262893                  1\n",
       "2   -1.072729  0.879836 -1.542415   -0.938513                  1\n",
       "3   -0.643181 -0.217332  0.945816    0.145041                  1\n",
       "4   -0.323098  0.712401 -1.473404   -0.642872                  1\n",
       "..        ...       ...       ...         ...                ...\n",
       "299  0.076099  1.105227 -0.609431    0.209332                  0\n",
       "300 -0.258249 -0.360422  0.778641    0.155357                  1\n",
       "301  0.110240  0.092504  0.945232    0.627581                  1\n",
       "302 -1.105639  0.426616  0.328063   -0.108335                  1\n",
       "303  1.141504  1.452440  0.883889    1.694167                  0\n",
       "\n",
       "[304 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDA_TonicMean_version02</th>\n",
       "      <th>EDA_TonicMean_version03</th>\n",
       "      <th>EDA_TonicMean_version04</th>\n",
       "      <th>EDA_TonicMean_version05</th>\n",
       "      <th>EDA_TonicMean_version09</th>\n",
       "      <th>EDA_TonicMean_version10</th>\n",
       "      <th>EDA_TonicMean_version11</th>\n",
       "      <th>EDA_TonicMean_version12</th>\n",
       "      <th>EDA_TonicMean_version16</th>\n",
       "      <th>EDA_TonicMean_version17</th>\n",
       "      <th>...</th>\n",
       "      <th>EEG_avgRelTheta_version09</th>\n",
       "      <th>EEG_avgRelTheta_version10</th>\n",
       "      <th>EEG_avgRelTheta_version11</th>\n",
       "      <th>EEG_avgRelTheta_version12</th>\n",
       "      <th>EEG_avgRelTheta_version16</th>\n",
       "      <th>EEG_avgRelTheta_version17</th>\n",
       "      <th>EEG_avgRelTheta_version19</th>\n",
       "      <th>EEG_avgRelTheta_version20</th>\n",
       "      <th>EEG_avgRelTheta_version22</th>\n",
       "      <th>EEG_avgRelTheta_version23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>-0.789734</td>\n",
       "      <td>-0.566526</td>\n",
       "      <td>0.109825</td>\n",
       "      <td>-0.506206</td>\n",
       "      <td>-0.197257</td>\n",
       "      <td>0.842311</td>\n",
       "      <td>-0.339775</td>\n",
       "      <td>0.197605</td>\n",
       "      <td>-1.006203</td>\n",
       "      <td>-0.501586</td>\n",
       "      <td>...</td>\n",
       "      <td>1.174838</td>\n",
       "      <td>1.018292</td>\n",
       "      <td>0.060181</td>\n",
       "      <td>-1.101042</td>\n",
       "      <td>0.620108</td>\n",
       "      <td>1.527067</td>\n",
       "      <td>-0.664651</td>\n",
       "      <td>-0.169305</td>\n",
       "      <td>-0.171997</td>\n",
       "      <td>-1.440045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>-0.598078</td>\n",
       "      <td>0.094184</td>\n",
       "      <td>-0.073457</td>\n",
       "      <td>-1.059710</td>\n",
       "      <td>1.233320</td>\n",
       "      <td>-0.099982</td>\n",
       "      <td>-1.714762</td>\n",
       "      <td>0.465817</td>\n",
       "      <td>-0.511862</td>\n",
       "      <td>-0.519493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.548652</td>\n",
       "      <td>1.181846</td>\n",
       "      <td>1.656398</td>\n",
       "      <td>0.037628</td>\n",
       "      <td>0.568487</td>\n",
       "      <td>-0.431520</td>\n",
       "      <td>-0.576094</td>\n",
       "      <td>-0.345905</td>\n",
       "      <td>-0.301990</td>\n",
       "      <td>1.657923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.319710</td>\n",
       "      <td>-0.618450</td>\n",
       "      <td>1.282761</td>\n",
       "      <td>-0.659256</td>\n",
       "      <td>0.721673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341369</td>\n",
       "      <td>0.059879</td>\n",
       "      <td>-0.091546</td>\n",
       "      <td>0.069638</td>\n",
       "      <td>...</td>\n",
       "      <td>1.148794</td>\n",
       "      <td>-0.306810</td>\n",
       "      <td>0.062537</td>\n",
       "      <td>0.064411</td>\n",
       "      <td>0.007059</td>\n",
       "      <td>-1.336422</td>\n",
       "      <td>2.853685</td>\n",
       "      <td>-0.512149</td>\n",
       "      <td>-2.614365</td>\n",
       "      <td>-0.860509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.338342</td>\n",
       "      <td>2.554621</td>\n",
       "      <td>-0.307842</td>\n",
       "      <td>-0.056275</td>\n",
       "      <td>0.357777</td>\n",
       "      <td>0.469791</td>\n",
       "      <td>-0.258565</td>\n",
       "      <td>-0.089433</td>\n",
       "      <td>0.105818</td>\n",
       "      <td>-0.799764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304035</td>\n",
       "      <td>1.203823</td>\n",
       "      <td>-0.468755</td>\n",
       "      <td>0.324137</td>\n",
       "      <td>-0.565269</td>\n",
       "      <td>-1.320804</td>\n",
       "      <td>-0.796984</td>\n",
       "      <td>0.245281</td>\n",
       "      <td>-0.817618</td>\n",
       "      <td>-1.068994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-0.743637</td>\n",
       "      <td>0.552497</td>\n",
       "      <td>1.423084</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>0.218692</td>\n",
       "      <td>3.514211</td>\n",
       "      <td>-0.754827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115300</td>\n",
       "      <td>-0.555953</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.288096</td>\n",
       "      <td>1.489270</td>\n",
       "      <td>0.123966</td>\n",
       "      <td>0.214784</td>\n",
       "      <td>-0.002149</td>\n",
       "      <td>-0.063372</td>\n",
       "      <td>0.173056</td>\n",
       "      <td>-0.581999</td>\n",
       "      <td>0.673157</td>\n",
       "      <td>0.254171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.346018</td>\n",
       "      <td>0.697155</td>\n",
       "      <td>0.545542</td>\n",
       "      <td>0.049048</td>\n",
       "      <td>0.119713</td>\n",
       "      <td>-0.584818</td>\n",
       "      <td>0.283305</td>\n",
       "      <td>-0.704285</td>\n",
       "      <td>-0.268734</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.355148</td>\n",
       "      <td>1.355268</td>\n",
       "      <td>-0.883532</td>\n",
       "      <td>-0.506775</td>\n",
       "      <td>-0.379363</td>\n",
       "      <td>-0.494632</td>\n",
       "      <td>0.124392</td>\n",
       "      <td>-0.873139</td>\n",
       "      <td>-0.298577</td>\n",
       "      <td>1.176818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.796969</td>\n",
       "      <td>0.144016</td>\n",
       "      <td>-0.727197</td>\n",
       "      <td>1.552358</td>\n",
       "      <td>-0.307338</td>\n",
       "      <td>0.054983</td>\n",
       "      <td>-2.048963</td>\n",
       "      <td>-0.455249</td>\n",
       "      <td>1.068357</td>\n",
       "      <td>-0.284962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080990</td>\n",
       "      <td>0.194275</td>\n",
       "      <td>0.805271</td>\n",
       "      <td>0.293527</td>\n",
       "      <td>-0.511802</td>\n",
       "      <td>1.268327</td>\n",
       "      <td>0.689936</td>\n",
       "      <td>-2.470424</td>\n",
       "      <td>0.230648</td>\n",
       "      <td>-0.576952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.397200</td>\n",
       "      <td>2.852104</td>\n",
       "      <td>0.023416</td>\n",
       "      <td>0.450465</td>\n",
       "      <td>0.233301</td>\n",
       "      <td>3.522785</td>\n",
       "      <td>-0.197094</td>\n",
       "      <td>0.015811</td>\n",
       "      <td>-0.504183</td>\n",
       "      <td>-0.545149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432980</td>\n",
       "      <td>-0.667217</td>\n",
       "      <td>0.418165</td>\n",
       "      <td>-0.020682</td>\n",
       "      <td>0.475154</td>\n",
       "      <td>-0.336831</td>\n",
       "      <td>0.368635</td>\n",
       "      <td>0.297896</td>\n",
       "      <td>-1.538414</td>\n",
       "      <td>0.768717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-0.851257</td>\n",
       "      <td>-0.901833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.339642</td>\n",
       "      <td>-0.004899</td>\n",
       "      <td>0.408027</td>\n",
       "      <td>0.817302</td>\n",
       "      <td>-0.087981</td>\n",
       "      <td>-0.115394</td>\n",
       "      <td>-0.715333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257777</td>\n",
       "      <td>-1.312263</td>\n",
       "      <td>-0.915717</td>\n",
       "      <td>1.379299</td>\n",
       "      <td>0.191171</td>\n",
       "      <td>2.607307</td>\n",
       "      <td>-0.037417</td>\n",
       "      <td>0.920577</td>\n",
       "      <td>1.139130</td>\n",
       "      <td>-0.573271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.177994</td>\n",
       "      <td>-0.196260</td>\n",
       "      <td>-0.043266</td>\n",
       "      <td>0.356358</td>\n",
       "      <td>-0.207008</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.105307</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>-0.216251</td>\n",
       "      <td>-0.640221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199444</td>\n",
       "      <td>-0.605012</td>\n",
       "      <td>0.854242</td>\n",
       "      <td>-0.251492</td>\n",
       "      <td>0.357638</td>\n",
       "      <td>-0.605849</td>\n",
       "      <td>-0.443268</td>\n",
       "      <td>-0.063294</td>\n",
       "      <td>-2.255020</td>\n",
       "      <td>0.809745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 5815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EDA_TonicMean_version02  EDA_TonicMean_version03  \\\n",
       "269                -0.789734                -0.566526   \n",
       "211                -0.598078                 0.094184   \n",
       "197                 0.319710                -0.618450   \n",
       "75                 -0.338342                 2.554621   \n",
       "177                -0.743637                 0.552497   \n",
       "..                       ...                      ...   \n",
       "188                 0.000000                -0.346018   \n",
       "71                 -0.796969                 0.144016   \n",
       "106                -0.397200                 2.852104   \n",
       "270                -0.851257                -0.901833   \n",
       "102                 0.177994                -0.196260   \n",
       "\n",
       "     EDA_TonicMean_version04  EDA_TonicMean_version05  \\\n",
       "269                 0.109825                -0.506206   \n",
       "211                -0.073457                -1.059710   \n",
       "197                 1.282761                -0.659256   \n",
       "75                 -0.307842                -0.056275   \n",
       "177                 1.423084                 0.009381   \n",
       "..                       ...                      ...   \n",
       "188                 0.697155                 0.545542   \n",
       "71                 -0.727197                 1.552358   \n",
       "106                 0.023416                 0.450465   \n",
       "270                 0.000000                -0.339642   \n",
       "102                -0.043266                 0.356358   \n",
       "\n",
       "     EDA_TonicMean_version09  EDA_TonicMean_version10  \\\n",
       "269                -0.197257                 0.842311   \n",
       "211                 1.233320                -0.099982   \n",
       "197                 0.721673                 0.000000   \n",
       "75                  0.357777                 0.469791   \n",
       "177                 0.218692                 3.514211   \n",
       "..                       ...                      ...   \n",
       "188                 0.049048                 0.119713   \n",
       "71                 -0.307338                 0.054983   \n",
       "106                 0.233301                 3.522785   \n",
       "270                -0.004899                 0.408027   \n",
       "102                -0.207008                 0.018722   \n",
       "\n",
       "     EDA_TonicMean_version11  EDA_TonicMean_version12  \\\n",
       "269                -0.339775                 0.197605   \n",
       "211                -1.714762                 0.465817   \n",
       "197                 0.341369                 0.059879   \n",
       "75                 -0.258565                -0.089433   \n",
       "177                -0.754827                 0.000000   \n",
       "..                       ...                      ...   \n",
       "188                -0.584818                 0.283305   \n",
       "71                 -2.048963                -0.455249   \n",
       "106                -0.197094                 0.015811   \n",
       "270                 0.817302                -0.087981   \n",
       "102                 0.105307                 0.008021   \n",
       "\n",
       "     EDA_TonicMean_version16  EDA_TonicMean_version17  ...  \\\n",
       "269                -1.006203                -0.501586  ...   \n",
       "211                -0.511862                -0.519493  ...   \n",
       "197                -0.091546                 0.069638  ...   \n",
       "75                  0.105818                -0.799764  ...   \n",
       "177                 0.115300                -0.555953  ...   \n",
       "..                       ...                      ...  ...   \n",
       "188                -0.704285                -0.268734  ...   \n",
       "71                  1.068357                -0.284962  ...   \n",
       "106                -0.504183                -0.545149  ...   \n",
       "270                -0.115394                -0.715333  ...   \n",
       "102                -0.216251                -0.640221  ...   \n",
       "\n",
       "     EEG_avgRelTheta_version09  EEG_avgRelTheta_version10  \\\n",
       "269                   1.174838                   1.018292   \n",
       "211                  -0.548652                   1.181846   \n",
       "197                   1.148794                  -0.306810   \n",
       "75                    0.304035                   1.203823   \n",
       "177                  -1.288096                   1.489270   \n",
       "..                         ...                        ...   \n",
       "188                  -1.355148                   1.355268   \n",
       "71                    0.080990                   0.194275   \n",
       "106                   0.432980                  -0.667217   \n",
       "270                   0.257777                  -1.312263   \n",
       "102                  -0.199444                  -0.605012   \n",
       "\n",
       "     EEG_avgRelTheta_version11  EEG_avgRelTheta_version12  \\\n",
       "269                   0.060181                  -1.101042   \n",
       "211                   1.656398                   0.037628   \n",
       "197                   0.062537                   0.064411   \n",
       "75                   -0.468755                   0.324137   \n",
       "177                   0.123966                   0.214784   \n",
       "..                         ...                        ...   \n",
       "188                  -0.883532                  -0.506775   \n",
       "71                    0.805271                   0.293527   \n",
       "106                   0.418165                  -0.020682   \n",
       "270                  -0.915717                   1.379299   \n",
       "102                   0.854242                  -0.251492   \n",
       "\n",
       "     EEG_avgRelTheta_version16  EEG_avgRelTheta_version17  \\\n",
       "269                   0.620108                   1.527067   \n",
       "211                   0.568487                  -0.431520   \n",
       "197                   0.007059                  -1.336422   \n",
       "75                   -0.565269                  -1.320804   \n",
       "177                  -0.002149                  -0.063372   \n",
       "..                         ...                        ...   \n",
       "188                  -0.379363                  -0.494632   \n",
       "71                   -0.511802                   1.268327   \n",
       "106                   0.475154                  -0.336831   \n",
       "270                   0.191171                   2.607307   \n",
       "102                   0.357638                  -0.605849   \n",
       "\n",
       "     EEG_avgRelTheta_version19  EEG_avgRelTheta_version20  \\\n",
       "269                  -0.664651                  -0.169305   \n",
       "211                  -0.576094                  -0.345905   \n",
       "197                   2.853685                  -0.512149   \n",
       "75                   -0.796984                   0.245281   \n",
       "177                   0.173056                  -0.581999   \n",
       "..                         ...                        ...   \n",
       "188                   0.124392                  -0.873139   \n",
       "71                    0.689936                  -2.470424   \n",
       "106                   0.368635                   0.297896   \n",
       "270                  -0.037417                   0.920577   \n",
       "102                  -0.443268                  -0.063294   \n",
       "\n",
       "     EEG_avgRelTheta_version22  EEG_avgRelTheta_version23  \n",
       "269                  -0.171997                  -1.440045  \n",
       "211                  -0.301990                   1.657923  \n",
       "197                  -2.614365                  -0.860509  \n",
       "75                   -0.817618                  -1.068994  \n",
       "177                   0.673157                   0.254171  \n",
       "..                         ...                        ...  \n",
       "188                  -0.298577                   1.176818  \n",
       "71                    0.230648                  -0.576952  \n",
       "106                  -1.538414                   0.768717  \n",
       "270                   1.139130                  -0.573271  \n",
       "102                  -2.255020                   0.809745  \n",
       "\n",
       "[243 rows x 5815 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjSA1</th>\n",
       "      <th>adjSA2</th>\n",
       "      <th>adjSA3</th>\n",
       "      <th>adjSAtotal</th>\n",
       "      <th>synthetic_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.143670</td>\n",
       "      <td>1.101324</td>\n",
       "      <td>-0.822506</td>\n",
       "      <td>0.117187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>-0.783965</td>\n",
       "      <td>-0.834554</td>\n",
       "      <td>0.116317</td>\n",
       "      <td>-0.677632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.475912</td>\n",
       "      <td>-0.162414</td>\n",
       "      <td>1.180378</td>\n",
       "      <td>0.804260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.088596</td>\n",
       "      <td>0.229732</td>\n",
       "      <td>0.972713</td>\n",
       "      <td>0.618738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-1.146056</td>\n",
       "      <td>0.662741</td>\n",
       "      <td>-3.060939</td>\n",
       "      <td>-1.932524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.116062</td>\n",
       "      <td>0.313836</td>\n",
       "      <td>0.270247</td>\n",
       "      <td>0.799881</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.881938</td>\n",
       "      <td>0.311514</td>\n",
       "      <td>-0.739256</td>\n",
       "      <td>-0.666210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.900207</td>\n",
       "      <td>0.372292</td>\n",
       "      <td>-1.423042</td>\n",
       "      <td>-1.032613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-2.025591</td>\n",
       "      <td>0.753425</td>\n",
       "      <td>0.139548</td>\n",
       "      <td>-0.472791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.002411</td>\n",
       "      <td>-1.686081</td>\n",
       "      <td>0.460911</td>\n",
       "      <td>-0.533697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adjSA1    adjSA2    adjSA3  adjSAtotal  synthetic_outcome\n",
       "269  0.143670  1.101324 -0.822506    0.117187                  1\n",
       "211 -0.783965 -0.834554  0.116317   -0.677632                  0\n",
       "197  0.475912 -0.162414  1.180378    0.804260                  1\n",
       "75  -0.088596  0.229732  0.972713    0.618738                  0\n",
       "177 -1.146056  0.662741 -3.060939   -1.932524                  0\n",
       "..        ...       ...       ...         ...                ...\n",
       "188  1.116062  0.313836  0.270247    0.799881                  0\n",
       "71  -0.881938  0.311514 -0.739256   -0.666210                  1\n",
       "106 -0.900207  0.372292 -1.423042   -1.032613                  0\n",
       "270 -2.025591  0.753425  0.139548   -0.472791                  1\n",
       "102 -0.002411 -1.686081  0.460911   -0.533697                  1\n",
       "\n",
       "[243 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDA_TonicMean_version02</th>\n",
       "      <th>EDA_TonicMean_version03</th>\n",
       "      <th>EDA_TonicMean_version04</th>\n",
       "      <th>EDA_TonicMean_version05</th>\n",
       "      <th>EDA_TonicMean_version09</th>\n",
       "      <th>EDA_TonicMean_version10</th>\n",
       "      <th>EDA_TonicMean_version11</th>\n",
       "      <th>EDA_TonicMean_version12</th>\n",
       "      <th>EDA_TonicMean_version16</th>\n",
       "      <th>EDA_TonicMean_version17</th>\n",
       "      <th>...</th>\n",
       "      <th>EEG_avgRelTheta_version09</th>\n",
       "      <th>EEG_avgRelTheta_version10</th>\n",
       "      <th>EEG_avgRelTheta_version11</th>\n",
       "      <th>EEG_avgRelTheta_version12</th>\n",
       "      <th>EEG_avgRelTheta_version16</th>\n",
       "      <th>EEG_avgRelTheta_version17</th>\n",
       "      <th>EEG_avgRelTheta_version19</th>\n",
       "      <th>EEG_avgRelTheta_version20</th>\n",
       "      <th>EEG_avgRelTheta_version22</th>\n",
       "      <th>EEG_avgRelTheta_version23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.797036</td>\n",
       "      <td>-0.588659</td>\n",
       "      <td>0.157157</td>\n",
       "      <td>-0.508528</td>\n",
       "      <td>-0.197596</td>\n",
       "      <td>0.786607</td>\n",
       "      <td>-0.338071</td>\n",
       "      <td>0.141133</td>\n",
       "      <td>-0.957364</td>\n",
       "      <td>-0.502597</td>\n",
       "      <td>...</td>\n",
       "      <td>1.230320</td>\n",
       "      <td>0.992512</td>\n",
       "      <td>0.068778</td>\n",
       "      <td>-1.119762</td>\n",
       "      <td>0.600838</td>\n",
       "      <td>1.525718</td>\n",
       "      <td>-0.670571</td>\n",
       "      <td>-0.187794</td>\n",
       "      <td>-0.169433</td>\n",
       "      <td>-1.570568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.605902</td>\n",
       "      <td>0.056401</td>\n",
       "      <td>-0.029084</td>\n",
       "      <td>-1.056900</td>\n",
       "      <td>1.260602</td>\n",
       "      <td>-0.147575</td>\n",
       "      <td>-1.676056</td>\n",
       "      <td>0.391740</td>\n",
       "      <td>-0.497362</td>\n",
       "      <td>-0.519378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.648581</td>\n",
       "      <td>1.152726</td>\n",
       "      <td>1.600785</td>\n",
       "      <td>-0.025203</td>\n",
       "      <td>0.549140</td>\n",
       "      <td>-0.407958</td>\n",
       "      <td>-0.583667</td>\n",
       "      <td>-0.362974</td>\n",
       "      <td>-0.299139</td>\n",
       "      <td>1.714507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.309386</td>\n",
       "      <td>-0.639354</td>\n",
       "      <td>1.349026</td>\n",
       "      <td>-0.660159</td>\n",
       "      <td>0.739077</td>\n",
       "      <td>-0.048454</td>\n",
       "      <td>0.324744</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>-0.106243</td>\n",
       "      <td>0.032697</td>\n",
       "      <td>...</td>\n",
       "      <td>1.201927</td>\n",
       "      <td>-0.305531</td>\n",
       "      <td>0.071040</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>-0.013120</td>\n",
       "      <td>-1.301350</td>\n",
       "      <td>2.782099</td>\n",
       "      <td>-0.527882</td>\n",
       "      <td>-2.606401</td>\n",
       "      <td>-0.956030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.346873</td>\n",
       "      <td>2.458558</td>\n",
       "      <td>-0.267252</td>\n",
       "      <td>-0.062768</td>\n",
       "      <td>0.368155</td>\n",
       "      <td>0.417293</td>\n",
       "      <td>-0.259046</td>\n",
       "      <td>-0.127064</td>\n",
       "      <td>0.077412</td>\n",
       "      <td>-0.782021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280994</td>\n",
       "      <td>1.174254</td>\n",
       "      <td>-0.438880</td>\n",
       "      <td>0.250207</td>\n",
       "      <td>-0.586296</td>\n",
       "      <td>-1.285930</td>\n",
       "      <td>-0.800434</td>\n",
       "      <td>0.223459</td>\n",
       "      <td>-0.813627</td>\n",
       "      <td>-1.177107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.751064</td>\n",
       "      <td>0.503858</td>\n",
       "      <td>1.491614</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.226384</td>\n",
       "      <td>3.435505</td>\n",
       "      <td>-0.741954</td>\n",
       "      <td>-0.043501</td>\n",
       "      <td>0.086235</td>\n",
       "      <td>-0.553544</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.454702</td>\n",
       "      <td>1.453872</td>\n",
       "      <td>0.129997</td>\n",
       "      <td>0.145090</td>\n",
       "      <td>-0.022342</td>\n",
       "      <td>-0.044492</td>\n",
       "      <td>0.151501</td>\n",
       "      <td>-0.597170</td>\n",
       "      <td>0.673852</td>\n",
       "      <td>0.225974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>-0.009453</td>\n",
       "      <td>-0.373374</td>\n",
       "      <td>0.753967</td>\n",
       "      <td>0.533471</td>\n",
       "      <td>0.053465</td>\n",
       "      <td>0.070229</td>\n",
       "      <td>-0.576520</td>\n",
       "      <td>0.221208</td>\n",
       "      <td>-0.676419</td>\n",
       "      <td>-0.284391</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.527801</td>\n",
       "      <td>1.322606</td>\n",
       "      <td>-0.836972</td>\n",
       "      <td>-0.548516</td>\n",
       "      <td>-0.400114</td>\n",
       "      <td>-0.470267</td>\n",
       "      <td>0.103745</td>\n",
       "      <td>-0.885969</td>\n",
       "      <td>-0.295734</td>\n",
       "      <td>1.204345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-0.804251</td>\n",
       "      <td>0.105052</td>\n",
       "      <td>-0.693376</td>\n",
       "      <td>1.530954</td>\n",
       "      <td>-0.309802</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>-2.001263</td>\n",
       "      <td>-0.468869</td>\n",
       "      <td>0.973089</td>\n",
       "      <td>-0.299599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037836</td>\n",
       "      <td>0.185321</td>\n",
       "      <td>0.783896</td>\n",
       "      <td>0.220783</td>\n",
       "      <td>-0.532749</td>\n",
       "      <td>1.270270</td>\n",
       "      <td>0.658734</td>\n",
       "      <td>-2.470410</td>\n",
       "      <td>0.232322</td>\n",
       "      <td>-0.655347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>-0.405572</td>\n",
       "      <td>2.748995</td>\n",
       "      <td>0.069353</td>\n",
       "      <td>0.439276</td>\n",
       "      <td>0.241275</td>\n",
       "      <td>3.444006</td>\n",
       "      <td>-0.199229</td>\n",
       "      <td>-0.028728</td>\n",
       "      <td>-0.490216</td>\n",
       "      <td>-0.543420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421567</td>\n",
       "      <td>-0.658579</td>\n",
       "      <td>0.412362</td>\n",
       "      <td>-0.081254</td>\n",
       "      <td>0.455668</td>\n",
       "      <td>-0.314473</td>\n",
       "      <td>0.343429</td>\n",
       "      <td>0.275650</td>\n",
       "      <td>-1.532829</td>\n",
       "      <td>0.771596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-0.858391</td>\n",
       "      <td>-0.916024</td>\n",
       "      <td>0.045559</td>\n",
       "      <td>-0.343508</td>\n",
       "      <td>-0.001523</td>\n",
       "      <td>0.356061</td>\n",
       "      <td>0.787868</td>\n",
       "      <td>-0.125707</td>\n",
       "      <td>-0.128434</td>\n",
       "      <td>-0.702900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230564</td>\n",
       "      <td>-1.290453</td>\n",
       "      <td>-0.867862</td>\n",
       "      <td>1.264494</td>\n",
       "      <td>0.171264</td>\n",
       "      <td>2.592219</td>\n",
       "      <td>-0.055043</td>\n",
       "      <td>0.893324</td>\n",
       "      <td>1.138795</td>\n",
       "      <td>-0.651444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.168055</td>\n",
       "      <td>-0.227164</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.346041</td>\n",
       "      <td>-0.207535</td>\n",
       "      <td>-0.029893</td>\n",
       "      <td>0.095034</td>\n",
       "      <td>-0.036006</td>\n",
       "      <td>-0.222285</td>\n",
       "      <td>-0.632513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267885</td>\n",
       "      <td>-0.597645</td>\n",
       "      <td>0.830897</td>\n",
       "      <td>-0.303122</td>\n",
       "      <td>0.337979</td>\n",
       "      <td>-0.580070</td>\n",
       "      <td>-0.453320</td>\n",
       "      <td>-0.082636</td>\n",
       "      <td>-2.247851</td>\n",
       "      <td>0.815102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 5815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EDA_TonicMean_version02  EDA_TonicMean_version03  \\\n",
       "0                  -0.797036                -0.588659   \n",
       "1                  -0.605902                 0.056401   \n",
       "2                   0.309386                -0.639354   \n",
       "3                  -0.346873                 2.458558   \n",
       "4                  -0.751064                 0.503858   \n",
       "..                       ...                      ...   \n",
       "238                -0.009453                -0.373374   \n",
       "239                -0.804251                 0.105052   \n",
       "240                -0.405572                 2.748995   \n",
       "241                -0.858391                -0.916024   \n",
       "242                 0.168055                -0.227164   \n",
       "\n",
       "     EDA_TonicMean_version04  EDA_TonicMean_version05  \\\n",
       "0                   0.157157                -0.508528   \n",
       "1                  -0.029084                -1.056900   \n",
       "2                   1.349026                -0.660159   \n",
       "3                  -0.267252                -0.062768   \n",
       "4                   1.491614                 0.002280   \n",
       "..                       ...                      ...   \n",
       "238                 0.753967                 0.533471   \n",
       "239                -0.693376                 1.530954   \n",
       "240                 0.069353                 0.439276   \n",
       "241                 0.045559                -0.343508   \n",
       "242                 0.001594                 0.346041   \n",
       "\n",
       "     EDA_TonicMean_version09  EDA_TonicMean_version10  \\\n",
       "0                  -0.197596                 0.786607   \n",
       "1                   1.260602                -0.147575   \n",
       "2                   0.739077                -0.048454   \n",
       "3                   0.368155                 0.417293   \n",
       "4                   0.226384                 3.435505   \n",
       "..                       ...                      ...   \n",
       "238                 0.053465                 0.070229   \n",
       "239                -0.309802                 0.006056   \n",
       "240                 0.241275                 3.444006   \n",
       "241                -0.001523                 0.356061   \n",
       "242                -0.207535                -0.029893   \n",
       "\n",
       "     EDA_TonicMean_version11  EDA_TonicMean_version12  \\\n",
       "0                  -0.338071                 0.141133   \n",
       "1                  -1.676056                 0.391740   \n",
       "2                   0.324744                 0.012448   \n",
       "3                  -0.259046                -0.127064   \n",
       "4                  -0.741954                -0.043501   \n",
       "..                       ...                      ...   \n",
       "238                -0.576520                 0.221208   \n",
       "239                -2.001263                -0.468869   \n",
       "240                -0.199229                -0.028728   \n",
       "241                 0.787868                -0.125707   \n",
       "242                 0.095034                -0.036006   \n",
       "\n",
       "     EDA_TonicMean_version16  EDA_TonicMean_version17  ...  \\\n",
       "0                  -0.957364                -0.502597  ...   \n",
       "1                  -0.497362                -0.519378  ...   \n",
       "2                  -0.106243                 0.032697  ...   \n",
       "3                   0.077412                -0.782021  ...   \n",
       "4                   0.086235                -0.553544  ...   \n",
       "..                       ...                      ...  ...   \n",
       "238                -0.676419                -0.284391  ...   \n",
       "239                 0.973089                -0.299599  ...   \n",
       "240                -0.490216                -0.543420  ...   \n",
       "241                -0.128434                -0.702900  ...   \n",
       "242                -0.222285                -0.632513  ...   \n",
       "\n",
       "     EEG_avgRelTheta_version09  EEG_avgRelTheta_version10  \\\n",
       "0                     1.230320                   0.992512   \n",
       "1                    -0.648581                   1.152726   \n",
       "2                     1.201927                  -0.305531   \n",
       "3                     0.280994                   1.174254   \n",
       "4                    -1.454702                   1.453872   \n",
       "..                         ...                        ...   \n",
       "238                  -1.527801                   1.322606   \n",
       "239                   0.037836                   0.185321   \n",
       "240                   0.421567                  -0.658579   \n",
       "241                   0.230564                  -1.290453   \n",
       "242                  -0.267885                  -0.597645   \n",
       "\n",
       "     EEG_avgRelTheta_version11  EEG_avgRelTheta_version12  \\\n",
       "0                     0.068778                  -1.119762   \n",
       "1                     1.600785                  -0.025203   \n",
       "2                     0.071040                   0.000542   \n",
       "3                    -0.438880                   0.250207   \n",
       "4                     0.129997                   0.145090   \n",
       "..                         ...                        ...   \n",
       "238                  -0.836972                  -0.548516   \n",
       "239                   0.783896                   0.220783   \n",
       "240                   0.412362                  -0.081254   \n",
       "241                  -0.867862                   1.264494   \n",
       "242                   0.830897                  -0.303122   \n",
       "\n",
       "     EEG_avgRelTheta_version16  EEG_avgRelTheta_version17  \\\n",
       "0                     0.600838                   1.525718   \n",
       "1                     0.549140                  -0.407958   \n",
       "2                    -0.013120                  -1.301350   \n",
       "3                    -0.586296                  -1.285930   \n",
       "4                    -0.022342                  -0.044492   \n",
       "..                         ...                        ...   \n",
       "238                  -0.400114                  -0.470267   \n",
       "239                  -0.532749                   1.270270   \n",
       "240                   0.455668                  -0.314473   \n",
       "241                   0.171264                   2.592219   \n",
       "242                   0.337979                  -0.580070   \n",
       "\n",
       "     EEG_avgRelTheta_version19  EEG_avgRelTheta_version20  \\\n",
       "0                    -0.670571                  -0.187794   \n",
       "1                    -0.583667                  -0.362974   \n",
       "2                     2.782099                  -0.527882   \n",
       "3                    -0.800434                   0.223459   \n",
       "4                     0.151501                  -0.597170   \n",
       "..                         ...                        ...   \n",
       "238                   0.103745                  -0.885969   \n",
       "239                   0.658734                  -2.470410   \n",
       "240                   0.343429                   0.275650   \n",
       "241                  -0.055043                   0.893324   \n",
       "242                  -0.453320                  -0.082636   \n",
       "\n",
       "     EEG_avgRelTheta_version22  EEG_avgRelTheta_version23  \n",
       "0                    -0.169433                  -1.570568  \n",
       "1                    -0.299139                   1.714507  \n",
       "2                    -2.606401                  -0.956030  \n",
       "3                    -0.813627                  -1.177107  \n",
       "4                     0.673852                   0.225974  \n",
       "..                         ...                        ...  \n",
       "238                  -0.295734                   1.204345  \n",
       "239                   0.232322                  -0.655347  \n",
       "240                  -1.532829                   0.771596  \n",
       "241                   1.138795                  -0.651444  \n",
       "242                  -2.247851                   0.815102  \n",
       "\n",
       "[243 rows x 5815 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictors_df = df.iloc[:, 1:(df.shape[1] - 5)]\n",
    "outcomes_df = df.iloc[:, (df.shape[1] - 5):]\n",
    "\n",
    "# Randomize data in all non-selected feature columns\n",
    "for col in predictors_df.columns:\n",
    "    # Don't randomize selected features\n",
    "    if col in selected_features:\n",
    "        continue\n",
    "\n",
    "    predictors_df[col] = np.random.permutation(predictors_df[col].values)\n",
    "\n",
    "display(predictors_df)\n",
    "display(outcomes_df)\n",
    "\n",
    "# Split into train and test\n",
    "predictors_train, predictors_test, outcomes_train, outcomes_test = train_test_split(predictors_df, outcomes_df, test_size = 0.2, random_state = 42)\n",
    "\n",
    "display(predictors_train)\n",
    "display(outcomes_train)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "predictors_train = scaler.fit_transform(predictors_train)\n",
    "predictors_train = pd.DataFrame(predictors_train, columns = predictors_df.columns)\n",
    "predictors_test = scaler.transform(predictors_test)\n",
    "predictors_test = pd.DataFrame(predictors_test, columns = predictors_df.columns)\n",
    "\n",
    "display(predictors_train)\n",
    "\n",
    "# Free up memory\n",
    "del df\n",
    "del predictors_df\n",
    "del outcomes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_hyperparameters(model, predictors, outcome, params, eval_metric):\n",
    "    \"\"\"\n",
    "        Conducts GridSearchCV on a Logistic Regression model to identify suitable hyperparameters\n",
    "\n",
    "        Parameters:\n",
    "            model (sklearn Model): sklearn Model to conduct GridSearchCV on\n",
    "            predictors (Dataframe): pandas Dataframe containing all predictor features\n",
    "            outcome (Series): pandas Series containing all values for the outcome variable\n",
    "            params (dictionary): Dictionary of parameters for GridSearchCV for a LogisticRegression model\n",
    "            eval_metric (string): Name of evaluation metric to use for GridSearchCV\n",
    "\n",
    "        Return:\n",
    "            clf (GridSearchCV): GridSearchCV object after running GridSearchCV with provided parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # Perform 5-fold cross-validation with different regularization strengths and regularization types\n",
    "    clf = GridSearchCV(model, params, cv = 5, scoring = eval_metric, n_jobs = -1)\n",
    "    clf.fit(predictors, outcome)\n",
    "\n",
    "    # Show the best regularization strength and penaalty type\n",
    "    print(\"Best regularization strength:\", clf.best_params_[\"C\"])\n",
    "    print(\"Best l1_ratio:\", clf.best_params_[\"l1_ratio\"])\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regularization strength: 0.1\n",
      "Best l1_ratio: 1\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"l1_ratio\": [0, 0.1, 0.5, 0.9, 1]\n",
    "}\n",
    "\n",
    "SA_func_Log_Reg = LogisticRegression(solver = \"saga\", penalty = \"elasticnet\", max_iter = 10000, fit_intercept = False)\n",
    "SA_GridSearchCV_func = select_hyperparameters(SA_func_Log_Reg, predictors_train, outcomes_train[\"synthetic_outcome\"], params, \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "0.8354591836734695\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(SA_GridSearchCV_func.best_estimator_.coef_ != 0))\n",
    "print(SA_GridSearchCV_func.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Actual Model with Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, fit_intercept=False, l1_ratio=1, max_iter=15000,\n",
       "                   n_jobs=-1, penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, fit_intercept=False, l1_ratio=1, max_iter=15000,\n",
       "                   n_jobs=-1, penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, fit_intercept=False, l1_ratio=1, max_iter=15000,\n",
       "                   n_jobs=-1, penalty='elasticnet', solver='saga')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_model_func = LogisticRegression(max_iter = 15000, penalty = \"elasticnet\", solver = \"saga\", C = 0.1, l1_ratio = 1, n_jobs = -1, fit_intercept = False)\n",
    "SA_model_func.fit(predictors_train, outcomes_train[\"synthetic_outcome\"])\n",
    "SA_model_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(65)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(SA_model_func.coef_ != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fNIRS_S8D6_hbr_timeToMax_version12</th>\n",
       "      <td>0.126171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S6D6_hbr_kurtosis_version17</th>\n",
       "      <td>-1.516998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_p100_poz_version11</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S7D5_hbo_kurtosis_version03</th>\n",
       "      <td>-1.039624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S5D3_hbr_kurtosis_version11</th>\n",
       "      <td>0.102187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    coefficients\n",
       "fNIRS_S8D6_hbr_timeToMax_version12      0.126171\n",
       "fNIRS_S6D6_hbr_kurtosis_version17      -1.516998\n",
       "EEG_p100_poz_version11                  0.000000\n",
       "fNIRS_S7D5_hbo_kurtosis_version03      -1.039624\n",
       "fNIRS_S5D3_hbr_kurtosis_version11       0.102187"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EDA_TonicMin_version23</th>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EYE_corm_version19</th>\n",
       "      <td>-0.020965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EYE_det_version22</th>\n",
       "      <td>0.000511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_avgRelMedAlpha_version10</th>\n",
       "      <td>0.094045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_avgRelFroBeta_version16</th>\n",
       "      <td>-0.046890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S8D6_hbr_RMS_version23</th>\n",
       "      <td>-0.005556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S8D6_hbr_timeToMax_version12</th>\n",
       "      <td>0.126171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S8D6_hbr_timeToMax_version17</th>\n",
       "      <td>0.052640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S8D7_hbo_skew_version05</th>\n",
       "      <td>-0.035306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S8D7_hbr_MaxAmp_version03</th>\n",
       "      <td>-0.031333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    coefficients\n",
       "EDA_TonicMin_version23                 -0.000518\n",
       "EYE_corm_version19                     -0.020965\n",
       "EYE_det_version22                       0.000511\n",
       "EEG_avgRelMedAlpha_version10            0.094045\n",
       "EEG_avgRelFroBeta_version16            -0.046890\n",
       "...                                          ...\n",
       "fNIRS_S8D6_hbr_RMS_version23           -0.005556\n",
       "fNIRS_S8D6_hbr_timeToMax_version12      0.126171\n",
       "fNIRS_S8D6_hbr_timeToMax_version17      0.052640\n",
       "fNIRS_S8D7_hbo_skew_version05          -0.035306\n",
       "fNIRS_S8D7_hbr_MaxAmp_version03        -0.031333\n",
       "\n",
       "[65 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SA_model_func_coef = pd.DataFrame(\n",
    "    data = {\n",
    "        \"coefficients\": SA_model_func.coef_[0]\n",
    "    },\n",
    "    index = np.array(list(predictors_test.columns))\n",
    ")\n",
    "\n",
    "display(SA_model_func_coef.loc[selected_features, :])\n",
    "display(SA_model_func_coef[SA_model_func_coef[\"coefficients\"] != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metrics(model, predictors, outcome):\n",
    "    \"\"\"\n",
    "        Plots confusion matrix and ROC-AUC curve for a fitted sklearn model\n",
    "\n",
    "        Parameters:\n",
    "            model (sklearn Model): sklearn model to predict outcome values\n",
    "            predictors (DataFrame): pandas Dataframe containing all predictor features\n",
    "            outcome (Series): pandas Series containing all values for the outcome variable\n",
    "            display_labels (list(str)): List of 2 strings for labeling the 0 and 1 outputs for confusion matrix\n",
    "\n",
    "        Return:\n",
    "            None\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_outcomes = model.predict(predictors)\n",
    "    print(\"Accuracy: \", accuracy_score(predicted_outcomes, outcome))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = metrics.confusion_matrix(outcome, predicted_outcomes)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm)\n",
    "    cm_display.plot()\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(outcome, predicted_outcomes)\n",
    "    roc_auc  = metrics.auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, label = \"ROC Curve (area = %0.3f)\" % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], \"k--\") # Random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9508196721311475\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_eval_metrics(SA_model_func, predictors_test, outcomes_test[\"synthetic_outcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
