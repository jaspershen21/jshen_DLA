{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>EDA_TonicMean_version02</th>\n",
       "      <th>EDA_TonicMean_version03</th>\n",
       "      <th>EDA_TonicMean_version04</th>\n",
       "      <th>EDA_TonicMean_version05</th>\n",
       "      <th>EDA_TonicMean_version09</th>\n",
       "      <th>EDA_TonicMean_version10</th>\n",
       "      <th>EDA_TonicMean_version11</th>\n",
       "      <th>EDA_TonicMean_version12</th>\n",
       "      <th>EDA_TonicMean_version16</th>\n",
       "      <th>...</th>\n",
       "      <th>EEG_avgRelTheta_version16</th>\n",
       "      <th>EEG_avgRelTheta_version17</th>\n",
       "      <th>EEG_avgRelTheta_version19</th>\n",
       "      <th>EEG_avgRelTheta_version20</th>\n",
       "      <th>EEG_avgRelTheta_version22</th>\n",
       "      <th>EEG_avgRelTheta_version23</th>\n",
       "      <th>adjSA1</th>\n",
       "      <th>adjSA2</th>\n",
       "      <th>adjSA3</th>\n",
       "      <th>adjSAtotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.123031</td>\n",
       "      <td>-0.226077</td>\n",
       "      <td>-1.220480</td>\n",
       "      <td>-1.697738</td>\n",
       "      <td>-0.273200</td>\n",
       "      <td>-0.601171</td>\n",
       "      <td>-0.809518</td>\n",
       "      <td>-1.012558</td>\n",
       "      <td>-0.299118</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.877017</td>\n",
       "      <td>-1.442056</td>\n",
       "      <td>1.070298</td>\n",
       "      <td>1.277417</td>\n",
       "      <td>0.249605</td>\n",
       "      <td>0.400156</td>\n",
       "      <td>0.119790</td>\n",
       "      <td>1.593122</td>\n",
       "      <td>-0.800726</td>\n",
       "      <td>0.350233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.152896</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>1.527067</td>\n",
       "      <td>1.883468</td>\n",
       "      <td>-0.378060</td>\n",
       "      <td>-0.018812</td>\n",
       "      <td>1.023216</td>\n",
       "      <td>1.189124</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.632698</td>\n",
       "      <td>-1.531970</td>\n",
       "      <td>1.779032</td>\n",
       "      <td>1.074498</td>\n",
       "      <td>0.409991</td>\n",
       "      <td>0.333842</td>\n",
       "      <td>0.075246</td>\n",
       "      <td>-1.663383</td>\n",
       "      <td>0.859309</td>\n",
       "      <td>-0.262893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.166035</td>\n",
       "      <td>-0.181478</td>\n",
       "      <td>1.634437</td>\n",
       "      <td>0.904620</td>\n",
       "      <td>-0.424192</td>\n",
       "      <td>-0.452936</td>\n",
       "      <td>1.123414</td>\n",
       "      <td>0.534554</td>\n",
       "      <td>-0.380039</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.489450</td>\n",
       "      <td>-1.448590</td>\n",
       "      <td>2.194570</td>\n",
       "      <td>1.262672</td>\n",
       "      <td>0.504028</td>\n",
       "      <td>0.395338</td>\n",
       "      <td>-1.072729</td>\n",
       "      <td>0.879836</td>\n",
       "      <td>-1.542415</td>\n",
       "      <td>-0.938513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.231095</td>\n",
       "      <td>-0.209571</td>\n",
       "      <td>1.654951</td>\n",
       "      <td>1.247081</td>\n",
       "      <td>-0.652624</td>\n",
       "      <td>-0.546311</td>\n",
       "      <td>1.214370</td>\n",
       "      <td>0.821624</td>\n",
       "      <td>-0.502463</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.353433</td>\n",
       "      <td>-1.059878</td>\n",
       "      <td>2.589134</td>\n",
       "      <td>2.139926</td>\n",
       "      <td>0.593317</td>\n",
       "      <td>0.682023</td>\n",
       "      <td>-0.643181</td>\n",
       "      <td>-0.217332</td>\n",
       "      <td>0.945816</td>\n",
       "      <td>0.145041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.236090</td>\n",
       "      <td>-0.323013</td>\n",
       "      <td>-0.478244</td>\n",
       "      <td>-1.080788</td>\n",
       "      <td>-0.670161</td>\n",
       "      <td>-0.923364</td>\n",
       "      <td>-0.421866</td>\n",
       "      <td>-0.775114</td>\n",
       "      <td>-0.511862</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.443846</td>\n",
       "      <td>-0.627980</td>\n",
       "      <td>2.326862</td>\n",
       "      <td>3.114644</td>\n",
       "      <td>0.533965</td>\n",
       "      <td>1.000560</td>\n",
       "      <td>-0.323098</td>\n",
       "      <td>0.712401</td>\n",
       "      <td>-1.473404</td>\n",
       "      <td>-0.642872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5820 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  EDA_TonicMean_version02  EDA_TonicMean_version03  \\\n",
       "0   5                -0.123031                -0.226077   \n",
       "1   5                -0.152896                -0.050866   \n",
       "2   5                -0.166035                -0.181478   \n",
       "3   5                -0.231095                -0.209571   \n",
       "4   5                -0.236090                -0.323013   \n",
       "\n",
       "   EDA_TonicMean_version04  EDA_TonicMean_version05  EDA_TonicMean_version09  \\\n",
       "0                -1.220480                -1.697738                -0.273200   \n",
       "1                 1.527067                 1.883468                -0.378060   \n",
       "2                 1.634437                 0.904620                -0.424192   \n",
       "3                 1.654951                 1.247081                -0.652624   \n",
       "4                -0.478244                -1.080788                -0.670161   \n",
       "\n",
       "   EDA_TonicMean_version10  EDA_TonicMean_version11  EDA_TonicMean_version12  \\\n",
       "0                -0.601171                -0.809518                -1.012558   \n",
       "1                -0.018812                 1.023216                 1.189124   \n",
       "2                -0.452936                 1.123414                 0.534554   \n",
       "3                -0.546311                 1.214370                 0.821624   \n",
       "4                -0.923364                -0.421866                -0.775114   \n",
       "\n",
       "   EDA_TonicMean_version16  ...  EEG_avgRelTheta_version16  \\\n",
       "0                -0.299118  ...                  -1.877017   \n",
       "1                -0.355315  ...                  -1.632698   \n",
       "2                -0.380039  ...                  -1.489450   \n",
       "3                -0.502463  ...                  -1.353433   \n",
       "4                -0.511862  ...                  -1.443846   \n",
       "\n",
       "   EEG_avgRelTheta_version17  EEG_avgRelTheta_version19  \\\n",
       "0                  -1.442056                   1.070298   \n",
       "1                  -1.531970                   1.779032   \n",
       "2                  -1.448590                   2.194570   \n",
       "3                  -1.059878                   2.589134   \n",
       "4                  -0.627980                   2.326862   \n",
       "\n",
       "   EEG_avgRelTheta_version20  EEG_avgRelTheta_version22  \\\n",
       "0                   1.277417                   0.249605   \n",
       "1                   1.074498                   0.409991   \n",
       "2                   1.262672                   0.504028   \n",
       "3                   2.139926                   0.593317   \n",
       "4                   3.114644                   0.533965   \n",
       "\n",
       "   EEG_avgRelTheta_version23    adjSA1    adjSA2    adjSA3  adjSAtotal  \n",
       "0                   0.400156  0.119790  1.593122 -0.800726    0.350233  \n",
       "1                   0.333842  0.075246 -1.663383  0.859309   -0.262893  \n",
       "2                   0.395338 -1.072729  0.879836 -1.542415   -0.938513  \n",
       "3                   0.682023 -0.643181 -0.217332  0.945816    0.145041  \n",
       "4                   1.000560 -0.323098  0.712401 -1.473404   -0.642872  \n",
       "\n",
       "[5 rows x 5820 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"./kieranFeatures_1-30_26-Sep-2024.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Outcome Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary variables for high and low \n",
    "adj_SA_1_median = np.median(df[\"adjSA1\"])\n",
    "adj_SA_2_median = np.median(df[\"adjSA2\"])\n",
    "adj_SA_3_median = np.median(df[\"adjSA3\"])\n",
    "adj_SA_tot_median = np.median(df[\"adjSAtotal\"])\n",
    "\n",
    "# Will be high if adjusted SA level score is equal to or above median, low otherwise\n",
    "df[\"Lv_1_Hi\"] = (df[\"adjSA1\"] >= adj_SA_1_median).astype(int)\n",
    "df[\"Lv_2_Hi\"] = (df[\"adjSA2\"] >= adj_SA_2_median).astype(int)\n",
    "df[\"Lv_3_Hi\"] = (df[\"adjSA3\"] >= adj_SA_3_median).astype(int)\n",
    "df[\"Tot_Hi\"] = (df[\"adjSAtotal\"] >= adj_SA_tot_median).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide up dataframe into predictors and outcomes. Train-test-split the following data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDA_TonicMean_version02</th>\n",
       "      <th>EDA_TonicMean_version03</th>\n",
       "      <th>EDA_TonicMean_version04</th>\n",
       "      <th>EDA_TonicMean_version05</th>\n",
       "      <th>EDA_TonicMean_version09</th>\n",
       "      <th>EDA_TonicMean_version10</th>\n",
       "      <th>EDA_TonicMean_version11</th>\n",
       "      <th>EDA_TonicMean_version12</th>\n",
       "      <th>EDA_TonicMean_version16</th>\n",
       "      <th>EDA_TonicMean_version17</th>\n",
       "      <th>...</th>\n",
       "      <th>EEG_avgRelTheta_version09</th>\n",
       "      <th>EEG_avgRelTheta_version10</th>\n",
       "      <th>EEG_avgRelTheta_version11</th>\n",
       "      <th>EEG_avgRelTheta_version12</th>\n",
       "      <th>EEG_avgRelTheta_version16</th>\n",
       "      <th>EEG_avgRelTheta_version17</th>\n",
       "      <th>EEG_avgRelTheta_version19</th>\n",
       "      <th>EEG_avgRelTheta_version20</th>\n",
       "      <th>EEG_avgRelTheta_version22</th>\n",
       "      <th>EEG_avgRelTheta_version23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.123031</td>\n",
       "      <td>-0.226077</td>\n",
       "      <td>-1.220480</td>\n",
       "      <td>-1.697738</td>\n",
       "      <td>-0.273200</td>\n",
       "      <td>-0.601171</td>\n",
       "      <td>-0.809518</td>\n",
       "      <td>-1.012558</td>\n",
       "      <td>-0.299118</td>\n",
       "      <td>-0.469374</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.470055</td>\n",
       "      <td>-1.633813</td>\n",
       "      <td>-1.521523</td>\n",
       "      <td>-1.189742</td>\n",
       "      <td>-1.877017</td>\n",
       "      <td>-1.442056</td>\n",
       "      <td>1.070298</td>\n",
       "      <td>1.277417</td>\n",
       "      <td>0.249605</td>\n",
       "      <td>0.400156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.152896</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>1.527067</td>\n",
       "      <td>1.883468</td>\n",
       "      <td>-0.378060</td>\n",
       "      <td>-0.018812</td>\n",
       "      <td>1.023216</td>\n",
       "      <td>1.189124</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>-0.160570</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.999027</td>\n",
       "      <td>-1.796969</td>\n",
       "      <td>-0.890211</td>\n",
       "      <td>-0.846923</td>\n",
       "      <td>-1.632698</td>\n",
       "      <td>-1.531970</td>\n",
       "      <td>1.779032</td>\n",
       "      <td>1.074498</td>\n",
       "      <td>0.409991</td>\n",
       "      <td>0.333842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.166035</td>\n",
       "      <td>-0.181478</td>\n",
       "      <td>1.634437</td>\n",
       "      <td>0.904620</td>\n",
       "      <td>-0.424192</td>\n",
       "      <td>-0.452936</td>\n",
       "      <td>1.123414</td>\n",
       "      <td>0.534554</td>\n",
       "      <td>-0.380039</td>\n",
       "      <td>-0.390771</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.722859</td>\n",
       "      <td>-1.645669</td>\n",
       "      <td>-0.543299</td>\n",
       "      <td>-0.588502</td>\n",
       "      <td>-1.489450</td>\n",
       "      <td>-1.448590</td>\n",
       "      <td>2.194570</td>\n",
       "      <td>1.262672</td>\n",
       "      <td>0.504028</td>\n",
       "      <td>0.395338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.231095</td>\n",
       "      <td>-0.209571</td>\n",
       "      <td>1.654951</td>\n",
       "      <td>1.247081</td>\n",
       "      <td>-0.652624</td>\n",
       "      <td>-0.546311</td>\n",
       "      <td>1.214370</td>\n",
       "      <td>0.821624</td>\n",
       "      <td>-0.502463</td>\n",
       "      <td>-0.440284</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.460630</td>\n",
       "      <td>-0.940319</td>\n",
       "      <td>-0.955926</td>\n",
       "      <td>-0.744128</td>\n",
       "      <td>-1.353433</td>\n",
       "      <td>-1.059878</td>\n",
       "      <td>2.589134</td>\n",
       "      <td>2.139926</td>\n",
       "      <td>0.593317</td>\n",
       "      <td>0.682023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.236090</td>\n",
       "      <td>-0.323013</td>\n",
       "      <td>-0.478244</td>\n",
       "      <td>-1.080788</td>\n",
       "      <td>-0.670161</td>\n",
       "      <td>-0.923364</td>\n",
       "      <td>-0.421866</td>\n",
       "      <td>-0.775114</td>\n",
       "      <td>-0.511862</td>\n",
       "      <td>-0.640221</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.634937</td>\n",
       "      <td>-0.156605</td>\n",
       "      <td>-0.344389</td>\n",
       "      <td>0.214848</td>\n",
       "      <td>-1.443846</td>\n",
       "      <td>-0.627980</td>\n",
       "      <td>2.326862</td>\n",
       "      <td>3.114644</td>\n",
       "      <td>0.533965</td>\n",
       "      <td>1.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>-0.390463</td>\n",
       "      <td>-0.392143</td>\n",
       "      <td>-0.150550</td>\n",
       "      <td>-0.112208</td>\n",
       "      <td>-0.248912</td>\n",
       "      <td>-0.241573</td>\n",
       "      <td>-0.239724</td>\n",
       "      <td>-0.191818</td>\n",
       "      <td>-0.336535</td>\n",
       "      <td>-0.330997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046622</td>\n",
       "      <td>-0.464843</td>\n",
       "      <td>0.523703</td>\n",
       "      <td>0.110708</td>\n",
       "      <td>0.163210</td>\n",
       "      <td>-0.308442</td>\n",
       "      <td>0.105745</td>\n",
       "      <td>-0.391989</td>\n",
       "      <td>0.798338</td>\n",
       "      <td>-0.432294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-0.369596</td>\n",
       "      <td>-0.380586</td>\n",
       "      <td>-0.609280</td>\n",
       "      <td>-0.487820</td>\n",
       "      <td>-0.175647</td>\n",
       "      <td>-0.203160</td>\n",
       "      <td>-0.582746</td>\n",
       "      <td>-0.450147</td>\n",
       "      <td>-0.286580</td>\n",
       "      <td>-0.305082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102853</td>\n",
       "      <td>-0.200243</td>\n",
       "      <td>0.539456</td>\n",
       "      <td>0.390624</td>\n",
       "      <td>0.101655</td>\n",
       "      <td>-0.000704</td>\n",
       "      <td>0.021136</td>\n",
       "      <td>-0.062902</td>\n",
       "      <td>0.571962</td>\n",
       "      <td>0.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-0.457362</td>\n",
       "      <td>-0.382835</td>\n",
       "      <td>-1.247644</td>\n",
       "      <td>-0.132967</td>\n",
       "      <td>-0.483803</td>\n",
       "      <td>-0.210636</td>\n",
       "      <td>-1.131586</td>\n",
       "      <td>-0.204537</td>\n",
       "      <td>-0.496694</td>\n",
       "      <td>-0.310125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160880</td>\n",
       "      <td>-0.095837</td>\n",
       "      <td>2.240786</td>\n",
       "      <td>1.697116</td>\n",
       "      <td>0.390354</td>\n",
       "      <td>0.120724</td>\n",
       "      <td>0.417964</td>\n",
       "      <td>0.066950</td>\n",
       "      <td>1.633695</td>\n",
       "      <td>0.299016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-0.370669</td>\n",
       "      <td>-0.390531</td>\n",
       "      <td>-1.078873</td>\n",
       "      <td>-0.866528</td>\n",
       "      <td>-0.179415</td>\n",
       "      <td>-0.236215</td>\n",
       "      <td>-0.917973</td>\n",
       "      <td>-0.699119</td>\n",
       "      <td>-0.289149</td>\n",
       "      <td>-0.327382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.394919</td>\n",
       "      <td>-0.514674</td>\n",
       "      <td>-0.292277</td>\n",
       "      <td>-0.368327</td>\n",
       "      <td>-0.218058</td>\n",
       "      <td>-0.366396</td>\n",
       "      <td>-0.418322</td>\n",
       "      <td>-0.453964</td>\n",
       "      <td>-0.603831</td>\n",
       "      <td>-0.531050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-0.375119</td>\n",
       "      <td>-0.381095</td>\n",
       "      <td>-0.045532</td>\n",
       "      <td>-0.083454</td>\n",
       "      <td>-0.195039</td>\n",
       "      <td>-0.204852</td>\n",
       "      <td>-0.151317</td>\n",
       "      <td>-0.168047</td>\n",
       "      <td>-0.299802</td>\n",
       "      <td>-0.306223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.386655</td>\n",
       "      <td>0.364642</td>\n",
       "      <td>-0.872179</td>\n",
       "      <td>-0.296389</td>\n",
       "      <td>-0.209012</td>\n",
       "      <td>0.656275</td>\n",
       "      <td>-0.405888</td>\n",
       "      <td>0.639655</td>\n",
       "      <td>-0.570563</td>\n",
       "      <td>1.211611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows Ã— 5815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EDA_TonicMean_version02  EDA_TonicMean_version03  \\\n",
       "0                  -0.123031                -0.226077   \n",
       "1                  -0.152896                -0.050866   \n",
       "2                  -0.166035                -0.181478   \n",
       "3                  -0.231095                -0.209571   \n",
       "4                  -0.236090                -0.323013   \n",
       "..                       ...                      ...   \n",
       "299                -0.390463                -0.392143   \n",
       "300                -0.369596                -0.380586   \n",
       "301                -0.457362                -0.382835   \n",
       "302                -0.370669                -0.390531   \n",
       "303                -0.375119                -0.381095   \n",
       "\n",
       "     EDA_TonicMean_version04  EDA_TonicMean_version05  \\\n",
       "0                  -1.220480                -1.697738   \n",
       "1                   1.527067                 1.883468   \n",
       "2                   1.634437                 0.904620   \n",
       "3                   1.654951                 1.247081   \n",
       "4                  -0.478244                -1.080788   \n",
       "..                       ...                      ...   \n",
       "299                -0.150550                -0.112208   \n",
       "300                -0.609280                -0.487820   \n",
       "301                -1.247644                -0.132967   \n",
       "302                -1.078873                -0.866528   \n",
       "303                -0.045532                -0.083454   \n",
       "\n",
       "     EDA_TonicMean_version09  EDA_TonicMean_version10  \\\n",
       "0                  -0.273200                -0.601171   \n",
       "1                  -0.378060                -0.018812   \n",
       "2                  -0.424192                -0.452936   \n",
       "3                  -0.652624                -0.546311   \n",
       "4                  -0.670161                -0.923364   \n",
       "..                       ...                      ...   \n",
       "299                -0.248912                -0.241573   \n",
       "300                -0.175647                -0.203160   \n",
       "301                -0.483803                -0.210636   \n",
       "302                -0.179415                -0.236215   \n",
       "303                -0.195039                -0.204852   \n",
       "\n",
       "     EDA_TonicMean_version11  EDA_TonicMean_version12  \\\n",
       "0                  -0.809518                -1.012558   \n",
       "1                   1.023216                 1.189124   \n",
       "2                   1.123414                 0.534554   \n",
       "3                   1.214370                 0.821624   \n",
       "4                  -0.421866                -0.775114   \n",
       "..                       ...                      ...   \n",
       "299                -0.239724                -0.191818   \n",
       "300                -0.582746                -0.450147   \n",
       "301                -1.131586                -0.204537   \n",
       "302                -0.917973                -0.699119   \n",
       "303                -0.151317                -0.168047   \n",
       "\n",
       "     EDA_TonicMean_version16  EDA_TonicMean_version17  ...  \\\n",
       "0                  -0.299118                -0.469374  ...   \n",
       "1                  -0.355315                -0.160570  ...   \n",
       "2                  -0.380039                -0.390771  ...   \n",
       "3                  -0.502463                -0.440284  ...   \n",
       "4                  -0.511862                -0.640221  ...   \n",
       "..                       ...                      ...  ...   \n",
       "299                -0.336535                -0.330997  ...   \n",
       "300                -0.286580                -0.305082  ...   \n",
       "301                -0.496694                -0.310125  ...   \n",
       "302                -0.289149                -0.327382  ...   \n",
       "303                -0.299802                -0.306223  ...   \n",
       "\n",
       "     EEG_avgRelTheta_version09  EEG_avgRelTheta_version10  \\\n",
       "0                    -2.470055                  -1.633813   \n",
       "1                    -1.999027                  -1.796969   \n",
       "2                    -1.722859                  -1.645669   \n",
       "3                    -1.460630                  -0.940319   \n",
       "4                    -1.634937                  -0.156605   \n",
       "..                         ...                        ...   \n",
       "299                  -0.046622                  -0.464843   \n",
       "300                  -0.102853                  -0.200243   \n",
       "301                   0.160880                  -0.095837   \n",
       "302                  -0.394919                  -0.514674   \n",
       "303                  -0.386655                   0.364642   \n",
       "\n",
       "     EEG_avgRelTheta_version11  EEG_avgRelTheta_version12  \\\n",
       "0                    -1.521523                  -1.189742   \n",
       "1                    -0.890211                  -0.846923   \n",
       "2                    -0.543299                  -0.588502   \n",
       "3                    -0.955926                  -0.744128   \n",
       "4                    -0.344389                   0.214848   \n",
       "..                         ...                        ...   \n",
       "299                   0.523703                   0.110708   \n",
       "300                   0.539456                   0.390624   \n",
       "301                   2.240786                   1.697116   \n",
       "302                  -0.292277                  -0.368327   \n",
       "303                  -0.872179                  -0.296389   \n",
       "\n",
       "     EEG_avgRelTheta_version16  EEG_avgRelTheta_version17  \\\n",
       "0                    -1.877017                  -1.442056   \n",
       "1                    -1.632698                  -1.531970   \n",
       "2                    -1.489450                  -1.448590   \n",
       "3                    -1.353433                  -1.059878   \n",
       "4                    -1.443846                  -0.627980   \n",
       "..                         ...                        ...   \n",
       "299                   0.163210                  -0.308442   \n",
       "300                   0.101655                  -0.000704   \n",
       "301                   0.390354                   0.120724   \n",
       "302                  -0.218058                  -0.366396   \n",
       "303                  -0.209012                   0.656275   \n",
       "\n",
       "     EEG_avgRelTheta_version19  EEG_avgRelTheta_version20  \\\n",
       "0                     1.070298                   1.277417   \n",
       "1                     1.779032                   1.074498   \n",
       "2                     2.194570                   1.262672   \n",
       "3                     2.589134                   2.139926   \n",
       "4                     2.326862                   3.114644   \n",
       "..                         ...                        ...   \n",
       "299                   0.105745                  -0.391989   \n",
       "300                   0.021136                  -0.062902   \n",
       "301                   0.417964                   0.066950   \n",
       "302                  -0.418322                  -0.453964   \n",
       "303                  -0.405888                   0.639655   \n",
       "\n",
       "     EEG_avgRelTheta_version22  EEG_avgRelTheta_version23  \n",
       "0                     0.249605                   0.400156  \n",
       "1                     0.409991                   0.333842  \n",
       "2                     0.504028                   0.395338  \n",
       "3                     0.593317                   0.682023  \n",
       "4                     0.533965                   1.000560  \n",
       "..                         ...                        ...  \n",
       "299                   0.798338                  -0.432294  \n",
       "300                   0.571962                   0.092100  \n",
       "301                   1.633695                   0.299016  \n",
       "302                  -0.603831                  -0.531050  \n",
       "303                  -0.570563                   1.211611  \n",
       "\n",
       "[304 rows x 5815 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjSA1</th>\n",
       "      <th>adjSA2</th>\n",
       "      <th>adjSA3</th>\n",
       "      <th>adjSAtotal</th>\n",
       "      <th>Lv_1_Hi</th>\n",
       "      <th>Lv_2_Hi</th>\n",
       "      <th>Lv_3_Hi</th>\n",
       "      <th>Tot_Hi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.119790</td>\n",
       "      <td>1.593122</td>\n",
       "      <td>-0.800726</td>\n",
       "      <td>0.350233</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.075246</td>\n",
       "      <td>-1.663383</td>\n",
       "      <td>0.859309</td>\n",
       "      <td>-0.262893</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.072729</td>\n",
       "      <td>0.879836</td>\n",
       "      <td>-1.542415</td>\n",
       "      <td>-0.938513</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.643181</td>\n",
       "      <td>-0.217332</td>\n",
       "      <td>0.945816</td>\n",
       "      <td>0.145041</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.323098</td>\n",
       "      <td>0.712401</td>\n",
       "      <td>-1.473404</td>\n",
       "      <td>-0.642872</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.076099</td>\n",
       "      <td>1.105227</td>\n",
       "      <td>-0.609431</td>\n",
       "      <td>0.209332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-0.258249</td>\n",
       "      <td>-0.360422</td>\n",
       "      <td>0.778641</td>\n",
       "      <td>0.155357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.110240</td>\n",
       "      <td>0.092504</td>\n",
       "      <td>0.945232</td>\n",
       "      <td>0.627581</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-1.105639</td>\n",
       "      <td>0.426616</td>\n",
       "      <td>0.328063</td>\n",
       "      <td>-0.108335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1.141504</td>\n",
       "      <td>1.452440</td>\n",
       "      <td>0.883889</td>\n",
       "      <td>1.694167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adjSA1    adjSA2    adjSA3  adjSAtotal  Lv_1_Hi  Lv_2_Hi  Lv_3_Hi  \\\n",
       "0    0.119790  1.593122 -0.800726    0.350233        1        1        0   \n",
       "1    0.075246 -1.663383  0.859309   -0.262893        0        0        1   \n",
       "2   -1.072729  0.879836 -1.542415   -0.938513        0        1        0   \n",
       "3   -0.643181 -0.217332  0.945816    0.145041        0        0        1   \n",
       "4   -0.323098  0.712401 -1.473404   -0.642872        0        1        0   \n",
       "..        ...       ...       ...         ...      ...      ...      ...   \n",
       "299  0.076099  1.105227 -0.609431    0.209332        0        1        0   \n",
       "300 -0.258249 -0.360422  0.778641    0.155357        0        0        1   \n",
       "301  0.110240  0.092504  0.945232    0.627581        1        1        1   \n",
       "302 -1.105639  0.426616  0.328063   -0.108335        0        1        1   \n",
       "303  1.141504  1.452440  0.883889    1.694167        1        1        1   \n",
       "\n",
       "     Tot_Hi  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "299       1  \n",
       "300       1  \n",
       "301       1  \n",
       "302       0  \n",
       "303       1  \n",
       "\n",
       "[304 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDA_TonicMean_version02</th>\n",
       "      <th>EDA_TonicMean_version03</th>\n",
       "      <th>EDA_TonicMean_version04</th>\n",
       "      <th>EDA_TonicMean_version05</th>\n",
       "      <th>EDA_TonicMean_version09</th>\n",
       "      <th>EDA_TonicMean_version10</th>\n",
       "      <th>EDA_TonicMean_version11</th>\n",
       "      <th>EDA_TonicMean_version12</th>\n",
       "      <th>EDA_TonicMean_version16</th>\n",
       "      <th>EDA_TonicMean_version17</th>\n",
       "      <th>...</th>\n",
       "      <th>EEG_avgRelTheta_version09</th>\n",
       "      <th>EEG_avgRelTheta_version10</th>\n",
       "      <th>EEG_avgRelTheta_version11</th>\n",
       "      <th>EEG_avgRelTheta_version12</th>\n",
       "      <th>EEG_avgRelTheta_version16</th>\n",
       "      <th>EEG_avgRelTheta_version17</th>\n",
       "      <th>EEG_avgRelTheta_version19</th>\n",
       "      <th>EEG_avgRelTheta_version20</th>\n",
       "      <th>EEG_avgRelTheta_version22</th>\n",
       "      <th>EEG_avgRelTheta_version23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>-0.494618</td>\n",
       "      <td>-0.555541</td>\n",
       "      <td>-2.076390</td>\n",
       "      <td>-1.869410</td>\n",
       "      <td>0.597167</td>\n",
       "      <td>0.362062</td>\n",
       "      <td>-1.765695</td>\n",
       "      <td>-1.479098</td>\n",
       "      <td>0.418093</td>\n",
       "      <td>0.161042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462172</td>\n",
       "      <td>0.859784</td>\n",
       "      <td>-0.051114</td>\n",
       "      <td>0.233826</td>\n",
       "      <td>0.237753</td>\n",
       "      <td>0.649436</td>\n",
       "      <td>0.111443</td>\n",
       "      <td>0.465456</td>\n",
       "      <td>0.779651</td>\n",
       "      <td>0.627392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>-0.495506</td>\n",
       "      <td>-0.500435</td>\n",
       "      <td>-0.131699</td>\n",
       "      <td>-0.129467</td>\n",
       "      <td>-0.662698</td>\n",
       "      <td>-0.644065</td>\n",
       "      <td>-0.258565</td>\n",
       "      <td>-0.237457</td>\n",
       "      <td>-0.612173</td>\n",
       "      <td>-0.596055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260123</td>\n",
       "      <td>1.010109</td>\n",
       "      <td>-0.213657</td>\n",
       "      <td>0.601153</td>\n",
       "      <td>-0.307295</td>\n",
       "      <td>0.907735</td>\n",
       "      <td>-0.047399</td>\n",
       "      <td>1.014504</td>\n",
       "      <td>0.237016</td>\n",
       "      <td>1.841947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.297909</td>\n",
       "      <td>0.310984</td>\n",
       "      <td>-1.254804</td>\n",
       "      <td>-0.683124</td>\n",
       "      <td>-0.014281</td>\n",
       "      <td>0.030278</td>\n",
       "      <td>-0.612785</td>\n",
       "      <td>-0.323310</td>\n",
       "      <td>-0.147675</td>\n",
       "      <td>-0.124319</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.458536</td>\n",
       "      <td>-2.291505</td>\n",
       "      <td>-0.823308</td>\n",
       "      <td>-1.187300</td>\n",
       "      <td>-1.355405</td>\n",
       "      <td>-1.868532</td>\n",
       "      <td>-0.703187</td>\n",
       "      <td>-1.310684</td>\n",
       "      <td>-0.785986</td>\n",
       "      <td>-1.462410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.751382</td>\n",
       "      <td>-0.767114</td>\n",
       "      <td>0.220138</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>-1.119621</td>\n",
       "      <td>-1.112651</td>\n",
       "      <td>0.082926</td>\n",
       "      <td>-0.217642</td>\n",
       "      <td>-1.034901</td>\n",
       "      <td>-1.023674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084950</td>\n",
       "      <td>-0.236394</td>\n",
       "      <td>-1.212890</td>\n",
       "      <td>-1.107865</td>\n",
       "      <td>-0.042654</td>\n",
       "      <td>-0.178245</td>\n",
       "      <td>-0.830580</td>\n",
       "      <td>-0.678148</td>\n",
       "      <td>-1.206773</td>\n",
       "      <td>-0.626839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-0.354384</td>\n",
       "      <td>-0.332566</td>\n",
       "      <td>-1.195093</td>\n",
       "      <td>-0.569050</td>\n",
       "      <td>-1.246429</td>\n",
       "      <td>-1.107403</td>\n",
       "      <td>-0.981167</td>\n",
       "      <td>-0.478398</td>\n",
       "      <td>-0.795857</td>\n",
       "      <td>-0.715333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509455</td>\n",
       "      <td>0.654922</td>\n",
       "      <td>0.548907</td>\n",
       "      <td>0.656188</td>\n",
       "      <td>0.507635</td>\n",
       "      <td>0.712548</td>\n",
       "      <td>-0.440298</td>\n",
       "      <td>0.200804</td>\n",
       "      <td>-0.601341</td>\n",
       "      <td>0.526651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-0.297054</td>\n",
       "      <td>-0.307219</td>\n",
       "      <td>-0.661230</td>\n",
       "      <td>-0.513394</td>\n",
       "      <td>-1.014946</td>\n",
       "      <td>-0.994582</td>\n",
       "      <td>-0.575531</td>\n",
       "      <td>-0.431628</td>\n",
       "      <td>-0.679828</td>\n",
       "      <td>-0.661295</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.726769</td>\n",
       "      <td>-1.195044</td>\n",
       "      <td>-0.629046</td>\n",
       "      <td>-0.860808</td>\n",
       "      <td>-0.798998</td>\n",
       "      <td>-1.181357</td>\n",
       "      <td>0.012439</td>\n",
       "      <td>-0.598611</td>\n",
       "      <td>0.566104</td>\n",
       "      <td>-0.681974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.559570</td>\n",
       "      <td>-0.562361</td>\n",
       "      <td>1.381119</td>\n",
       "      <td>0.854606</td>\n",
       "      <td>-0.446144</td>\n",
       "      <td>-0.432101</td>\n",
       "      <td>1.443925</td>\n",
       "      <td>0.759285</td>\n",
       "      <td>-0.517737</td>\n",
       "      <td>-0.506605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597457</td>\n",
       "      <td>0.281063</td>\n",
       "      <td>-0.908693</td>\n",
       "      <td>-0.867127</td>\n",
       "      <td>0.619710</td>\n",
       "      <td>0.355382</td>\n",
       "      <td>0.196207</td>\n",
       "      <td>-0.034579</td>\n",
       "      <td>0.716476</td>\n",
       "      <td>0.070465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.362930</td>\n",
       "      <td>-0.376268</td>\n",
       "      <td>-0.392341</td>\n",
       "      <td>-0.370327</td>\n",
       "      <td>-0.500164</td>\n",
       "      <td>-0.518055</td>\n",
       "      <td>-0.417380</td>\n",
       "      <td>-0.369009</td>\n",
       "      <td>-0.471410</td>\n",
       "      <td>-0.478937</td>\n",
       "      <td>...</td>\n",
       "      <td>1.048729</td>\n",
       "      <td>1.497494</td>\n",
       "      <td>-0.488310</td>\n",
       "      <td>-0.037478</td>\n",
       "      <td>1.458071</td>\n",
       "      <td>2.088352</td>\n",
       "      <td>-0.736493</td>\n",
       "      <td>0.362864</td>\n",
       "      <td>-1.311561</td>\n",
       "      <td>0.741032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-0.663595</td>\n",
       "      <td>-0.680655</td>\n",
       "      <td>-0.323792</td>\n",
       "      <td>-0.360686</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>-0.053789</td>\n",
       "      <td>-0.548041</td>\n",
       "      <td>-0.547836</td>\n",
       "      <td>-0.197162</td>\n",
       "      <td>-0.265638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846641</td>\n",
       "      <td>1.038962</td>\n",
       "      <td>0.487292</td>\n",
       "      <td>0.634474</td>\n",
       "      <td>0.559359</td>\n",
       "      <td>0.808679</td>\n",
       "      <td>0.689936</td>\n",
       "      <td>0.688303</td>\n",
       "      <td>2.265877</td>\n",
       "      <td>0.874194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.219538</td>\n",
       "      <td>-0.209273</td>\n",
       "      <td>-0.103224</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.036997</td>\n",
       "      <td>-0.163482</td>\n",
       "      <td>-0.066556</td>\n",
       "      <td>-0.158862</td>\n",
       "      <td>-0.138007</td>\n",
       "      <td>...</td>\n",
       "      <td>1.671283</td>\n",
       "      <td>1.827563</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>1.212934</td>\n",
       "      <td>2.163855</td>\n",
       "      <td>2.485919</td>\n",
       "      <td>0.200236</td>\n",
       "      <td>0.773377</td>\n",
       "      <td>0.940547</td>\n",
       "      <td>1.372242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 5815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EDA_TonicMean_version02  EDA_TonicMean_version03  \\\n",
       "269                -0.494618                -0.555541   \n",
       "211                -0.495506                -0.500435   \n",
       "197                 0.297909                 0.310984   \n",
       "75                 -0.751382                -0.767114   \n",
       "177                -0.354384                -0.332566   \n",
       "..                       ...                      ...   \n",
       "188                -0.297054                -0.307219   \n",
       "71                 -0.559570                -0.562361   \n",
       "106                -0.362930                -0.376268   \n",
       "270                -0.663595                -0.680655   \n",
       "102                -0.219538                -0.209273   \n",
       "\n",
       "     EDA_TonicMean_version04  EDA_TonicMean_version05  \\\n",
       "269                -2.076390                -1.869410   \n",
       "211                -0.131699                -0.129467   \n",
       "197                -1.254804                -0.683124   \n",
       "75                  0.220138                -0.002063   \n",
       "177                -1.195093                -0.569050   \n",
       "..                       ...                      ...   \n",
       "188                -0.661230                -0.513394   \n",
       "71                  1.381119                 0.854606   \n",
       "106                -0.392341                -0.370327   \n",
       "270                -0.323792                -0.360686   \n",
       "102                -0.103224                 0.025001   \n",
       "\n",
       "     EDA_TonicMean_version09  EDA_TonicMean_version10  \\\n",
       "269                 0.597167                 0.362062   \n",
       "211                -0.662698                -0.644065   \n",
       "197                -0.014281                 0.030278   \n",
       "75                 -1.119621                -1.112651   \n",
       "177                -1.246429                -1.107403   \n",
       "..                       ...                      ...   \n",
       "188                -1.014946                -0.994582   \n",
       "71                 -0.446144                -0.432101   \n",
       "106                -0.500164                -0.518055   \n",
       "270                 0.003870                -0.053789   \n",
       "102                 0.003300                 0.036997   \n",
       "\n",
       "     EDA_TonicMean_version11  EDA_TonicMean_version12  \\\n",
       "269                -1.765695                -1.479098   \n",
       "211                -0.258565                -0.237457   \n",
       "197                -0.612785                -0.323310   \n",
       "75                  0.082926                -0.217642   \n",
       "177                -0.981167                -0.478398   \n",
       "..                       ...                      ...   \n",
       "188                -0.575531                -0.431628   \n",
       "71                  1.443925                 0.759285   \n",
       "106                -0.417380                -0.369009   \n",
       "270                -0.548041                -0.547836   \n",
       "102                -0.163482                -0.066556   \n",
       "\n",
       "     EDA_TonicMean_version16  EDA_TonicMean_version17  ...  \\\n",
       "269                 0.418093                 0.161042  ...   \n",
       "211                -0.612173                -0.596055  ...   \n",
       "197                -0.147675                -0.124319  ...   \n",
       "75                 -1.034901                -1.023674  ...   \n",
       "177                -0.795857                -0.715333  ...   \n",
       "..                       ...                      ...  ...   \n",
       "188                -0.679828                -0.661295  ...   \n",
       "71                 -0.517737                -0.506605  ...   \n",
       "106                -0.471410                -0.478937  ...   \n",
       "270                -0.197162                -0.265638  ...   \n",
       "102                -0.158862                -0.138007  ...   \n",
       "\n",
       "     EEG_avgRelTheta_version09  EEG_avgRelTheta_version10  \\\n",
       "269                   0.462172                   0.859784   \n",
       "211                  -0.260123                   1.010109   \n",
       "197                  -1.458536                  -2.291505   \n",
       "75                   -0.084950                  -0.236394   \n",
       "177                   0.509455                   0.654922   \n",
       "..                         ...                        ...   \n",
       "188                  -0.726769                  -1.195044   \n",
       "71                    0.597457                   0.281063   \n",
       "106                   1.048729                   1.497494   \n",
       "270                   0.846641                   1.038962   \n",
       "102                   1.671283                   1.827563   \n",
       "\n",
       "     EEG_avgRelTheta_version11  EEG_avgRelTheta_version12  \\\n",
       "269                  -0.051114                   0.233826   \n",
       "211                  -0.213657                   0.601153   \n",
       "197                  -0.823308                  -1.187300   \n",
       "75                   -1.212890                  -1.107865   \n",
       "177                   0.548907                   0.656188   \n",
       "..                         ...                        ...   \n",
       "188                  -0.629046                  -0.860808   \n",
       "71                   -0.908693                  -0.867127   \n",
       "106                  -0.488310                  -0.037478   \n",
       "270                   0.487292                   0.634474   \n",
       "102                   0.991150                   1.212934   \n",
       "\n",
       "     EEG_avgRelTheta_version16  EEG_avgRelTheta_version17  \\\n",
       "269                   0.237753                   0.649436   \n",
       "211                  -0.307295                   0.907735   \n",
       "197                  -1.355405                  -1.868532   \n",
       "75                   -0.042654                  -0.178245   \n",
       "177                   0.507635                   0.712548   \n",
       "..                         ...                        ...   \n",
       "188                  -0.798998                  -1.181357   \n",
       "71                    0.619710                   0.355382   \n",
       "106                   1.458071                   2.088352   \n",
       "270                   0.559359                   0.808679   \n",
       "102                   2.163855                   2.485919   \n",
       "\n",
       "     EEG_avgRelTheta_version19  EEG_avgRelTheta_version20  \\\n",
       "269                   0.111443                   0.465456   \n",
       "211                  -0.047399                   1.014504   \n",
       "197                  -0.703187                  -1.310684   \n",
       "75                   -0.830580                  -0.678148   \n",
       "177                  -0.440298                   0.200804   \n",
       "..                         ...                        ...   \n",
       "188                   0.012439                  -0.598611   \n",
       "71                    0.196207                  -0.034579   \n",
       "106                  -0.736493                   0.362864   \n",
       "270                   0.689936                   0.688303   \n",
       "102                   0.200236                   0.773377   \n",
       "\n",
       "     EEG_avgRelTheta_version22  EEG_avgRelTheta_version23  \n",
       "269                   0.779651                   0.627392  \n",
       "211                   0.237016                   1.841947  \n",
       "197                  -0.785986                  -1.462410  \n",
       "75                   -1.206773                  -0.626839  \n",
       "177                  -0.601341                   0.526651  \n",
       "..                         ...                        ...  \n",
       "188                   0.566104                  -0.681974  \n",
       "71                    0.716476                   0.070465  \n",
       "106                  -1.311561                   0.741032  \n",
       "270                   2.265877                   0.874194  \n",
       "102                   0.940547                   1.372242  \n",
       "\n",
       "[243 rows x 5815 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjSA1</th>\n",
       "      <th>adjSA2</th>\n",
       "      <th>adjSA3</th>\n",
       "      <th>adjSAtotal</th>\n",
       "      <th>Lv_1_Hi</th>\n",
       "      <th>Lv_2_Hi</th>\n",
       "      <th>Lv_3_Hi</th>\n",
       "      <th>Tot_Hi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.143670</td>\n",
       "      <td>1.101324</td>\n",
       "      <td>-0.822506</td>\n",
       "      <td>0.117187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>-0.783965</td>\n",
       "      <td>-0.834554</td>\n",
       "      <td>0.116317</td>\n",
       "      <td>-0.677632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.475912</td>\n",
       "      <td>-0.162414</td>\n",
       "      <td>1.180378</td>\n",
       "      <td>0.804260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.088596</td>\n",
       "      <td>0.229732</td>\n",
       "      <td>0.972713</td>\n",
       "      <td>0.618738</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-1.146056</td>\n",
       "      <td>0.662741</td>\n",
       "      <td>-3.060939</td>\n",
       "      <td>-1.932524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.116062</td>\n",
       "      <td>0.313836</td>\n",
       "      <td>0.270247</td>\n",
       "      <td>0.799881</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.881938</td>\n",
       "      <td>0.311514</td>\n",
       "      <td>-0.739256</td>\n",
       "      <td>-0.666210</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.900207</td>\n",
       "      <td>0.372292</td>\n",
       "      <td>-1.423042</td>\n",
       "      <td>-1.032613</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-2.025591</td>\n",
       "      <td>0.753425</td>\n",
       "      <td>0.139548</td>\n",
       "      <td>-0.472791</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.002411</td>\n",
       "      <td>-1.686081</td>\n",
       "      <td>0.460911</td>\n",
       "      <td>-0.533697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adjSA1    adjSA2    adjSA3  adjSAtotal  Lv_1_Hi  Lv_2_Hi  Lv_3_Hi  \\\n",
       "269  0.143670  1.101324 -0.822506    0.117187        1        1        0   \n",
       "211 -0.783965 -0.834554  0.116317   -0.677632        0        0        0   \n",
       "197  0.475912 -0.162414  1.180378    0.804260        1        0        1   \n",
       "75  -0.088596  0.229732  0.972713    0.618738        0        1        1   \n",
       "177 -1.146056  0.662741 -3.060939   -1.932524        0        1        0   \n",
       "..        ...       ...       ...         ...      ...      ...      ...   \n",
       "188  1.116062  0.313836  0.270247    0.799881        1        1        1   \n",
       "71  -0.881938  0.311514 -0.739256   -0.666210        0        1        0   \n",
       "106 -0.900207  0.372292 -1.423042   -1.032613        0        1        0   \n",
       "270 -2.025591  0.753425  0.139548   -0.472791        0        1        0   \n",
       "102 -0.002411 -1.686081  0.460911   -0.533697        0        0        1   \n",
       "\n",
       "     Tot_Hi  \n",
       "269       0  \n",
       "211       0  \n",
       "197       1  \n",
       "75        1  \n",
       "177       0  \n",
       "..      ...  \n",
       "188       1  \n",
       "71        0  \n",
       "106       0  \n",
       "270       0  \n",
       "102       0  \n",
       "\n",
       "[243 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictors_df = df.iloc[:, 1:(df.shape[1] - 8)]\n",
    "outcomes_df = df.iloc[:, (df.shape[1] - 8):]\n",
    "\n",
    "display(predictors_df)\n",
    "display(outcomes_df)\n",
    "\n",
    "predictors_train, predictors_test, outcomes_train, outcomes_test = train_test_split(predictors_df, outcomes_df, test_size = 0.2, random_state = 42)\n",
    "\n",
    "display(predictors_train)\n",
    "display(outcomes_train)\n",
    "\n",
    "# Free up memory\n",
    "del df\n",
    "# del predictors_df\n",
    "# del outcomes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Point Biserial Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coors(predictors, outcomes, outcome_var):\n",
    "    coors = np.array([])\n",
    "    x = outcomes[outcome_var]\n",
    "    for column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations with Level 1 High SA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jshen/.local/lib/python3.10/site-packages/scipy/stats/_stats_py.py:5657: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rpb, prob = pearsonr(x, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fNIRS_S3D4_hbr_mean_version09        0.259524\n",
       "fNIRS_S6D4_hbr_mean_version09        0.248932\n",
       "EYE_meanline_version02              -0.230052\n",
       "fNIRS_S7D5_hbr_mean_version09        0.225756\n",
       "fNIRS_S1D1_hbr_mean_version10        0.225447\n",
       "fNIRS_S7D5_hbr_slope_version02       0.224202\n",
       "fNIRS_S4D5_hbr_RMS_version03        -0.217083\n",
       "fNIRS_S4D5_hbr_var_version03        -0.214469\n",
       "fNIRS_S4D5_hbr_MaxAmp_version03     -0.213761\n",
       "EYE_det_version03                   -0.212822\n",
       "fNIRS_S4D5_hbr_MaxAmp_version02     -0.209365\n",
       "fNIRS_S4D5_hbr_var_version02        -0.208932\n",
       "fNIRS_S1D1_hbr_mean_version02        0.208749\n",
       "fNIRS_S4D5_hbr_RMS_version02        -0.208439\n",
       "fNIRS_S4D5_hbo_MaxAmp_version03     -0.207962\n",
       "fNIRS_S2D1_hbr_mean_version10        0.207330\n",
       "fNIRS_S4D5_hbo_RMS_version02        -0.206484\n",
       "fNIRS_S6D4_hbr_skew_version03       -0.206203\n",
       "EYE_det_version02                   -0.206132\n",
       "fNIRS_S4D5_hbo_RMS_version03        -0.205783\n",
       "fNIRS_S1D1_hbr_mean_version09        0.204328\n",
       "fNIRS_S4D5_hbo_MaxAmp_version02     -0.204312\n",
       "fNIRS_S4D5_hbo_slope_version03      -0.203369\n",
       "fNIRS_S6D4_hbr_var_version11         0.200559\n",
       "fNIRS_S2D3_hbr_var_version03        -0.200540\n",
       "fNIRS_S6D6_hbr_mean_version05        0.200321\n",
       "fNIRS_S4D5_hbo_slope_version02      -0.199935\n",
       "fNIRS_S1D2_hbo_MaxAmp_version02     -0.199320\n",
       "fNIRS_S4D5_hbo_var_version02        -0.197967\n",
       "fNIRS_S5D3_hbr_mean_version04        0.197752\n",
       "fNIRS_S1D2_hbo_MaxAmp_version03     -0.197449\n",
       "fNIRS_S7D7_hbr_mean_version09        0.196461\n",
       "fNIRS_S6D4_hbr_mean_version10        0.195897\n",
       "fNIRS_S1D2_hbo_slope_version02      -0.195895\n",
       "fNIRS_S1D2_hbo_slope_version03      -0.195340\n",
       "fNIRS_S5D3_hbr_var_version19        -0.195243\n",
       "fNIRS_S5D3_hbr_RMS_version19        -0.194825\n",
       "fNIRS_S3D1_hbr_mean_version09        0.193542\n",
       "fNIRS_S4D5_hbr_slope_version03       0.190576\n",
       "EYE_BlinkRate_version02             -0.190498\n",
       "EYE_BlinkRate_version04              0.190335\n",
       "fNIRS_S8D7_hbr_var_version02        -0.188961\n",
       "fNIRS_S5D6_hbr_mean_version05        0.187966\n",
       "EYE_AvgPupilDiam_version03           0.187582\n",
       "fNIRS_S1D2_hbr_RMS_version03        -0.187442\n",
       "fNIRS_S6D6_hbr_kurtosis_version17   -0.187111\n",
       "fNIRS_S5D6_hbr_mean_version02        0.187104\n",
       "fNIRS_S4D2_hbr_MaxAmp_version02     -0.186944\n",
       "fNIRS_S2D1_hbr_kurtosis_version23   -0.185958\n",
       "fNIRS_S8D7_hbr_RMS_version02        -0.185580\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA1_coors = np.array([])\n",
    "x = outcomes_df[\"Lv_1_Hi\"]\n",
    "for column in predictors_df:\n",
    "    y = predictors_df[column]\n",
    "    SA1_coors = np.append(SA1_coors, stats.pointbiserialr(x, y)[0])\n",
    "\n",
    "SA1_corrs_series = pd.Series(data = SA1_coors, index = predictors_df.columns)\n",
    "SA1_corrs_series = SA1_corrs_series.sort_values(ascending = False, key = lambda x: np.abs(x))\n",
    "SA1_corrs_series.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations with Level 2 SA High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fNIRS_S1D2_hbo_RMS_version09         -0.194613\n",
       "EDA_PhasicMin_version23              -0.190724\n",
       "fNIRS_S1D1_hbr_area_version05        -0.184949\n",
       "fNIRS_S4D5_hbo_RMS_version09         -0.183523\n",
       "fNIRS_S4D5_hbo_RMS_version16         -0.179908\n",
       "fNIRS_S4D5_hbo_RMS_version17         -0.179320\n",
       "fNIRS_S3D3_hbo_mean_version03        -0.176381\n",
       "EYE_det_version10                    -0.176294\n",
       "fNIRS_S4D2_hbr_mean_version04         0.176009\n",
       "fNIRS_S5D3_hbo_MaxAmp_version17      -0.174589\n",
       "fNIRS_S5D3_hbo_MaxAmp_version10      -0.173018\n",
       "fNIRS_S1D2_hbo_area_version10        -0.172941\n",
       "fNIRS_S8D7_hbo_RMS_version23         -0.172309\n",
       "EYE_AvgPupilDiam_version12           -0.172236\n",
       "fNIRS_S4D2_hbr_mean_version09         0.170941\n",
       "fNIRS_S2D1_hbo_area_version05        -0.170657\n",
       "fNIRS_S6D7_hbr_slope_version02        0.169484\n",
       "fNIRS_S6D7_hbr_skew_version04         0.165854\n",
       "fNIRS_S6D6_hbr_slope_version23       -0.164438\n",
       "fNIRS_S1D2_hbo_var_version09         -0.164278\n",
       "fNIRS_S4D4_hbo_RMS_version09         -0.162949\n",
       "EYE_corm_version16                    0.162598\n",
       "ECG_Heartrate_version11              -0.162172\n",
       "fNIRS_S4D5_hbr_slope_version16       -0.161445\n",
       "fNIRS_S2D3_hbo_var_version04         -0.161145\n",
       "ECG_Heartrate_version04              -0.160722\n",
       "fNIRS_S2D3_hbo_var_version05         -0.160476\n",
       "fNIRS_S7D7_hbo_var_version10         -0.159830\n",
       "fNIRS_S4D2_hbo_RMS_version10         -0.155668\n",
       "fNIRS_S3D4_hbo_slope_version16       -0.155598\n",
       "fNIRS_S5D3_hbo_MaxAmp_version16      -0.154871\n",
       "fNIRS_S6D7_hbo_timeToMax_version05   -0.154532\n",
       "fNIRS_S6D7_hbr_skew_version09         0.154464\n",
       "fNIRS_S3D1_hbo_var_version12         -0.154003\n",
       "fNIRS_S3D1_hbo_var_version05         -0.153824\n",
       "fNIRS_S7D5_hbr_mean_version09         0.151708\n",
       "fNIRS_S2D3_hbr_area_version17         0.151321\n",
       "fNIRS_S7D5_hbr_timeToMax_version19    0.151002\n",
       "EEG_avgRelOccBeta_version02           0.150834\n",
       "fNIRS_S6D6_hbo_timeToMax_version19    0.150784\n",
       "fNIRS_S6D7_hbr_slope_version16       -0.150624\n",
       "fNIRS_S3D4_hbr_mean_version09         0.150273\n",
       "RSP_MedianAmplitude_version11        -0.149818\n",
       "fNIRS_S2D1_hbr_timeToMax_version04   -0.149526\n",
       "fNIRS_S7D5_hbr_timeToMax_version22    0.149523\n",
       "fNIRS_S5D3_hbr_timeToMax_version19    0.149521\n",
       "fNIRS_S6D4_hbo_area_version10        -0.149365\n",
       "fNIRS_S7D5_hbo_RMS_version09         -0.149313\n",
       "fNIRS_S5D3_hbr_timeToMax_version22    0.149147\n",
       "fNIRS_S1D1_hbr_timeToMax_version22    0.149022\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get array of point biserial correlations\n",
    "SA2_coors = np.array([])\n",
    "x = outcomes_df[\"Lv_2_Hi\"]\n",
    "for column in predictors_df:\n",
    "    y = predictors_df[column]\n",
    "    SA2_coors = np.append(SA2_coors, stats.pointbiserialr(x, y)[0])\n",
    "\n",
    "# Map features to correlations\n",
    "SA2_corrs_series = pd.Series(data = SA2_coors, index = predictors_df.columns)\n",
    "SA2_corrs_series = SA2_corrs_series.sort_values(ascending = False, key = lambda x: np.abs(x))\n",
    "SA2_corrs_series.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations with Level 3 SA High\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fNIRS_S7D5_hbr_slope_version09        0.267208\n",
       "fNIRS_S6D7_hbr_skew_version10         0.244622\n",
       "fNIRS_S7D5_hbr_slope_version02        0.242424\n",
       "EEG_avgRelAlpha_version16            -0.240167\n",
       "fNIRS_S4D5_hbr_MaxAmp_version02      -0.239346\n",
       "fNIRS_S7D5_hbr_slope_version10        0.236189\n",
       "fNIRS_S4D5_hbr_RMS_version02         -0.235369\n",
       "EEG_avgRelParAlpha_version16         -0.234341\n",
       "fNIRS_S7D5_hbr_MaxAmp_version02      -0.234271\n",
       "fNIRS_S4D5_hbr_RMS_version03         -0.233104\n",
       "EEG_avgRelMedAlpha_version16         -0.233081\n",
       "fNIRS_S7D5_hbr_MaxAmp_version03      -0.231953\n",
       "fNIRS_S5D6_hbr_RMS_version16         -0.230836\n",
       "fNIRS_S4D5_hbo_RMS_version02         -0.230458\n",
       "fNIRS_S4D5_hbr_MaxAmp_version03      -0.229220\n",
       "fNIRS_S4D5_hbr_var_version02         -0.228163\n",
       "fNIRS_S6D7_hbo_slope_version16       -0.227969\n",
       "fNIRS_S4D5_hbo_MaxAmp_version02      -0.223793\n",
       "EEG_avgRelOccAlpha_version16         -0.223479\n",
       "EEG_avgRelFroDelta_version09          0.222471\n",
       "EEG_avgRelFroDelta_version16          0.222341\n",
       "EEG_avgRelDelta_version09             0.222337\n",
       "EYE_BlinkRate_version04               0.221471\n",
       "fNIRS_S4D5_hbo_RMS_version03         -0.220977\n",
       "fNIRS_S4D5_hbr_slope_version03        0.219415\n",
       "EEG_avgRelFroAlpha_version16         -0.217487\n",
       "fNIRS_S7D5_hbr_MaxAmp_version09      -0.216818\n",
       "fNIRS_S5D3_hbr_slope_version09        0.216542\n",
       "EEG_avgRelAlpha_version11            -0.215488\n",
       "fNIRS_S4D5_hbr_var_version03         -0.215303\n",
       "EYE_BlinkRate_version09               0.213812\n",
       "fNIRS_S1D2_hbr_skew_version09         0.212808\n",
       "EEG_avgRelMedDelta_version09          0.210740\n",
       "fNIRS_S4D5_hbo_MaxAmp_version03      -0.210737\n",
       "EEG_avgRelDelta_version16             0.210237\n",
       "fNIRS_S4D5_hbo_var_version02         -0.209704\n",
       "fNIRS_S4D5_hbr_slope_version02        0.208255\n",
       "EEG_avgRelAlpha_version17            -0.208007\n",
       "fNIRS_S7D5_hbr_MaxAmp_version10      -0.207304\n",
       "fNIRS_S7D7_hbr_MaxAmp_version02      -0.206391\n",
       "EEG_avgRelMedAlpha_version11         -0.206294\n",
       "fNIRS_S3D3_hbo_var_version09         -0.206219\n",
       "fNIRS_S5D3_hbo_RMS_version09         -0.205884\n",
       "fNIRS_S4D5_hbo_slope_version02       -0.205850\n",
       "fNIRS_S8D7_hbr_RMS_version02         -0.205808\n",
       "fNIRS_S7D5_hbr_slope_version03        0.205769\n",
       "fNIRS_S7D5_hbr_RMS_version02         -0.205060\n",
       "fNIRS_S3D3_hbo_skew_version05         0.204846\n",
       "fNIRS_S7D5_hbr_timeToMax_version02   -0.204235\n",
       "fNIRS_S7D5_hbo_timeToMax_version02   -0.204234\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA3_coors = np.array([])\n",
    "x = outcomes_df[\"Lv_3_Hi\"]\n",
    "for column in predictors_df:\n",
    "    y = predictors_df[column]\n",
    "    SA3_coors = np.append(SA3_coors, stats.pointbiserialr(x, y)[0])\n",
    "\n",
    "SA3_corrs_series = pd.Series(data = SA3_coors, index = predictors_df.columns)\n",
    "SA3_corrs_series = SA3_corrs_series.sort_values(ascending = False, key = lambda x: np.abs(x))\n",
    "SA3_corrs_series.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations with Total SA High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EEG_avgRelFroAlpha_version16      -0.283605\n",
       "fNIRS_S5D6_hbr_RMS_version17      -0.267804\n",
       "fNIRS_S7D5_hbr_slope_version02     0.267341\n",
       "fNIRS_S4D5_hbr_RMS_version03      -0.264881\n",
       "fNIRS_S4D5_hbr_MaxAmp_version02   -0.263713\n",
       "fNIRS_S4D5_hbr_RMS_version02      -0.263675\n",
       "fNIRS_S4D5_hbr_MaxAmp_version03   -0.258945\n",
       "EEG_avgRelOccAlpha_version03       0.254052\n",
       "fNIRS_S4D5_hbr_var_version02      -0.250935\n",
       "EEG_avgRelAlpha_version16         -0.249727\n",
       "EEG_avgRelMedAlpha_version03       0.248657\n",
       "fNIRS_S4D5_hbo_RMS_version02      -0.248485\n",
       "EEG_avgRelOccAlpha_version02       0.247489\n",
       "fNIRS_S6D4_hbr_mean_version09      0.246073\n",
       "EEG_avgRelParAlpha_version02       0.246072\n",
       "fNIRS_S7D5_hbr_MaxAmp_version03   -0.245727\n",
       "fNIRS_S4D5_hbo_RMS_version03      -0.245000\n",
       "EEG_avgRelAlpha_version11         -0.244357\n",
       "EEG_avgRelParAlpha_version03       0.243798\n",
       "fNIRS_S4D5_hbr_slope_version03     0.243046\n",
       "EEG_avgRelFroAlpha_version09      -0.242836\n",
       "fNIRS_S4D5_hbo_MaxAmp_version02   -0.241826\n",
       "fNIRS_S4D5_hbr_var_version03      -0.241085\n",
       "EEG_avgRelMedAlpha_version16      -0.240285\n",
       "EEG_avgRelMedAlpha_version02       0.239624\n",
       "EEG_avgRelAlpha_version04         -0.237928\n",
       "EEG_avgRelMedAlpha_version04      -0.234887\n",
       "EEG_avgRelParAlpha_version04      -0.234060\n",
       "fNIRS_S4D5_hbo_MaxAmp_version03   -0.233885\n",
       "EEG_avgRelParAlpha_version16      -0.233786\n",
       "fNIRS_S7D5_hbr_slope_version03     0.231751\n",
       "EEG_avgRelAlpha_version03          0.230166\n",
       "fNIRS_S5D6_hbr_RMS_version16      -0.229772\n",
       "fNIRS_S4D5_hbr_slope_version02     0.229068\n",
       "EEG_avgRelMedAlpha_version11      -0.228560\n",
       "EEG_avgRelAlpha_version02          0.227092\n",
       "EEG_avgRelFroDelta_version09       0.225118\n",
       "EEG_avgRelAlpha_version09         -0.223322\n",
       "fNIRS_S4D5_hbo_slope_version03    -0.222610\n",
       "fNIRS_S7D5_hbr_MaxAmp_version02   -0.222201\n",
       "fNIRS_S4D5_hbo_slope_version02    -0.221578\n",
       "EEG_avgRelOccAlpha_version04      -0.221576\n",
       "EEG_EI_version09                   0.221518\n",
       "EEG_avgRelFroAlpha_version11      -0.221387\n",
       "fNIRS_S4D5_hbo_var_version02      -0.219552\n",
       "fNIRS_S3D4_hbr_mean_version09      0.219101\n",
       "EEG_avgRelDelta_version04          0.217046\n",
       "fNIRS_S5D6_hbr_RMS_version09      -0.216983\n",
       "EEG_avgRelParAlpha_version11      -0.216908\n",
       "fNIRS_S5D6_hbr_RMS_version10      -0.216901\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_tot_coors = np.array([])\n",
    "x = outcomes_df[\"Tot_Hi\"]\n",
    "for column in predictors_df:\n",
    "    y = predictors_df[column]\n",
    "    SA_tot_coors = np.append(SA_tot_coors, stats.pointbiserialr(x, y)[0])\n",
    "\n",
    "SA_tot_corrs_series = pd.Series(data = SA_tot_coors, index = predictors_df.columns)\n",
    "SA_tot_corrs_series = SA_tot_corrs_series.sort_values(ascending = False, key = lambda x: np.abs(x))\n",
    "SA_tot_corrs_series.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outcome of the cell below is that parameters of elasticnet regularization, regularization strength of 1.0, and l1_ratio of 0.25 is best currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regularization strength: 1.0\n",
      "Best penalty: elasticnet\n",
      "Best alpha: 0.25\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "SA1_model = LogisticRegression(solver = \"saga\", max_iter = 5000)\n",
    "\n",
    "params = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    \"penalty\": [\"l1\", \"elasticnet\"],\n",
    "    \"l1_ratio\": [.25, .50, .75]\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation with different regularization strengths and regularization types\n",
    "clf = GridSearchCV(SA1_model, params, cv = 5, scoring = \"f1\", n_jobs = -1)\n",
    "clf.fit(predictors_train, outcomes_train[\"Lv_1_Hi\"])\n",
    "\n",
    "# Show the best regularization strength and penaalty type\n",
    "print(\"Best regularization strength:\", clf.best_params_[\"C\"])\n",
    "print(\"Best penalty:\", clf.best_params_[\"penalty\"])\n",
    "\n",
    "if clf.best_params_[\"penalty\"] == \"elasticnet\":\n",
    "    print(\"Best alpha:\", clf.best_params_[\"l1_ratio\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elasticnet penalty slightly better than l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 10-fold cross-validation score for l1: 0.685989010989011\n",
      "Average 10-fold cross-validation score for elasticnet: 0.6910648192387322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "SA1_model_l1 = LogisticRegression(penalty = \"l1\", C = 10.0, solver = \"saga\", max_iter = 10000)\n",
    "SA1_model_elasticnet = LogisticRegression(l1_ratio = 0.25, max_iter = 10000, penalty = \"elasticnet\", solver = \"saga\", C = 1.0)\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "cv_scores_l1 = cross_val_score(SA1_model_l1, predictors_train, outcomes_train[\"Lv_1_Hi\"], cv = 10, scoring = \"f1\", n_jobs = -1)\n",
    "cv_scores_elasticnet = cross_val_score(SA1_model_elasticnet, predictors_train, outcomes_train[\"Lv_1_Hi\"], cv = 10, scoring = \"f1\", n_jobs = -1)\n",
    "\n",
    "# Calculate the average cross-validation score\n",
    "mean_cv_score_l1 = cv_scores_l1.mean()\n",
    "mean_cv_score_elasticnet = cv_scores_elasticnet.mean()\n",
    "\n",
    "print(\"Average 10-fold cross-validation score for l1:\", mean_cv_score_l1)\n",
    "print(\"Average 10-fold cross-validation score for elasticnet:\", mean_cv_score_elasticnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 10-fold cross-validation score: 0.6910648192387322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "SA1_model = LogisticRegression(l1_ratio = 0.25, max_iter = 20000, penalty = \"elasticnet\", solver = \"saga\", C = 1.0, n_jobs = -1)\n",
    "cv_scores = cross_val_score(SA1_model, predictors_train, outcomes_train[\"Lv_1_Hi\"], cv = 10, scoring = \"f1\", n_jobs = -1)\n",
    "mean_cv_score = cv_scores.mean()\n",
    "print(\"Average 10-fold cross-validation score:\", mean_cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual SA1 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(l1_ratio=0.25, max_iter=20000, n_jobs=-1,\n",
       "                   penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(l1_ratio=0.25, max_iter=20000, n_jobs=-1,\n",
       "                   penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(l1_ratio=0.25, max_iter=20000, n_jobs=-1,\n",
       "                   penalty='elasticnet', solver='saga')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA1_model = LogisticRegression(l1_ratio = 0.25, max_iter = 20000, penalty = \"elasticnet\", solver = \"saga\", C = 1.0, n_jobs = -1)\n",
    "SA1_model.fit(predictors_train, outcomes_train[\"Lv_1_Hi\"])\n",
    "SA1_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2807)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(SA1_model.coef_ != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "SA1_predicted_outcomes = SA1_model.predict(predictors_test)\n",
    "SA1_cm = metrics.confusion_matrix(outcomes_test[\"Lv_1_Hi\"], SA1_predicted_outcomes)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = SA1_cm, display_labels = [\"Level 1 Low\", \"Level 1 High\"])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa33630ad40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(outcomes_test[\"Lv_1_Hi\"], SA1_predicted_outcomes)\n",
    "roc_auc  = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label = \"ROC Curve (area = %0.3f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], \"k--\") # Random predictions curve\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model Regularization with Made-Up Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def func_val_bin(predictors):\n",
    "    \"\"\"\n",
    "        Creates a function out of five variables in the predictors dataframe\n",
    "        and outputs a boolean Pandas series where True means the function value\n",
    "        was greater than or equal to the median and False otherwise.\n",
    "\n",
    "        Parameters:\n",
    "            predictors (Dataframe): pandas Dataframe containing all predictor features\n",
    "\n",
    "        Output:\n",
    "            (Series): pandas Series containing True and False values where True means that\n",
    "                      the calculated value was above the median and False otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize arary to store continuous values of function\n",
    "    func_calcs = np.array([])\n",
    "\n",
    "    # Get random coefficients and features\n",
    "    random.seed(42)\n",
    "    coefficients = np.array([round(random.uniform(-5, 5), 1) for i in range(5)])\n",
    "    selected_features = np.array(random.sample(list(predictors.columns), 5))\n",
    "\n",
    "    print(\"Function = \" + \n",
    "            f\"{coefficients[0]} * {selected_features[0]} + \" +\n",
    "            f\"{coefficients[1]} * {selected_features[1]} + \" +\n",
    "            f\"{coefficients[2]} * {selected_features[2]} + \" +\n",
    "            f\"{coefficients[3]} * {selected_features[3]} + \" +\n",
    "            f\"{coefficients[4]} * {selected_features[4]}\")\n",
    "    \n",
    "    for index, row in predictors.iterrows():\n",
    "        # Add new calculation to func_calcs\n",
    "        func_calcs = np.append(func_calcs, (coefficients[0] * row[selected_features[0]] +\n",
    "                                              coefficients[1] * row[selected_features[1]] +\n",
    "                                              coefficients[2] * row[selected_features[2]] +\n",
    "                                              coefficients[3] * row[selected_features[3]] +\n",
    "                                              coefficients[4] * row[selected_features[4]]))\n",
    "\n",
    "    func_calcs_median = np.median(func_calcs)\n",
    "    return func_calcs >= func_calcs_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/jshen/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regularization strength: 0.1\n",
      "Best penalty: l1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "SA1_model_func = LogisticRegression(solver = \"saga\", max_iter = 5000)\n",
    "\n",
    "params = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "    \"l1_ratio\": [.25, .50, .75]\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation with different regularization strengths and regularization types\n",
    "clf = GridSearchCV(SA1_model_func, params, cv = 5, scoring = \"f1\", n_jobs = -1)\n",
    "clf.fit(predictors_train, outcomes_train_func[\"Lv_1_Hi\"])\n",
    "\n",
    "# Show the best regularization strength and penaalty type\n",
    "print(\"Best regularization strength:\", clf.best_params_[\"C\"])\n",
    "print(\"Best penalty:\", clf.best_params_[\"penalty\"])\n",
    "\n",
    "if clf.best_params_[\"penalty\"] == \"elasticnet\":\n",
    "    print(\"Best alpha:\", clf.best_params_[\"l1_ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, max_iter=20000, n_jobs=-1, penalty=&#x27;l1&#x27;,\n",
       "                   solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, max_iter=20000, n_jobs=-1, penalty=&#x27;l1&#x27;,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=20000, n_jobs=-1, penalty='l1',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA1_model_func = LogisticRegression(max_iter = 20000, penalty = \"l1\", solver = \"saga\", C = 0.1, n_jobs = -1)\n",
    "SA1_model_func.fit(predictors_train, outcomes_train_func[\"Lv_1_Hi\"])\n",
    "SA1_model_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EDA_TonicMean_version23</th>\n",
       "      <td>0.001721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_avgRelOccAlpha_version23</th>\n",
       "      <td>0.203009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S1D1_hbo_slope_version23</th>\n",
       "      <td>0.588721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fNIRS_S2D1_hbr_kurtosis_version23</th>\n",
       "      <td>0.736985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EYE_FixationDuration_version23</th>\n",
       "      <td>0.691237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   coefficients\n",
       "EDA_TonicMean_version23                0.001721\n",
       "EEG_avgRelOccAlpha_version23           0.203009\n",
       "fNIRS_S1D1_hbo_slope_version23         0.588721\n",
       "fNIRS_S2D1_hbr_kurtosis_version23      0.736985\n",
       "EYE_FixationDuration_version23         0.691237"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA1_model_func_coef = pd.DataFrame(\n",
    "    data = {\n",
    "        \"coefficients\": SA1_model_func.coef_[0]\n",
    "    },\n",
    "    index = np.array(list(predictors_test.columns))\n",
    ")\n",
    "\n",
    "SA1_model_func_coef.loc[[\"EDA_TonicMean_version23\", \"EEG_avgRelOccAlpha_version23\", \"fNIRS_S1D1_hbo_slope_version23\", \"fNIRS_S2D1_hbr_kurtosis_version23\", \"EYE_FixationDuration_version23\"], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show that the coefficients above where nowhere near their actual values. Slightly suspicious of the effectiveness of regularization, but reduced a good amount of the features without removing any of the actual features used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
